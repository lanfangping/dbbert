#FORMAT=WebAnno TSV 3.3


#Text=Deep Dive into the New Features of Apache Spark 3.0 - Databricks
#Text=SAIS 2020
#Text=Agenda
#Text=Speakers
#Text=Training
#Text=Sponsors
#Text=Special Events
#Text=Women at Summit
#Text=Financial Services
#Text=Government and Education
#Text=Healthcare and Life Sciences
#Text=Media and Entertainment
#Text=Retail and Consumer Goods
#Text=Job Board
#Text=FAQ
#Text=WATCH KEYNOTES
#Text=SAIS 2020
#Text=Agenda
#Text=Speakers
#Text=Training
#Text=Sponsors
#Text=Special Events
#Text=Women at Summit
#Text=Financial Services
#Text=Government and Education
#Text=Healthcare and Life Sciences
#Text=Media and Entertainment
#Text=Retail and Consumer Goods
#Text=Job Board
#Text=FAQ
#Text=WATCH KEYNOTES
#Text=Deep Dive into the New Features of Apache Spark 3.0Download Slides
#Text=Continuing with the objectives to make Spark faster, easier, and smarter, Apache Spark 3.0 extends its scope with more than 3000 resolved JIRAs.
1-1	0-4	Deep	
1-2	5-9	Dive	
1-3	10-14	into	
1-4	15-18	the	
1-5	19-22	New	
1-6	23-31	Features	
1-7	32-34	of	
1-8	35-41	Apache	
1-9	42-47	Spark	
1-10	48-51	3.0	
1-11	52-53	-	
1-12	54-64	Databricks	
1-13	65-69	SAIS	
1-14	70-74	2020	
1-15	75-81	Agenda	
1-16	82-90	Speakers	
1-17	91-99	Training	
1-18	100-108	Sponsors	
1-19	109-116	Special	
1-20	117-123	Events	
1-21	124-129	Women	
1-22	130-132	at	
1-23	133-139	Summit	
1-24	140-149	Financial	
1-25	150-158	Services	
1-26	159-169	Government	
1-27	170-173	and	
1-28	174-183	Education	
1-29	184-194	Healthcare	
1-30	195-198	and	
1-31	199-203	Life	
1-32	204-212	Sciences	
1-33	213-218	Media	
1-34	219-222	and	
1-35	223-236	Entertainment	
1-36	237-243	Retail	
1-37	244-247	and	
1-38	248-256	Consumer	
1-39	257-262	Goods	
1-40	263-266	Job	
1-41	267-272	Board	
1-42	273-276	FAQ	
1-43	277-282	WATCH	
1-44	283-291	KEYNOTES	
1-45	292-296	SAIS	
1-46	297-301	2020	
1-47	302-308	Agenda	
1-48	309-317	Speakers	
1-49	318-326	Training	
1-50	327-335	Sponsors	
1-51	336-343	Special	
1-52	344-350	Events	
1-53	351-356	Women	
1-54	357-359	at	
1-55	360-366	Summit	
1-56	367-376	Financial	
1-57	377-385	Services	
1-58	386-396	Government	
1-59	397-400	and	
1-60	401-410	Education	
1-61	411-421	Healthcare	
1-62	422-425	and	
1-63	426-430	Life	
1-64	431-439	Sciences	
1-65	440-445	Media	
1-66	446-449	and	
1-67	450-463	Entertainment	
1-68	464-470	Retail	
1-69	471-474	and	
1-70	475-483	Consumer	
1-71	484-489	Goods	
1-72	490-493	Job	
1-73	494-499	Board	
1-74	500-503	FAQ	
1-75	504-509	WATCH	
1-76	510-518	KEYNOTES	
1-77	519-523	Deep	
1-78	524-528	Dive	
1-79	529-533	into	
1-80	534-537	the	
1-81	538-541	New	
1-82	542-550	Features	
1-83	551-553	of	
1-84	554-560	Apache	
1-85	561-566	Spark	
1-86	567-578	3.0Download	
1-87	579-585	Slides	
1-88	586-596	Continuing	
1-89	597-601	with	
1-90	602-605	the	
1-91	606-616	objectives	
1-92	617-619	to	
1-93	620-624	make	
1-94	625-630	Spark	
1-95	631-637	faster	
1-96	637-638	,	
1-97	639-645	easier	
1-98	645-646	,	
1-99	647-650	and	
1-100	651-658	smarter	
1-101	658-659	,	
1-102	660-666	Apache	
1-103	667-672	Spark	
1-104	673-676	3.0	
1-105	677-684	extends	
1-106	685-688	its	
1-107	689-694	scope	
1-108	695-699	with	
1-109	700-704	more	
1-110	705-709	than	
1-111	710-714	3000	
1-112	715-723	resolved	
1-113	724-729	JIRAs	
1-114	729-730	.	

#Text=We will talk about the exciting new developments in the Spark 3.0 as well as some other major initiatives that are coming in the future.
2-1	731-733	We	
2-2	734-738	will	
2-3	739-743	talk	
2-4	744-749	about	
2-5	750-753	the	
2-6	754-762	exciting	
2-7	763-766	new	
2-8	767-779	developments	
2-9	780-782	in	
2-10	783-786	the	
2-11	787-792	Spark	
2-12	793-796	3.0	
2-13	797-799	as	
2-14	800-804	well	
2-15	805-807	as	
2-16	808-812	some	
2-17	813-818	other	
2-18	819-824	major	
2-19	825-836	initiatives	
2-20	837-841	that	
2-21	842-845	are	
2-22	846-852	coming	
2-23	853-855	in	
2-24	856-859	the	
2-25	860-866	future	
2-26	866-867	.	

#Text=In this talk, we want to share with the community many of the more important changes with the examples and demos.
3-1	868-870	In	
3-2	871-875	this	
3-3	876-880	talk	
3-4	880-881	,	
3-5	882-884	we	
3-6	885-889	want	
3-7	890-892	to	
3-8	893-898	share	
3-9	899-903	with	
3-10	904-907	the	
3-11	908-917	community	
3-12	918-922	many	
3-13	923-925	of	
3-14	926-929	the	
3-15	930-934	more	
3-16	935-944	important	
3-17	945-952	changes	
3-18	953-957	with	
3-19	958-961	the	
3-20	962-970	examples	
3-21	971-974	and	
3-22	975-980	demos	
3-23	980-981	.	

#Text=The following features are covered: accelerator-aware scheduling, adaptive query execution, dynamic partition pruning, join hints, new query explain, better ANSI compliance, observable metrics, new UI for structured streaming, new UDAF and built-in functions, new unified interface for Pandas UDF, and various enhancements in the built-in data sources [e.g., parquet, ORC and JDBC].
4-1	982-985	The	
4-2	986-995	following	
4-3	996-1004	features	
4-4	1005-1008	are	
4-5	1009-1016	covered	
4-6	1016-1017	:	
4-7	1018-1035	accelerator-aware	
4-8	1036-1046	scheduling	
4-9	1046-1047	,	
4-10	1048-1056	adaptive	
4-11	1057-1062	query	
4-12	1063-1072	execution	
4-13	1072-1073	,	
4-14	1074-1081	dynamic	
4-15	1082-1091	partition	
4-16	1092-1099	pruning	
4-17	1099-1100	,	
4-18	1101-1105	join	
4-19	1106-1111	hints	
4-20	1111-1112	,	
4-21	1113-1116	new	
4-22	1117-1122	query	
4-23	1123-1130	explain	
4-24	1130-1131	,	
4-25	1132-1138	better	
4-26	1139-1143	ANSI	
4-27	1144-1154	compliance	
4-28	1154-1155	,	
4-29	1156-1166	observable	
4-30	1167-1174	metrics	
4-31	1174-1175	,	
4-32	1176-1179	new	
4-33	1180-1182	UI	
4-34	1183-1186	for	
4-35	1187-1197	structured	
4-36	1198-1207	streaming	
4-37	1207-1208	,	
4-38	1209-1212	new	
4-39	1213-1217	UDAF	
4-40	1218-1221	and	
4-41	1222-1230	built-in	
4-42	1231-1240	functions	
4-43	1240-1241	,	
4-44	1242-1245	new	
4-45	1246-1253	unified	
4-46	1254-1263	interface	
4-47	1264-1267	for	
4-48	1268-1274	Pandas	
4-49	1275-1278	UDF	
4-50	1278-1279	,	
4-51	1280-1283	and	
4-52	1284-1291	various	
4-53	1292-1304	enhancements	
4-54	1305-1307	in	
4-55	1308-1311	the	
4-56	1312-1320	built-in	
4-57	1321-1325	data	
4-58	1326-1333	sources	
4-59	1334-1335	[	
4-60	1335-1338	e.g	
4-61	1338-1339	.	
4-62	1339-1340	,	
4-63	1341-1348	parquet	
4-64	1348-1349	,	
4-65	1350-1353	ORC	
4-66	1354-1357	and	
4-67	1358-1362	JDBC	
4-68	1362-1363	]	
4-69	1363-1364	.	

#Text=Watch more Spark + AI sessions here
#Text=Try Databricks for free
#Text=Video Transcript
#Text=About us and our Open Source contributions
#Text=Hello, everyone.
5-1	1365-1370	Watch	
5-2	1371-1375	more	
5-3	1376-1381	Spark	
5-4	1382-1383	+	
5-5	1384-1386	AI	
5-6	1387-1395	sessions	
5-7	1396-1400	here	
5-8	1401-1404	Try	
5-9	1405-1415	Databricks	
5-10	1416-1419	for	
5-11	1420-1424	free	
5-12	1425-1430	Video	
5-13	1431-1441	Transcript	
5-14	1442-1447	About	
5-15	1448-1450	us	
5-16	1451-1454	and	
5-17	1455-1458	our	
5-18	1459-1463	Open	
5-19	1464-1470	Source	
5-20	1471-1484	contributions	
5-21	1485-1490	Hello	
5-22	1490-1491	,	
5-23	1492-1500	everyone	
5-24	1500-1501	.	

#Text=Today, Wenchen and I are glad to share with you the latest
#Text=updates about the upcoming release, Spark 3.0.
6-1	1502-1507	Today	
6-2	1507-1508	,	
6-3	1509-1516	Wenchen	
6-4	1517-1520	and	
6-5	1521-1522	I	
6-6	1523-1526	are	
6-7	1527-1531	glad	
6-8	1532-1534	to	
6-9	1535-1540	share	
6-10	1541-1545	with	
6-11	1546-1549	you	
6-12	1550-1553	the	
6-13	1554-1560	latest	
6-14	1561-1568	updates	
6-15	1569-1574	about	
6-16	1575-1578	the	
6-17	1579-1587	upcoming	
6-18	1588-1595	release	
6-19	1595-1596	,	
6-20	1597-1602	Spark	
6-21	1603-1606	3.0	
6-22	1606-1607	.	

#Text=So I’m Xiao Li.
7-1	1608-1610	So	
7-2	1611-1612	I	
7-3	1612-1613	’	
7-4	1613-1614	m	
7-5	1615-1619	Xiao	
7-6	1620-1622	Li	
7-7	1622-1623	.	

#Text=Both Wenchen and I are
#Text=working for Databricks.
8-1	1624-1628	Both	
8-2	1629-1636	Wenchen	
8-3	1637-1640	and	
8-4	1641-1642	I	
8-5	1643-1646	are	
8-6	1647-1654	working	
8-7	1655-1658	for	
8-8	1659-1669	Databricks	
8-9	1669-1670	.	

#Text=We focus on the open-source developments.
9-1	1671-1673	We	
9-2	1674-1679	focus	
9-3	1680-1682	on	
9-4	1683-1686	the	
9-5	1687-1698	open-source	
9-6	1699-1711	developments	
9-7	1711-1712	.	

#Text=Both of us are Spark
#Text=committers and PMC members.
10-1	1713-1717	Both	
10-2	1718-1720	of	
10-3	1721-1723	us	
10-4	1724-1727	are	
10-5	1728-1733	Spark	
10-6	1734-1744	committers	
10-7	1745-1748	and	
10-8	1749-1752	PMC	
10-9	1753-1760	members	
10-10	1760-1761	.	

#Text=About Databricks
#Text=Databricks provides a unified data analytics platform to accelerate
#Text=your data-driven animation.
11-1	1762-1767	About	
11-2	1768-1778	Databricks	
11-3	1779-1789	Databricks	
11-4	1790-1798	provides	
11-5	1799-1800	a	
11-6	1801-1808	unified	
11-7	1809-1813	data	
11-8	1814-1823	analytics	
11-9	1824-1832	platform	
11-10	1833-1835	to	
11-11	1836-1846	accelerate	
11-12	1847-1851	your	
11-13	1852-1863	data-driven	
11-14	1864-1873	animation	
11-15	1873-1874	.	

#Text=We are a global company with more than 5,000 customers across
#Text=various industries, and we have more than 450 partners worldwide.
12-1	1875-1877	We	
12-2	1878-1881	are	
12-3	1882-1883	a	
12-4	1884-1890	global	
12-5	1891-1898	company	
12-6	1899-1903	with	
12-7	1904-1908	more	
12-8	1909-1913	than	
12-9	1914-1919	5,000	
12-10	1920-1929	customers	
12-11	1930-1936	across	
12-12	1937-1944	various	
12-13	1945-1955	industries	
12-14	1955-1956	,	
12-15	1957-1960	and	
12-16	1961-1963	we	
12-17	1964-1968	have	
12-18	1969-1973	more	
12-19	1974-1978	than	
12-20	1979-1982	450	
12-21	1983-1991	partners	
12-22	1992-2001	worldwide	
12-23	2001-2002	.	

#Text=And most of you might
#Text=have heard of Databricks as original creator of Spark, Delta Lake, MLflow, and Koalas.
13-1	2003-2006	And	
13-2	2007-2011	most	
13-3	2012-2014	of	
13-4	2015-2018	you	
13-5	2019-2024	might	
13-6	2025-2029	have	
13-7	2030-2035	heard	
13-8	2036-2038	of	
13-9	2039-2049	Databricks	
13-10	2050-2052	as	
13-11	2053-2061	original	
13-12	2062-2069	creator	
13-13	2070-2072	of	
13-14	2073-2078	Spark	
13-15	2078-2079	,	
13-16	2080-2085	Delta	
13-17	2086-2090	Lake	
13-18	2090-2091	,	
13-19	2092-2098	MLflow	
13-20	2098-2099	,	
13-21	2100-2103	and	
13-22	2104-2110	Koalas	
13-23	2110-2111	.	

#Text=These are open-source projects that are leading innovation in the fields of data and machine
#Text=learnings.
14-1	2112-2117	These	
14-2	2118-2121	are	
14-3	2122-2133	open-source	
14-4	2134-2142	projects	
14-5	2143-2147	that	
14-6	2148-2151	are	
14-7	2152-2159	leading	
14-8	2160-2170	innovation	
14-9	2171-2173	in	
14-10	2174-2177	the	
14-11	2178-2184	fields	
14-12	2185-2187	of	
14-13	2188-2192	data	
14-14	2193-2196	and	
14-15	2197-2204	machine	
14-16	2205-2214	learnings	
14-17	2214-2215	.	

#Text=We continue to contribute and nurture this open-source community.
15-1	2216-2218	We	
15-2	2219-2227	continue	
15-3	2228-2230	to	
15-4	2231-2241	contribute	
15-5	2242-2245	and	
15-6	2246-2253	nurture	
15-7	2254-2258	this	
15-8	2259-2270	open-source	
15-9	2271-2280	community	
15-10	2280-2281	.	

#Text=Spark 3.0 Highlights
#Text=In Spark 3.0, the whole community resolved more than 3,400 JIRAs.
16-1	2282-2287	Spark	
16-2	2288-2291	3.0	
16-3	2292-2302	Highlights	
16-4	2303-2305	In	
16-5	2306-2311	Spark	
16-6	2312-2315	3.0	
16-7	2315-2316	,	
16-8	2317-2320	the	
16-9	2321-2326	whole	
16-10	2327-2336	community	
16-11	2337-2345	resolved	
16-12	2346-2350	more	
16-13	2351-2355	than	
16-14	2356-2361	3,400	
16-15	2362-2367	JIRAs	
16-16	2367-2368	.	

#Text=Spark SQL
#Text=and the Core are the new core module, and all the other components are built on Spark
#Text=SQL and the Core.
17-1	2369-2374	Spark	
17-2	2375-2378	SQL	
17-3	2379-2382	and	
17-4	2383-2386	the	
17-5	2387-2391	Core	
17-6	2392-2395	are	
17-7	2396-2399	the	
17-8	2400-2403	new	
17-9	2404-2408	core	
17-10	2409-2415	module	
17-11	2415-2416	,	
17-12	2417-2420	and	
17-13	2421-2424	all	
17-14	2425-2428	the	
17-15	2429-2434	other	
17-16	2435-2445	components	
17-17	2446-2449	are	
17-18	2450-2455	built	
17-19	2456-2458	on	
17-20	2459-2464	Spark	
17-21	2465-2468	SQL	
17-22	2469-2472	and	
17-23	2473-2476	the	
17-24	2477-2481	Core	
17-25	2481-2482	.	

#Text=Today, the pull requests for Spark SQL and the core constitute
#Text=more than 60% of Spark 3.0.
18-1	2483-2488	Today	
18-2	2488-2489	,	
18-3	2490-2493	the	
18-4	2494-2498	pull	
18-5	2499-2507	requests	
18-6	2508-2511	for	
18-7	2512-2517	Spark	
18-8	2518-2521	SQL	
18-9	2522-2525	and	
18-10	2526-2529	the	
18-11	2530-2534	core	
18-12	2535-2545	constitute	
18-13	2546-2550	more	
18-14	2551-2555	than	
18-15	2556-2559	60%	
18-16	2560-2562	of	
18-17	2563-2568	Spark	
18-18	2569-2572	3.0	
18-19	2572-2573	.	

#Text=In the last few releases, the percentage keeps going up.
19-1	2574-2576	In	
19-2	2577-2580	the	
19-3	2581-2585	last	
19-4	2586-2589	few	
19-5	2590-2598	releases	
19-6	2598-2599	,	
19-7	2600-2603	the	
19-8	2604-2614	percentage	
19-9	2615-2620	keeps	
19-10	2621-2626	going	
19-11	2627-2629	up	
19-12	2629-2630	.	

#Text=Today,
#Text=we will focus on the key features in both Spark SQL and the Core.
20-1	2631-2636	Today	
20-2	2636-2637	,	
20-3	2638-2640	we	
20-4	2641-2645	will	
20-5	2646-2651	focus	
20-6	2652-2654	on	
20-7	2655-2658	the	
20-8	2659-2662	key	
20-9	2663-2671	features	
20-10	2672-2674	in	
20-11	2675-2679	both	
20-12	2680-2685	Spark	
20-13	2686-2689	SQL	
20-14	2690-2693	and	
20-15	2694-2697	the	
20-16	2698-2702	Core	
20-17	2702-2703	.	

#Text=This release delivered
#Text=many new capabilities, performance gains, and extended compatibility for the Spark ecosystem.
21-1	2704-2708	This	
21-2	2709-2716	release	
21-3	2717-2726	delivered	
21-4	2727-2731	many	
21-5	2732-2735	new	
21-6	2736-2748	capabilities	
21-7	2748-2749	,	
21-8	2750-2761	performance	
21-9	2762-2767	gains	
21-10	2767-2768	,	
21-11	2769-2772	and	
21-12	2773-2781	extended	
21-13	2782-2795	compatibility	
21-14	2796-2799	for	
21-15	2800-2803	the	
21-16	2804-2809	Spark	
21-17	2810-2819	ecosystem	
21-18	2819-2820	.	

#Text=This is a combination of the tremendous contributions from the open-source community.
22-1	2821-2825	This	
22-2	2826-2828	is	
22-3	2829-2830	a	
22-4	2831-2842	combination	
22-5	2843-2845	of	
22-6	2846-2849	the	
22-7	2850-2860	tremendous	
22-8	2861-2874	contributions	
22-9	2875-2879	from	
22-10	2880-2883	the	
22-11	2884-2895	open-source	
22-12	2896-2905	community	
22-13	2905-2906	.	

#Text=It is impossible
#Text=to discuss the new features within 16 minutes.
23-1	2907-2909	It	
23-2	2910-2912	is	
23-3	2913-2923	impossible	
23-4	2924-2926	to	
23-5	2927-2934	discuss	
23-6	2935-2938	the	
23-7	2939-2942	new	
23-8	2943-2951	features	
23-9	2952-2958	within	
23-10	2959-2961	16	
23-11	2962-2969	minutes	
23-12	2969-2970	.	

#Text=We resolved more than 3,400 JIRAs.
24-1	2971-2973	We	
24-2	2974-2982	resolved	
24-3	2983-2987	more	
24-4	2988-2992	than	
24-5	2993-2998	3,400	
24-6	2999-3004	JIRAs	
24-7	3004-3005	.	

#Text=Even in
#Text=this light, I did my best, but I only can put 24 new Spark 3.0 features.
25-1	3006-3010	Even	
25-2	3011-3013	in	
25-3	3014-3018	this	
25-4	3019-3024	light	
25-5	3024-3025	,	
25-6	3026-3027	I	
25-7	3028-3031	did	
25-8	3032-3034	my	
25-9	3035-3039	best	
25-10	3039-3040	,	
25-11	3041-3044	but	
25-12	3045-3046	I	
25-13	3047-3051	only	
25-14	3052-3055	can	
25-15	3056-3059	put	
25-16	3060-3062	24	
25-17	3063-3066	new	
25-18	3067-3072	Spark	
25-19	3073-3076	3.0	
25-20	3077-3085	features	
25-21	3085-3086	.	

#Text=Today, we would like to present some of them.
26-1	3087-3092	Today	
26-2	3092-3093	,	
26-3	3094-3096	we	
26-4	3097-3102	would	
26-5	3103-3107	like	
26-6	3108-3110	to	
26-7	3111-3118	present	
26-8	3119-3123	some	
26-9	3124-3126	of	
26-10	3127-3131	them	
26-11	3131-3132	.	

#Text=First, let us talk about the
#Text=performance-related features.
27-1	3133-3138	First	
27-2	3138-3139	,	
27-3	3140-3143	let	
27-4	3144-3146	us	
27-5	3147-3151	talk	
27-6	3152-3157	about	
27-7	3158-3161	the	
27-8	3162-3181	performance-related	
27-9	3182-3190	features	
27-10	3190-3191	.	

#Text=Spark 3.0 Enhanced Performance
#Text=High performance is one of the major advantages when people
#Text=select Spark as their computation engine.
28-1	3192-3197	Spark	
28-2	3198-3201	3.0	
28-3	3202-3210	Enhanced	
28-4	3211-3222	Performance	
28-5	3223-3227	High	
28-6	3228-3239	performance	
28-7	3240-3242	is	
28-8	3243-3246	one	
28-9	3247-3249	of	
28-10	3250-3253	the	
28-11	3254-3259	major	
28-12	3260-3270	advantages	
28-13	3271-3275	when	
28-14	3276-3282	people	
28-15	3283-3289	select	
28-16	3290-3295	Spark	
28-17	3296-3298	as	
28-18	3299-3304	their	
28-19	3305-3316	computation	
28-20	3317-3323	engine	
28-21	3323-3324	.	

#Text=This release keeps enhancing the performance
#Text=for interactive, batch, streaming, and [inaudible] workloads.
29-1	3325-3329	This	
29-2	3330-3337	release	
29-3	3338-3343	keeps	
29-4	3344-3353	enhancing	
29-5	3354-3357	the	
29-6	3358-3369	performance	
29-7	3370-3373	for	
29-8	3374-3385	interactive	
29-9	3385-3386	,	
29-10	3387-3392	batch	
29-11	3392-3393	,	
29-12	3394-3403	streaming	
29-13	3403-3404	,	
29-14	3405-3408	and	
29-15	3409-3410	[	
29-16	3410-3419	inaudible	
29-17	3419-3420	]	
29-18	3421-3430	workloads	
29-19	3430-3431	.	

#Text=Here, I will first cover four of
#Text=the performance features in SQL query compilers.
30-1	3432-3436	Here	
30-2	3436-3437	,	
30-3	3438-3439	I	
30-4	3440-3444	will	
30-5	3445-3450	first	
30-6	3451-3456	cover	
30-7	3457-3461	four	
30-8	3462-3464	of	
30-9	3465-3468	the	
30-10	3469-3480	performance	
30-11	3481-3489	features	
30-12	3490-3492	in	
30-13	3493-3496	SQL	
30-14	3497-3502	query	
30-15	3503-3512	compilers	
30-16	3512-3513	.	

#Text=Later, Wenchen will talk about the performance enhancement for building data sources.
31-1	3514-3519	Later	
31-2	3519-3520	,	
31-3	3521-3528	Wenchen	
31-4	3529-3533	will	
31-5	3534-3538	talk	
31-6	3539-3544	about	
31-7	3545-3548	the	
31-8	3549-3560	performance	
31-9	3561-3572	enhancement	
31-10	3573-3576	for	
31-11	3577-3585	building	
31-12	3586-3590	data	
31-13	3591-3598	sources	
31-14	3598-3599	.	

#Text=The four major features in query compilers include
#Text=a new framework for adaptive query execution and a new runtime filtering for dynamic partition
#Text=pruning.
32-1	3600-3603	The	
32-2	3604-3608	four	
32-3	3609-3614	major	
32-4	3615-3623	features	
32-5	3624-3626	in	
32-6	3627-3632	query	
32-7	3633-3642	compilers	
32-8	3643-3650	include	
32-9	3651-3652	a	
32-10	3653-3656	new	
32-11	3657-3666	framework	
32-12	3667-3670	for	
32-13	3671-3679	adaptive	
32-14	3680-3685	query	
32-15	3686-3695	execution	
32-16	3696-3699	and	
32-17	3700-3701	a	
32-18	3702-3705	new	
32-19	3706-3713	runtime	
32-20	3714-3723	filtering	
32-21	3724-3727	for	
32-22	3728-3735	dynamic	
32-23	3736-3745	partition	
32-24	3746-3753	pruning	
32-25	3753-3754	.	

#Text=And also, we greatly reduce the overhead of our query compiler by more than a half,
#Text=especially on the optimizer overhead and the SQL cache synchronization.
33-1	3755-3758	And	
33-2	3759-3763	also	
33-3	3763-3764	,	
33-4	3765-3767	we	
33-5	3768-3775	greatly	
33-6	3776-3782	reduce	
33-7	3783-3786	the	
33-8	3787-3795	overhead	
33-9	3796-3798	of	
33-10	3799-3802	our	
33-11	3803-3808	query	
33-12	3809-3817	compiler	
33-13	3818-3820	by	
33-14	3821-3825	more	
33-15	3826-3830	than	
33-16	3831-3832	a	
33-17	3833-3837	half	
33-18	3837-3838	,	
33-19	3839-3849	especially	
33-20	3850-3852	on	
33-21	3853-3856	the	
33-22	3857-3866	optimizer	
33-23	3867-3875	overhead	
33-24	3876-3879	and	
33-25	3880-3883	the	
33-26	3884-3887	SQL	
33-27	3888-3893	cache	
33-28	3894-3909	synchronization	
33-29	3909-3910	.	

#Text=Supporting a complete
#Text=set of join hints is another useful features many people are waiting for.
34-1	3911-3921	Supporting	
34-2	3922-3923	a	
34-3	3924-3932	complete	
34-4	3933-3936	set	
34-5	3937-3939	of	
34-6	3940-3944	join	
34-7	3945-3950	hints	
34-8	3951-3953	is	
34-9	3954-3961	another	
34-10	3962-3968	useful	
34-11	3969-3977	features	
34-12	3978-3982	many	
34-13	3983-3989	people	
34-14	3990-3993	are	
34-15	3994-4001	waiting	
34-16	4002-4005	for	
34-17	4005-4006	.	

#Text=Adaptive query
#Text=execution was available at the previous releases.
35-1	4007-4015	Adaptive	
35-2	4016-4021	query	
35-3	4022-4031	execution	
35-4	4032-4035	was	
35-5	4036-4045	available	
35-6	4046-4048	at	
35-7	4049-4052	the	
35-8	4053-4061	previous	
35-9	4062-4070	releases	
35-10	4070-4071	.	

#Text=However, the previous framework has a few
#Text=major drawbacks.
36-1	4072-4079	However	
36-2	4079-4080	,	
36-3	4081-4084	the	
36-4	4085-4093	previous	
36-5	4094-4103	framework	
36-6	4104-4107	has	
36-7	4108-4109	a	
36-8	4110-4113	few	
36-9	4114-4119	major	
36-10	4120-4129	drawbacks	
36-11	4129-4130	.	

#Text=Very few companies are using it in the production systems.
37-1	4131-4135	Very	
37-2	4136-4139	few	
37-3	4140-4149	companies	
37-4	4150-4153	are	
37-5	4154-4159	using	
37-6	4160-4162	it	
37-7	4163-4165	in	
37-8	4166-4169	the	
37-9	4170-4180	production	
37-10	4181-4188	systems	
37-11	4188-4189	.	

#Text=In this release,
#Text=Databricks and the [inaudible] work together and redesigned the new framework and resolved
#Text=all the known issues.
38-1	4190-4192	In	
38-2	4193-4197	this	
38-3	4198-4205	release	
38-4	4205-4206	,	
38-5	4207-4217	Databricks	
38-6	4218-4221	and	
38-7	4222-4225	the	
38-8	4226-4227	[	
38-9	4227-4236	inaudible	
38-10	4236-4237	]	
38-11	4238-4242	work	
38-12	4243-4251	together	
38-13	4252-4255	and	
38-14	4256-4266	redesigned	
38-15	4267-4270	the	
38-16	4271-4274	new	
38-17	4275-4284	framework	
38-18	4285-4288	and	
38-19	4289-4297	resolved	
38-20	4298-4301	all	
38-21	4302-4305	the	
38-22	4306-4311	known	
38-23	4312-4318	issues	
38-24	4318-4319	.	

#Text=Let us talk about what we did in this release.
39-1	4320-4323	Let	
39-2	4324-4326	us	
39-3	4327-4331	talk	
39-4	4332-4337	about	
39-5	4338-4342	what	
39-6	4343-4345	we	
39-7	4346-4349	did	
39-8	4350-4352	in	
39-9	4353-4357	this	
39-10	4358-4365	release	
39-11	4365-4366	.	

#Text=Spark Catalyst Optimizer
#Text=Michael Armbrust.
#Text=is the creator of Spark SQL and also, Catalyst Optimizer.
40-1	4367-4372	Spark	
40-2	4373-4381	Catalyst	
40-3	4382-4391	Optimizer	
40-4	4392-4399	Michael	
40-5	4400-4408	Armbrust	
40-6	4408-4409	.	
40-7	4410-4412	is	
40-8	4413-4416	the	
40-9	4417-4424	creator	
40-10	4425-4427	of	
40-11	4428-4433	Spark	
40-12	4434-4437	SQL	
40-13	4438-4441	and	
40-14	4442-4446	also	
40-15	4446-4447	,	
40-16	4448-4456	Catalyst	
40-17	4457-4466	Optimizer	
40-18	4466-4467	.	

#Text=In the initial release of Spark
#Text=SQL, all the optimizer rules are heuristic-based.
41-1	4468-4470	In	
41-2	4471-4474	the	
41-3	4475-4482	initial	
41-4	4483-4490	release	
41-5	4491-4493	of	
41-6	4494-4499	Spark	
41-7	4500-4503	SQL	
41-8	4503-4504	,	
41-9	4505-4508	all	
41-10	4509-4512	the	
41-11	4513-4522	optimizer	
41-12	4523-4528	rules	
41-13	4529-4532	are	
41-14	4533-4548	heuristic-based	
41-15	4548-4549	.	

#Text=To generate good query plans, the query optimizer
#Text=needs to understand the data characteristics.
42-1	4550-4552	To	
42-2	4553-4561	generate	
42-3	4562-4566	good	
42-4	4567-4572	query	
42-5	4573-4578	plans	
42-6	4578-4579	,	
42-7	4580-4583	the	
42-8	4584-4589	query	
42-9	4590-4599	optimizer	
42-10	4600-4605	needs	
42-11	4606-4608	to	
42-12	4609-4619	understand	
42-13	4620-4623	the	
42-14	4624-4628	data	
42-15	4629-4644	characteristics	
42-16	4644-4645	.	

#Text=Then in Spark 2.x, we introduced a cost-based
#Text=optimizer.
43-1	4646-4650	Then	
43-2	4651-4653	in	
43-3	4654-4659	Spark	
43-4	4660-4661	2	
43-5	4661-4662	.	
43-6	4662-4663	x	
43-7	4663-4664	,	
43-8	4665-4667	we	
43-9	4668-4678	introduced	
43-10	4679-4680	a	
43-11	4681-4691	cost-based	
43-12	4692-4701	optimizer	
43-13	4701-4702	.	

#Text=However, in most cases, data statistics are commonly absent, especially when statistics collection is even more expensive than the data processing in the [search?].
44-1	4703-4710	However	
44-2	4710-4711	,	
44-3	4712-4714	in	
44-4	4715-4719	most	
44-5	4720-4725	cases	
44-6	4725-4726	,	
44-7	4727-4731	data	
44-8	4732-4742	statistics	
44-9	4743-4746	are	
44-10	4747-4755	commonly	
44-11	4756-4762	absent	
44-12	4762-4763	,	
44-13	4764-4774	especially	
44-14	4775-4779	when	
44-15	4780-4790	statistics	
44-16	4791-4801	collection	
44-17	4802-4804	is	
44-18	4805-4809	even	
44-19	4810-4814	more	
44-20	4815-4824	expensive	
44-21	4825-4829	than	
44-22	4830-4833	the	
44-23	4834-4838	data	
44-24	4839-4849	processing	
44-25	4850-4852	in	
44-26	4853-4856	the	
44-27	4857-4858	[	
44-28	4858-4864	search	
44-29	4864-4865	?	
44-30	4865-4866	]	
44-31	4866-4867	.	

#Text=Even if
#Text=the statistics are available, the statistics are likely out of date.
45-1	4868-4872	Even	
45-2	4873-4875	if	
45-3	4876-4879	the	
45-4	4880-4890	statistics	
45-5	4891-4894	are	
45-6	4895-4904	available	
45-7	4904-4905	,	
45-8	4906-4909	the	
45-9	4910-4920	statistics	
45-10	4921-4924	are	
45-11	4925-4931	likely	
45-12	4932-4935	out	
45-13	4936-4938	of	
45-14	4939-4943	date	
45-15	4943-4944	.	

#Text=Based on the storage and the compute separation in Spark, the characteristics of data [rival?]
46-1	4945-4950	Based	
46-2	4951-4953	on	
46-3	4954-4957	the	
46-4	4958-4965	storage	
46-5	4966-4969	and	
46-6	4970-4973	the	
46-7	4974-4981	compute	
46-8	4982-4992	separation	
46-9	4993-4995	in	
46-10	4996-5001	Spark	
46-11	5001-5002	,	
46-12	5003-5006	the	
46-13	5007-5022	characteristics	
46-14	5023-5025	of	
46-15	5026-5030	data	
46-16	5031-5032	[	
46-17	5032-5037	rival	
46-18	5037-5038	?	
46-19	5038-5039	]	

#Text=is unpredictable.
47-1	5040-5042	is	
47-2	5043-5056	unpredictable	
47-3	5056-5057	.	

#Text=The costs
#Text=are often misestimated due to the different deployment environment and the black box user-defined
#Text=functions.
48-1	5058-5061	The	
48-2	5062-5067	costs	
48-3	5068-5071	are	
48-4	5072-5077	often	
48-5	5078-5090	misestimated	
48-6	5091-5094	due	
48-7	5095-5097	to	
48-8	5098-5101	the	
48-9	5102-5111	different	
48-10	5112-5122	deployment	
48-11	5123-5134	environment	
48-12	5135-5138	and	
48-13	5139-5142	the	
48-14	5143-5148	black	
48-15	5149-5152	box	
48-16	5153-5165	user-defined	
48-17	5166-5175	functions	
48-18	5175-5176	.	

#Text=We are unable to estimate the cost for the UDF.
49-1	5177-5179	We	
49-2	5180-5183	are	
49-3	5184-5190	unable	
49-4	5191-5193	to	
49-5	5194-5202	estimate	
49-6	5203-5206	the	
49-7	5207-5211	cost	
49-8	5212-5215	for	
49-9	5216-5219	the	
49-10	5220-5223	UDF	
49-11	5223-5224	.	

#Text=Basically, in many cases, Spark
#Text=optimizer is enabled to generate the best plan due to this limitation.
50-1	5225-5234	Basically	
50-2	5234-5235	,	
50-3	5236-5238	in	
50-4	5239-5243	many	
50-5	5244-5249	cases	
50-6	5249-5250	,	
50-7	5251-5256	Spark	
50-8	5257-5266	optimizer	
50-9	5267-5269	is	
50-10	5270-5277	enabled	
50-11	5278-5280	to	
50-12	5281-5289	generate	
50-13	5290-5293	the	
50-14	5294-5298	best	
50-15	5299-5303	plan	
50-16	5304-5307	due	
50-17	5308-5310	to	
50-18	5311-5315	this	
50-19	5316-5326	limitation	
50-20	5326-5327	.	

#Text=Adaptive Query Execution
#Text=For all these
#Text=reasons, runtime adaptivity becomes more critical for Spark than the traditional systems.
51-1	5328-5336	Adaptive	
51-2	5337-5342	Query	
51-3	5343-5352	Execution	
51-4	5353-5356	For	
51-5	5357-5360	all	
51-6	5361-5366	these	
51-7	5367-5374	reasons	
51-8	5374-5375	,	
51-9	5376-5383	runtime	
51-10	5384-5394	adaptivity	
51-11	5395-5402	becomes	
51-12	5403-5407	more	
51-13	5408-5416	critical	
51-14	5417-5420	for	
51-15	5421-5426	Spark	
51-16	5427-5431	than	
51-17	5432-5435	the	
51-18	5436-5447	traditional	
51-19	5448-5455	systems	
51-20	5455-5456	.	

#Text=So this release introduced a new adaptive query execution framework called
#Text=AQE.
52-1	5457-5459	So	
52-2	5460-5464	this	
52-3	5465-5472	release	
52-4	5473-5483	introduced	
52-5	5484-5485	a	
52-6	5486-5489	new	
52-7	5490-5498	adaptive	
52-8	5499-5504	query	
52-9	5505-5514	execution	
52-10	5515-5524	framework	
52-11	5525-5531	called	
52-12	5532-5535	AQE	
52-13	5535-5536	.	

#Text=The basic idea of adaptive planning is simple.
53-1	5537-5540	The	
53-2	5541-5546	basic	
53-3	5547-5551	idea	
53-4	5552-5554	of	
53-5	5555-5563	adaptive	
53-6	5564-5572	planning	
53-7	5573-5575	is	
53-8	5576-5582	simple	
53-9	5582-5583	.	

#Text=We optimize the execution plan using
#Text=the existing rules of the optimizer and the planner after we collect more accurate statistics
#Text=from the finished plans.
54-1	5584-5586	We	
54-2	5587-5595	optimize	
54-3	5596-5599	the	
54-4	5600-5609	execution	
54-5	5610-5614	plan	
54-6	5615-5620	using	
54-7	5621-5624	the	
54-8	5625-5633	existing	
54-9	5634-5639	rules	
54-10	5640-5642	of	
54-11	5643-5646	the	
54-12	5647-5656	optimizer	
54-13	5657-5660	and	
54-14	5661-5664	the	
54-15	5665-5672	planner	
54-16	5673-5678	after	
54-17	5679-5681	we	
54-18	5682-5689	collect	
54-19	5690-5694	more	
54-20	5695-5703	accurate	
54-21	5704-5714	statistics	
54-22	5715-5719	from	
54-23	5720-5723	the	
54-24	5724-5732	finished	
54-25	5733-5738	plans	
54-26	5738-5739	.	

#Text=The red line shows the new logics we added in this release.
55-1	5740-5743	The	
55-2	5744-5747	red	
55-3	5748-5752	line	
55-4	5753-5758	shows	
55-5	5759-5762	the	
55-6	5763-5766	new	
55-7	5767-5773	logics	
55-8	5774-5776	we	
55-9	5777-5782	added	
55-10	5783-5785	in	
55-11	5786-5790	this	
55-12	5791-5798	release	
55-13	5798-5799	.	

#Text=Instead
#Text=of directly optimizing the execution plans, we send back the unfinished plan segments
#Text=and then use an existing optimizer and planner to optimize them at the end and build a new
#Text=execution plan.
56-1	5800-5807	Instead	
56-2	5808-5810	of	
56-3	5811-5819	directly	
56-4	5820-5830	optimizing	
56-5	5831-5834	the	
56-6	5835-5844	execution	
56-7	5845-5850	plans	
56-8	5850-5851	,	
56-9	5852-5854	we	
56-10	5855-5859	send	
56-11	5860-5864	back	
56-12	5865-5868	the	
56-13	5869-5879	unfinished	
56-14	5880-5884	plan	
56-15	5885-5893	segments	
56-16	5894-5897	and	
56-17	5898-5902	then	
56-18	5903-5906	use	
56-19	5907-5909	an	
56-20	5910-5918	existing	
56-21	5919-5928	optimizer	
56-22	5929-5932	and	
56-23	5933-5940	planner	
56-24	5941-5943	to	
56-25	5944-5952	optimize	
56-26	5953-5957	them	
56-27	5958-5960	at	
56-28	5961-5964	the	
56-29	5965-5968	end	
56-30	5969-5972	and	
56-31	5973-5978	build	
56-32	5979-5980	a	
56-33	5981-5984	new	
56-34	5985-5994	execution	
56-35	5995-5999	plan	
56-36	5999-6000	.	

#Text=This release includes three adaptive features.
57-1	6001-6005	This	
57-2	6006-6013	release	
57-3	6014-6022	includes	
57-4	6023-6028	three	
57-5	6029-6037	adaptive	
57-6	6038-6046	features	
57-7	6046-6047	.	

#Text=We can convert the soft
#Text=merge join to broadcast hash join, based on the runtime statistics.
58-1	6048-6050	We	
58-2	6051-6054	can	
58-3	6055-6062	convert	
58-4	6063-6066	the	
58-5	6067-6071	soft	
58-6	6072-6077	merge	
58-7	6078-6082	join	
58-8	6083-6085	to	
58-9	6086-6095	broadcast	
58-10	6096-6100	hash	
58-11	6101-6105	join	
58-12	6105-6106	,	
58-13	6107-6112	based	
58-14	6113-6115	on	
58-15	6116-6119	the	
58-16	6120-6127	runtime	
58-17	6128-6138	statistics	
58-18	6138-6139	.	

#Text=We can shrink the
#Text=number of reducers after over-partitioning.
59-1	6140-6142	We	
59-2	6143-6146	can	
59-3	6147-6153	shrink	
59-4	6154-6157	the	
59-5	6158-6164	number	
59-6	6165-6167	of	
59-7	6168-6176	reducers	
59-8	6177-6182	after	
59-9	6183-6200	over-partitioning	
59-10	6200-6201	.	

#Text=We can also handle the skew join at runtime.
60-1	6202-6204	We	
60-2	6205-6208	can	
60-3	6209-6213	also	
60-4	6214-6220	handle	
60-5	6221-6224	the	
60-6	6225-6229	skew	
60-7	6230-6234	join	
60-8	6235-6237	at	
60-9	6238-6245	runtime	
60-10	6245-6246	.	

#Text=If you want to know more details, please read the blog post I posted here.
61-1	6247-6249	If	
61-2	6250-6253	you	
61-3	6254-6258	want	
61-4	6259-6261	to	
61-5	6262-6266	know	
61-6	6267-6271	more	
61-7	6272-6279	details	
61-8	6279-6280	,	
61-9	6281-6287	please	
61-10	6288-6292	read	
61-11	6293-6296	the	
61-12	6297-6301	blog	
61-13	6302-6306	post	
61-14	6307-6308	I	
61-15	6309-6315	posted	
61-16	6316-6320	here	
61-17	6320-6321	.	

#Text=Today, I will briefly explain them one by one.
62-1	6322-6327	Today	
62-2	6327-6328	,	
62-3	6329-6330	I	
62-4	6331-6335	will	
62-5	6336-6343	briefly	
62-6	6344-6351	explain	
62-7	6352-6356	them	
62-8	6357-6360	one	
62-9	6361-6363	by	
62-10	6364-6367	one	
62-11	6367-6368	.	

#Text=Maybe most of you already
#Text=learn many performance tuning tips.
63-1	6369-6374	Maybe	
63-2	6375-6379	most	
63-3	6380-6382	of	
63-4	6383-6386	you	
63-5	6387-6394	already	
63-6	6395-6400	learn	
63-7	6401-6405	many	
63-8	6406-6417	performance	
63-9	6418-6424	tuning	
63-10	6425-6429	tips	
63-11	6429-6430	.	

#Text=For example, to make your join faster, you might guide
#Text=your optimizer to choose a broadcast hash join instead of the sort merge join.
64-1	6431-6434	For	
64-2	6435-6442	example	
64-3	6442-6443	,	
64-4	6444-6446	to	
64-5	6447-6451	make	
64-6	6452-6456	your	
64-7	6457-6461	join	
64-8	6462-6468	faster	
64-9	6468-6469	,	
64-10	6470-6473	you	
64-11	6474-6479	might	
64-12	6480-6485	guide	
64-13	6486-6490	your	
64-14	6491-6500	optimizer	
64-15	6501-6503	to	
64-16	6504-6510	choose	
64-17	6511-6512	a	
64-18	6513-6522	broadcast	
64-19	6523-6527	hash	
64-20	6528-6532	join	
64-21	6533-6540	instead	
64-22	6541-6543	of	
64-23	6544-6547	the	
64-24	6548-6552	sort	
64-25	6553-6558	merge	
64-26	6559-6563	join	
64-27	6563-6564	.	

#Text=You can
#Text=increase the spark.sql.autobroadcastjointhreshold or use a broadcast join hint.
65-1	6565-6568	You	
65-2	6569-6572	can	
65-3	6573-6581	increase	
65-4	6582-6585	the	
65-5	6586-6622	spark.sql.autobroadcastjointhreshold	
65-6	6623-6625	or	
65-7	6626-6629	use	
65-8	6630-6631	a	
65-9	6632-6641	broadcast	
65-10	6642-6646	join	
65-11	6647-6651	hint	
65-12	6651-6652	.	

#Text=However, it
#Text=is hard to tune it.
66-1	6653-6660	However	
66-2	6660-6661	,	
66-3	6662-6664	it	
66-4	6665-6667	is	
66-5	6668-6672	hard	
66-6	6673-6675	to	
66-7	6676-6680	tune	
66-8	6681-6683	it	
66-9	6683-6684	.	

#Text=You might hit out of memory exceptions and even get worse performance.
67-1	6685-6688	You	
67-2	6689-6694	might	
67-3	6695-6698	hit	
67-4	6699-6702	out	
67-5	6703-6705	of	
67-6	6706-6712	memory	
67-7	6713-6723	exceptions	
67-8	6724-6727	and	
67-9	6728-6732	even	
67-10	6733-6736	get	
67-11	6737-6742	worse	
67-12	6743-6754	performance	
67-13	6754-6755	.	

#Text=Even if it works now, it is hard to maintain over time because it is sensitive to your
#Text=data workloads.
68-1	6756-6760	Even	
68-2	6761-6763	if	
68-3	6764-6766	it	
68-4	6767-6772	works	
68-5	6773-6776	now	
68-6	6776-6777	,	
68-7	6778-6780	it	
68-8	6781-6783	is	
68-9	6784-6788	hard	
68-10	6789-6791	to	
68-11	6792-6800	maintain	
68-12	6801-6805	over	
68-13	6806-6810	time	
68-14	6811-6818	because	
68-15	6819-6821	it	
68-16	6822-6824	is	
68-17	6825-6834	sensitive	
68-18	6835-6837	to	
68-19	6838-6842	your	
68-20	6843-6847	data	
68-21	6848-6857	workloads	
68-22	6857-6858	.	

#Text=You might be wondering why Spark is unable to make the wise choice by
#Text=itself.
69-1	6859-6862	You	
69-2	6863-6868	might	
69-3	6869-6871	be	
69-4	6872-6881	wondering	
69-5	6882-6885	why	
69-6	6886-6891	Spark	
69-7	6892-6894	is	
69-8	6895-6901	unable	
69-9	6902-6904	to	
69-10	6905-6909	make	
69-11	6910-6913	the	
69-12	6914-6918	wise	
69-13	6919-6925	choice	
69-14	6926-6928	by	
69-15	6929-6935	itself	
69-16	6935-6936	.	

#Text=I can easily list multiple reasons.
#Text=the statistics might
#Text=be missing or out of date.
#Text=the file is compressed.
#Text=the file format is column-based, so the file
#Text=size does not represent the actual data volume.
#Text=the filters could be compressed
#Text=(the filters) might also contain the black box UDFs.
70-1	6937-6938	I	
70-2	6939-6942	can	
70-3	6943-6949	easily	
70-4	6950-6954	list	
70-5	6955-6963	multiple	
70-6	6964-6971	reasons	
70-7	6971-6972	.	
70-8	6973-6976	the	
70-9	6977-6987	statistics	
70-10	6988-6993	might	
70-11	6994-6996	be	
70-12	6997-7004	missing	
70-13	7005-7007	or	
70-14	7008-7011	out	
70-15	7012-7014	of	
70-16	7015-7019	date	
70-17	7019-7020	.	
70-18	7021-7024	the	
70-19	7025-7029	file	
70-20	7030-7032	is	
70-21	7033-7043	compressed	
70-22	7043-7044	.	
70-23	7045-7048	the	
70-24	7049-7053	file	
70-25	7054-7060	format	
70-26	7061-7063	is	
70-27	7064-7076	column-based	
70-28	7076-7077	,	
70-29	7078-7080	so	
70-30	7081-7084	the	
70-31	7085-7089	file	
70-32	7090-7094	size	
70-33	7095-7099	does	
70-34	7100-7103	not	
70-35	7104-7113	represent	
70-36	7114-7117	the	
70-37	7118-7124	actual	
70-38	7125-7129	data	
70-39	7130-7136	volume	
70-40	7136-7137	.	
70-41	7138-7141	the	
70-42	7142-7149	filters	
70-43	7150-7155	could	
70-44	7156-7158	be	
70-45	7159-7169	compressed	
70-46	7170-7171	(	
70-47	7171-7174	the	
70-48	7175-7182	filters	
70-49	7182-7183	)	
70-50	7184-7189	might	
70-51	7190-7194	also	
70-52	7195-7202	contain	
70-53	7203-7206	the	
70-54	7207-7212	black	
70-55	7213-7216	box	
70-56	7217-7221	UDFs	
70-57	7221-7222	.	

#Text=The whole query fragments might be large,
#Text=complex, and it is hard to estimate the actual data volume for Spark to make the best choice.
71-1	7223-7226	The	
71-2	7227-7232	whole	
71-3	7233-7238	query	
71-4	7239-7248	fragments	
71-5	7249-7254	might	
71-6	7255-7257	be	
71-7	7258-7263	large	
71-8	7263-7264	,	
71-9	7265-7272	complex	
71-10	7272-7273	,	
71-11	7274-7277	and	
71-12	7278-7280	it	
71-13	7281-7283	is	
71-14	7284-7288	hard	
71-15	7289-7291	to	
71-16	7292-7300	estimate	
71-17	7301-7304	the	
71-18	7305-7311	actual	
71-19	7312-7316	data	
71-20	7317-7323	volume	
71-21	7324-7327	for	
71-22	7328-7333	Spark	
71-23	7334-7336	to	
71-24	7337-7341	make	
71-25	7342-7345	the	
71-26	7346-7350	best	
71-27	7351-7357	choice	
71-28	7357-7358	.	

#Text=Convert Sort Merge Join to Broadcast Hash Join
#Text=So this is an example to show how AQE converts a sort merge join to
#Text=a broadcast hash join at runtime.
72-1	7359-7366	Convert	
72-2	7367-7371	Sort	
72-3	7372-7377	Merge	
72-4	7378-7382	Join	
72-5	7383-7385	to	
72-6	7386-7395	Broadcast	
72-7	7396-7400	Hash	
72-8	7401-7405	Join	
72-9	7406-7408	So	
72-10	7409-7413	this	
72-11	7414-7416	is	
72-12	7417-7419	an	
72-13	7420-7427	example	
72-14	7428-7430	to	
72-15	7431-7435	show	
72-16	7436-7439	how	
72-17	7440-7443	AQE	
72-18	7444-7452	converts	
72-19	7453-7454	a	
72-20	7455-7459	sort	
72-21	7460-7465	merge	
72-22	7466-7470	join	
72-23	7471-7473	to	
72-24	7474-7475	a	
72-25	7476-7485	broadcast	
72-26	7486-7490	hash	
72-27	7491-7495	join	
72-28	7496-7498	at	
72-29	7499-7506	runtime	
72-30	7506-7507	.	

#Text=First, execute the leave stages.
73-1	7508-7513	First	
73-2	7513-7514	,	
73-3	7515-7522	execute	
73-4	7523-7526	the	
73-5	7527-7532	leave	
73-6	7533-7539	stages	
73-7	7539-7540	.	

#Text=Query the statistics from
#Text=the shuffle operators which materialize the query fragments.
74-1	7541-7546	Query	
74-2	7547-7550	the	
74-3	7551-7561	statistics	
74-4	7562-7566	from	
74-5	7567-7570	the	
74-6	7571-7578	shuffle	
74-7	7579-7588	operators	
74-8	7589-7594	which	
74-9	7595-7606	materialize	
74-10	7607-7610	the	
74-11	7611-7616	query	
74-12	7617-7626	fragments	
74-13	7626-7627	.	

#Text=You can see the actual size
#Text=of stage two is much smaller than the estimated size reduced from 30 megabytes to 8 megabytes
#Text=so we can optimize the remaining plan and change the join algorithm from sort merge
#Text=join to broadcast hash join.
75-1	7628-7631	You	
75-2	7632-7635	can	
75-3	7636-7639	see	
75-4	7640-7643	the	
75-5	7644-7650	actual	
75-6	7651-7655	size	
75-7	7656-7658	of	
75-8	7659-7664	stage	
75-9	7665-7668	two	
75-10	7669-7671	is	
75-11	7672-7676	much	
75-12	7677-7684	smaller	
75-13	7685-7689	than	
75-14	7690-7693	the	
75-15	7694-7703	estimated	
75-16	7704-7708	size	
75-17	7709-7716	reduced	
75-18	7717-7721	from	
75-19	7722-7724	30	
75-20	7725-7734	megabytes	
75-21	7735-7737	to	
75-22	7738-7739	8	
75-23	7740-7749	megabytes	
75-24	7750-7752	so	
75-25	7753-7755	we	
75-26	7756-7759	can	
75-27	7760-7768	optimize	
75-28	7769-7772	the	
75-29	7773-7782	remaining	
75-30	7783-7787	plan	
75-31	7788-7791	and	
75-32	7792-7798	change	
75-33	7799-7802	the	
75-34	7803-7807	join	
75-35	7808-7817	algorithm	
75-36	7818-7822	from	
75-37	7823-7827	sort	
75-38	7828-7833	merge	
75-39	7834-7838	join	
75-40	7839-7841	to	
75-41	7842-7851	broadcast	
75-42	7852-7856	hash	
75-43	7857-7861	join	
75-44	7861-7862	.	

#Text=Another popular performance tuning tip is to tune the configuration
#Text=spark.sql.shuffle.partitions.
76-1	7863-7870	Another	
76-2	7871-7878	popular	
76-3	7879-7890	performance	
76-4	7891-7897	tuning	
76-5	7898-7901	tip	
76-6	7902-7904	is	
76-7	7905-7907	to	
76-8	7908-7912	tune	
76-9	7913-7916	the	
76-10	7917-7930	configuration	
76-11	7931-7959	spark.sql.shuffle.partitions	
76-12	7959-7960	.	

#Text=The default value is a magic number, 200.
77-1	7961-7964	The	
77-2	7965-7972	default	
77-3	7973-7978	value	
77-4	7979-7981	is	
77-5	7982-7983	a	
77-6	7984-7989	magic	
77-7	7990-7996	number	
77-8	7996-7997	,	
77-9	7998-8001	200	
77-10	8001-8002	.	

#Text=Previously,
#Text=the original default is 8.
78-1	8003-8013	Previously	
78-2	8013-8014	,	
78-3	8015-8018	the	
78-4	8019-8027	original	
78-5	8028-8035	default	
78-6	8036-8038	is	
78-7	8039-8040	8	
78-8	8040-8041	.	

#Text=Later, it was increased to 200.
79-1	8042-8047	Later	
79-2	8047-8048	,	
79-3	8049-8051	it	
79-4	8052-8055	was	
79-5	8056-8065	increased	
79-6	8066-8068	to	
79-7	8069-8072	200	
79-8	8072-8073	.	

#Text=I believe no one knows the reason
#Text=why it become 200 instead of 50, 400, or 2,000.
80-1	8074-8075	I	
80-2	8076-8083	believe	
80-3	8084-8086	no	
80-4	8087-8090	one	
80-5	8091-8096	knows	
80-6	8097-8100	the	
80-7	8101-8107	reason	
80-8	8108-8111	why	
80-9	8112-8114	it	
80-10	8115-8121	become	
80-11	8122-8125	200	
80-12	8126-8133	instead	
80-13	8134-8136	of	
80-14	8137-8139	50	
80-15	8139-8140	,	
80-16	8141-8144	400	
80-17	8144-8145	,	
80-18	8146-8148	or	
80-19	8149-8154	2,000	
80-20	8154-8155	.	

#Text=It is very hard to tune it, to be
#Text=honest.
81-1	8156-8158	It	
81-2	8159-8161	is	
81-3	8162-8166	very	
81-4	8167-8171	hard	
81-5	8172-8174	to	
81-6	8175-8179	tune	
81-7	8180-8182	it	
81-8	8182-8183	,	
81-9	8184-8186	to	
81-10	8187-8189	be	
81-11	8190-8196	honest	
81-12	8196-8197	.	

#Text=Because it is a global configuration, it is almost impossible to decide the best
#Text=value for every query’s fragment using a single configuration, especially when your query
#Text=plan is huge and complex.
82-1	8198-8205	Because	
82-2	8206-8208	it	
82-3	8209-8211	is	
82-4	8212-8213	a	
82-5	8214-8220	global	
82-6	8221-8234	configuration	
82-7	8234-8235	,	
82-8	8236-8238	it	
82-9	8239-8241	is	
82-10	8242-8248	almost	
82-11	8249-8259	impossible	
82-12	8260-8262	to	
82-13	8263-8269	decide	
82-14	8270-8273	the	
82-15	8274-8278	best	
82-16	8279-8284	value	
82-17	8285-8288	for	
82-18	8289-8294	every	
82-19	8295-8300	query	
82-20	8300-8301	’	
82-21	8301-8302	s	
82-22	8303-8311	fragment	
82-23	8312-8317	using	
82-24	8318-8319	a	
82-25	8320-8326	single	
82-26	8327-8340	configuration	
82-27	8340-8341	,	
82-28	8342-8352	especially	
82-29	8353-8357	when	
82-30	8358-8362	your	
82-31	8363-8368	query	
82-32	8369-8373	plan	
82-33	8374-8376	is	
82-34	8377-8381	huge	
82-35	8382-8385	and	
82-36	8386-8393	complex	
82-37	8393-8394	.	

#Text=If you set it to very small values, the partition will be huge,
#Text=and the aggregation and the sort might need to spew the data to the disk.
83-1	8395-8397	If	
83-2	8398-8401	you	
83-3	8402-8405	set	
83-4	8406-8408	it	
83-5	8409-8411	to	
83-6	8412-8416	very	
83-7	8417-8422	small	
83-8	8423-8429	values	
83-9	8429-8430	,	
83-10	8431-8434	the	
83-11	8435-8444	partition	
83-12	8445-8449	will	
83-13	8450-8452	be	
83-14	8453-8457	huge	
83-15	8457-8458	,	
83-16	8459-8462	and	
83-17	8463-8466	the	
83-18	8467-8478	aggregation	
83-19	8479-8482	and	
83-20	8483-8486	the	
83-21	8487-8491	sort	
83-22	8492-8497	might	
83-23	8498-8502	need	
83-24	8503-8505	to	
83-25	8506-8510	spew	
83-26	8511-8514	the	
83-27	8515-8519	data	
83-28	8520-8522	to	
83-29	8523-8526	the	
83-30	8527-8531	disk	
83-31	8531-8532	.	

#Text=If the configuration
#Text=values are too big, the partition will be small.
84-1	8533-8535	If	
84-2	8536-8539	the	
84-3	8540-8553	configuration	
84-4	8554-8560	values	
84-5	8561-8564	are	
84-6	8565-8568	too	
84-7	8569-8572	big	
84-8	8572-8573	,	
84-9	8574-8577	the	
84-10	8578-8587	partition	
84-11	8588-8592	will	
84-12	8593-8595	be	
84-13	8596-8601	small	
84-14	8601-8602	.	

#Text=But the number of partitions is big.
85-1	8603-8606	But	
85-2	8607-8610	the	
85-3	8611-8617	number	
85-4	8618-8620	of	
85-5	8621-8631	partitions	
85-6	8632-8634	is	
85-7	8635-8638	big	
85-8	8638-8639	.	

#Text=It will cause inefficient IO and the performance bottleneck could be the task scheduler.
86-1	8640-8642	It	
86-2	8643-8647	will	
86-3	8648-8653	cause	
86-4	8654-8665	inefficient	
86-5	8666-8668	IO	
86-6	8669-8672	and	
86-7	8673-8676	the	
86-8	8677-8688	performance	
86-9	8689-8699	bottleneck	
86-10	8700-8705	could	
86-11	8706-8708	be	
86-12	8709-8712	the	
86-13	8713-8717	task	
86-14	8718-8727	scheduler	
86-15	8727-8728	.	

#Text=Then
#Text=it will slow down everybody.
87-1	8729-8733	Then	
87-2	8734-8736	it	
87-3	8737-8741	will	
87-4	8742-8746	slow	
87-5	8747-8751	down	
87-6	8752-8761	everybody	
87-7	8761-8762	.	

#Text=Also, it is very hard to maintain over time.
88-1	8763-8767	Also	
88-2	8767-8768	,	
88-3	8769-8771	it	
88-4	8772-8774	is	
88-5	8775-8779	very	
88-6	8780-8784	hard	
88-7	8785-8787	to	
88-8	8788-8796	maintain	
88-9	8797-8801	over	
88-10	8802-8806	time	
88-11	8806-8807	.	

#Text=Dynamically Coalesce Shuffle Partitions
#Text=Until you can
#Text=solve it in a smart way, we can first increase our initial partition number to a big one.
89-1	8808-8819	Dynamically	
89-2	8820-8828	Coalesce	
89-3	8829-8836	Shuffle	
89-4	8837-8847	Partitions	
89-5	8848-8853	Until	
89-6	8854-8857	you	
89-7	8858-8861	can	
89-8	8862-8867	solve	
89-9	8868-8870	it	
89-10	8871-8873	in	
89-11	8874-8875	a	
89-12	8876-8881	smart	
89-13	8882-8885	way	
89-14	8885-8886	,	
89-15	8887-8889	we	
89-16	8890-8893	can	
89-17	8894-8899	first	
89-18	8900-8908	increase	
89-19	8909-8912	our	
89-20	8913-8920	initial	
89-21	8921-8930	partition	
89-22	8931-8937	number	
89-23	8938-8940	to	
89-24	8941-8942	a	
89-25	8943-8946	big	
89-26	8947-8950	one	
89-27	8950-8951	.	

#Text=After we execute the leave query stage, we can know the actual size of each partition.
90-1	8952-8957	After	
90-2	8958-8960	we	
90-3	8961-8968	execute	
90-4	8969-8972	the	
90-5	8973-8978	leave	
90-6	8979-8984	query	
90-7	8985-8990	stage	
90-8	8990-8991	,	
90-9	8992-8994	we	
90-10	8995-8998	can	
90-11	8999-9003	know	
90-12	9004-9007	the	
90-13	9008-9014	actual	
90-14	9015-9019	size	
90-15	9020-9022	of	
90-16	9023-9027	each	
90-17	9028-9037	partition	
90-18	9037-9038	.	

#Text=Then we can automatically correlate the nearby partitions and automatically reduce the number
#Text=of partitions to a smaller number.
91-1	9039-9043	Then	
91-2	9044-9046	we	
91-3	9047-9050	can	
91-4	9051-9064	automatically	
91-5	9065-9074	correlate	
91-6	9075-9078	the	
91-7	9079-9085	nearby	
91-8	9086-9096	partitions	
91-9	9097-9100	and	
91-10	9101-9114	automatically	
91-11	9115-9121	reduce	
91-12	9122-9125	the	
91-13	9126-9132	number	
91-14	9133-9135	of	
91-15	9136-9146	partitions	
91-16	9147-9149	to	
91-17	9150-9151	a	
91-18	9152-9159	smaller	
91-19	9160-9166	number	
91-20	9166-9167	.	

#Text=This example shows how we reduce the number of partitions
#Text=from 50 to 5 at runtime.
92-1	9168-9172	This	
92-2	9173-9180	example	
92-3	9181-9186	shows	
92-4	9187-9190	how	
92-5	9191-9193	we	
92-6	9194-9200	reduce	
92-7	9201-9204	the	
92-8	9205-9211	number	
92-9	9212-9214	of	
92-10	9215-9225	partitions	
92-11	9226-9230	from	
92-12	9231-9233	50	
92-13	9234-9236	to	
92-14	9237-9238	5	
92-15	9239-9241	at	
92-16	9242-9249	runtime	
92-17	9249-9250	.	

#Text=And we added the actual coalesce at runtime.
93-1	9251-9254	And	
93-2	9255-9257	we	
93-3	9258-9263	added	
93-4	9264-9267	the	
93-5	9268-9274	actual	
93-6	9275-9283	coalesce	
93-7	9284-9286	at	
93-8	9287-9294	runtime	
93-9	9294-9295	.	

#Text=Data Skew
#Text=One more popular performance tuning tip is about data skew.
94-1	9296-9300	Data	
94-2	9301-9305	Skew	
94-3	9306-9309	One	
94-4	9310-9314	more	
94-5	9315-9322	popular	
94-6	9323-9334	performance	
94-7	9335-9341	tuning	
94-8	9342-9345	tip	
94-9	9346-9348	is	
94-10	9349-9354	about	
94-11	9355-9359	data	
94-12	9360-9364	skew	
94-13	9364-9365	.	

#Text=Data skew is
#Text=very annoying.
95-1	9366-9370	Data	
95-2	9371-9375	skew	
95-3	9376-9378	is	
95-4	9379-9383	very	
95-5	9384-9392	annoying	
95-6	9392-9393	.	

#Text=You could see some long-running or frozen task and a lot of disks spinning
#Text=and a very low resource authorization rate in most nodes and even out of memory.
96-1	9394-9397	You	
96-2	9398-9403	could	
96-3	9404-9407	see	
96-4	9408-9412	some	
96-5	9413-9425	long-running	
96-6	9426-9428	or	
96-7	9429-9435	frozen	
96-8	9436-9440	task	
96-9	9441-9444	and	
96-10	9445-9446	a	
96-11	9447-9450	lot	
96-12	9451-9453	of	
96-13	9454-9459	disks	
96-14	9460-9468	spinning	
96-15	9469-9472	and	
96-16	9473-9474	a	
96-17	9475-9479	very	
96-18	9480-9483	low	
96-19	9484-9492	resource	
96-20	9493-9506	authorization	
96-21	9507-9511	rate	
96-22	9512-9514	in	
96-23	9515-9519	most	
96-24	9520-9525	nodes	
96-25	9526-9529	and	
96-26	9530-9534	even	
96-27	9535-9538	out	
96-28	9539-9541	of	
96-29	9542-9548	memory	
96-30	9548-9549	.	

#Text=Our
#Text=Spark community might tell you many different ways to solve such a typical performance problem.
97-1	9550-9553	Our	
97-2	9554-9559	Spark	
97-3	9560-9569	community	
97-4	9570-9575	might	
97-5	9576-9580	tell	
97-6	9581-9584	you	
97-7	9585-9589	many	
97-8	9590-9599	different	
97-9	9600-9604	ways	
97-10	9605-9607	to	
97-11	9608-9613	solve	
97-12	9614-9618	such	
97-13	9619-9620	a	
97-14	9621-9628	typical	
97-15	9629-9640	performance	
97-16	9641-9648	problem	
97-17	9648-9649	.	

#Text=You can find the skew value and the right queries to handle the skew value separately.
98-1	9650-9653	You	
98-2	9654-9657	can	
98-3	9658-9662	find	
98-4	9663-9666	the	
98-5	9667-9671	skew	
98-6	9672-9677	value	
98-7	9678-9681	and	
98-8	9682-9685	the	
98-9	9686-9691	right	
98-10	9692-9699	queries	
98-11	9700-9702	to	
98-12	9703-9709	handle	
98-13	9710-9713	the	
98-14	9714-9718	skew	
98-15	9719-9724	value	
98-16	9725-9735	separately	
98-17	9735-9736	.	

#Text=And also, you can add the actual skew keys that can remove the data skew, either new
#Text=columns or some existing columns.
99-1	9737-9740	And	
99-2	9741-9745	also	
99-3	9745-9746	,	
99-4	9747-9750	you	
99-5	9751-9754	can	
99-6	9755-9758	add	
99-7	9759-9762	the	
99-8	9763-9769	actual	
99-9	9770-9774	skew	
99-10	9775-9779	keys	
99-11	9780-9784	that	
99-12	9785-9788	can	
99-13	9789-9795	remove	
99-14	9796-9799	the	
99-15	9800-9804	data	
99-16	9805-9809	skew	
99-17	9809-9810	,	
99-18	9811-9817	either	
99-19	9818-9821	new	
99-20	9822-9829	columns	
99-21	9830-9832	or	
99-22	9833-9837	some	
99-23	9838-9846	existing	
99-24	9847-9854	columns	
99-25	9854-9855	.	

#Text=Anyway, you have to manually rewrite your queries,
#Text=and this is annoying and sensitive to your workloads, too, which could be changed over
#Text=time.
100-1	9856-9862	Anyway	
100-2	9862-9863	,	
100-3	9864-9867	you	
100-4	9868-9872	have	
100-5	9873-9875	to	
100-6	9876-9884	manually	
100-7	9885-9892	rewrite	
100-8	9893-9897	your	
100-9	9898-9905	queries	
100-10	9905-9906	,	
100-11	9907-9910	and	
100-12	9911-9915	this	
100-13	9916-9918	is	
100-14	9919-9927	annoying	
100-15	9928-9931	and	
100-16	9932-9941	sensitive	
100-17	9942-9944	to	
100-18	9945-9949	your	
100-19	9950-9959	workloads	
100-20	9959-9960	,	
100-21	9961-9964	too	
100-22	9964-9965	,	
100-23	9966-9971	which	
100-24	9972-9977	could	
100-25	9978-9980	be	
100-26	9981-9988	changed	
100-27	9989-9993	over	
100-28	9994-9998	time	
100-29	9998-9999	.	

#Text=This is an example without the skew optimization.
101-1	10000-10004	This	
101-2	10005-10007	is	
101-3	10008-10010	an	
101-4	10011-10018	example	
101-5	10019-10026	without	
101-6	10027-10030	the	
101-7	10031-10035	skew	
101-8	10036-10048	optimization	
101-9	10048-10049	.	

#Text=Because of data skew,
#Text=after the shuffle, the shuffle partition, A0, will be very large.
102-1	10050-10057	Because	
102-2	10058-10060	of	
102-3	10061-10065	data	
102-4	10066-10070	skew	
102-5	10070-10071	,	
102-6	10072-10077	after	
102-7	10078-10081	the	
102-8	10082-10089	shuffle	
102-9	10089-10090	,	
102-10	10091-10094	the	
102-11	10095-10102	shuffle	
102-12	10103-10112	partition	
102-13	10112-10113	,	
102-14	10114-10116	A0	
102-15	10116-10117	,	
102-16	10118-10122	will	
102-17	10123-10125	be	
102-18	10126-10130	very	
102-19	10131-10136	large	
102-20	10136-10137	.	

#Text=If we do a join on
#Text=these two tables, the whole performance bottleneck is to join the values for this specific partition,
#Text=A0.
103-1	10138-10140	If	
103-2	10141-10143	we	
103-3	10144-10146	do	
103-4	10147-10148	a	
103-5	10149-10153	join	
103-6	10154-10156	on	
103-7	10157-10162	these	
103-8	10163-10166	two	
103-9	10167-10173	tables	
103-10	10173-10174	,	
103-11	10175-10178	the	
103-12	10179-10184	whole	
103-13	10185-10196	performance	
103-14	10197-10207	bottleneck	
103-15	10208-10210	is	
103-16	10211-10213	to	
103-17	10214-10218	join	
103-18	10219-10222	the	
103-19	10223-10229	values	
103-20	10230-10233	for	
103-21	10234-10238	this	
103-22	10239-10247	specific	
103-23	10248-10257	partition	
103-24	10257-10258	,	
103-25	10259-10261	A0	
103-26	10261-10262	.	

#Text=For this partition, A0, the cost of shuffle, sort, and merge are much bigger than the other
#Text=partitions.
104-1	10263-10266	For	
104-2	10267-10271	this	
104-3	10272-10281	partition	
104-4	10281-10282	,	
104-5	10283-10285	A0	
104-6	10285-10286	,	
104-7	10287-10290	the	
104-8	10291-10295	cost	
104-9	10296-10298	of	
104-10	10299-10306	shuffle	
104-11	10306-10307	,	
104-12	10308-10312	sort	
104-13	10312-10313	,	
104-14	10314-10317	and	
104-15	10318-10323	merge	
104-16	10324-10327	are	
104-17	10328-10332	much	
104-18	10333-10339	bigger	
104-19	10340-10344	than	
104-20	10345-10348	the	
104-21	10349-10354	other	
104-22	10355-10365	partitions	
104-23	10365-10366	.	

#Text=Everyone is waiting for the partition 0 to complete and slow down the execution
#Text=of the whole query.
105-1	10367-10375	Everyone	
105-2	10376-10378	is	
105-3	10379-10386	waiting	
105-4	10387-10390	for	
105-5	10391-10394	the	
105-6	10395-10404	partition	
105-7	10405-10406	0	
105-8	10407-10409	to	
105-9	10410-10418	complete	
105-10	10419-10422	and	
105-11	10423-10427	slow	
105-12	10428-10432	down	
105-13	10433-10436	the	
105-14	10437-10446	execution	
105-15	10447-10449	of	
105-16	10450-10453	the	
105-17	10454-10459	whole	
105-18	10460-10465	query	
105-19	10465-10466	.	

#Text=Our adaptive query execution can handle it very well in the data skew case.
106-1	10467-10470	Our	
106-2	10471-10479	adaptive	
106-3	10480-10485	query	
106-4	10486-10495	execution	
106-5	10496-10499	can	
106-6	10500-10506	handle	
106-7	10507-10509	it	
106-8	10510-10514	very	
106-9	10515-10519	well	
106-10	10520-10522	in	
106-11	10523-10526	the	
106-12	10527-10531	data	
106-13	10532-10536	skew	
106-14	10537-10541	case	
106-15	10541-10542	.	

#Text=After executing the leaf stages (stages one and stage two), we can optimize our queries
#Text=with a skew shuffle reader.
107-1	10543-10548	After	
107-2	10549-10558	executing	
107-3	10559-10562	the	
107-4	10563-10567	leaf	
107-5	10568-10574	stages	
107-6	10575-10576	(	
107-7	10576-10582	stages	
107-8	10583-10586	one	
107-9	10587-10590	and	
107-10	10591-10596	stage	
107-11	10597-10600	two	
107-12	10600-10601	)	
107-13	10601-10602	,	
107-14	10603-10605	we	
107-15	10606-10609	can	
107-16	10610-10618	optimize	
107-17	10619-10622	our	
107-18	10623-10630	queries	
107-19	10631-10635	with	
107-20	10636-10637	a	
107-21	10638-10642	skew	
107-22	10643-10650	shuffle	
107-23	10651-10657	reader	
107-24	10657-10658	.	

#Text=Basically, it will split the skew partitions into smaller
#Text=subpartitions after we realize some shuffle partitions are too big.
108-1	10659-10668	Basically	
108-2	10668-10669	,	
108-3	10670-10672	it	
108-4	10673-10677	will	
108-5	10678-10683	split	
108-6	10684-10687	the	
108-7	10688-10692	skew	
108-8	10693-10703	partitions	
108-9	10704-10708	into	
108-10	10709-10716	smaller	
108-11	10717-10730	subpartitions	
108-12	10731-10736	after	
108-13	10737-10739	we	
108-14	10740-10747	realize	
108-15	10748-10752	some	
108-16	10753-10760	shuffle	
108-17	10761-10771	partitions	
108-18	10772-10775	are	
108-19	10776-10779	too	
108-20	10780-10783	big	
108-21	10783-10784	.	

#Text=Let us use same example to show how to resolve it using adaptive query
#Text=execution.
109-1	10785-10788	Let	
109-2	10789-10791	us	
109-3	10792-10795	use	
109-4	10796-10800	same	
109-5	10801-10808	example	
109-6	10809-10811	to	
109-7	10812-10816	show	
109-8	10817-10820	how	
109-9	10821-10823	to	
109-10	10824-10831	resolve	
109-11	10832-10834	it	
109-12	10835-10840	using	
109-13	10841-10849	adaptive	
109-14	10850-10855	query	
109-15	10856-10865	execution	
109-16	10865-10866	.	

#Text=After realizing partitions are too large, AQE will add a skew reader to automatically
#Text=split table A’s partition part 0 to three segments: split 0, split 1, and split 2.
110-1	10867-10872	After	
110-2	10873-10882	realizing	
110-3	10883-10893	partitions	
110-4	10894-10897	are	
110-5	10898-10901	too	
110-6	10902-10907	large	
110-7	10907-10908	,	
110-8	10909-10912	AQE	
110-9	10913-10917	will	
110-10	10918-10921	add	
110-11	10922-10923	a	
110-12	10924-10928	skew	
110-13	10929-10935	reader	
110-14	10936-10938	to	
110-15	10939-10952	automatically	
110-16	10953-10958	split	
110-17	10959-10964	table	
110-18	10965-10966	A	
110-19	10966-10967	’	
110-20	10967-10968	s	
110-21	10969-10978	partition	
110-22	10979-10983	part	
110-23	10984-10985	0	
110-24	10986-10988	to	
110-25	10989-10994	three	
110-26	10995-11003	segments	
110-27	11003-11004	:	
110-28	11005-11010	split	
110-29	11011-11012	0	
110-30	11012-11013	,	
110-31	11014-11019	split	
110-32	11020-11021	1	
110-33	11021-11022	,	
110-34	11023-11026	and	
110-35	11027-11032	split	
110-36	11033-11034	2	
110-37	11034-11035	.	

#Text=Then
#Text=it will also duplicate another side for table B.
111-1	11036-11040	Then	
111-2	11041-11043	it	
111-3	11044-11048	will	
111-4	11049-11053	also	
111-5	11054-11063	duplicate	
111-6	11064-11071	another	
111-7	11072-11076	side	
111-8	11077-11080	for	
111-9	11081-11086	table	
111-10	11087-11088	B	
111-11	11088-11089	.	

#Text=Then we will have three copies for table
#Text=B’s part 0.
112-1	11090-11094	Then	
112-2	11095-11097	we	
112-3	11098-11102	will	
112-4	11103-11107	have	
112-5	11108-11113	three	
112-6	11114-11120	copies	
112-7	11121-11124	for	
112-8	11125-11130	table	
112-9	11131-11132	B	
112-10	11132-11133	’	
112-11	11133-11134	s	
112-12	11135-11139	part	
112-13	11140-11141	0	
112-14	11141-11142	.	

#Text=After this step, we can parallelize the shuffle reading, sorting, merging for
#Text=this split partition A0.
113-1	11143-11148	After	
113-2	11149-11153	this	
113-3	11154-11158	step	
113-4	11158-11159	,	
113-5	11160-11162	we	
113-6	11163-11166	can	
113-7	11167-11178	parallelize	
113-8	11179-11182	the	
113-9	11183-11190	shuffle	
113-10	11191-11198	reading	
113-11	11198-11199	,	
113-12	11200-11207	sorting	
113-13	11207-11208	,	
113-14	11209-11216	merging	
113-15	11217-11220	for	
113-16	11221-11225	this	
113-17	11226-11231	split	
113-18	11232-11241	partition	
113-19	11242-11244	A0	
113-20	11244-11245	.	

#Text=We can avoid generating very big partition for the sort merge join.
114-1	11246-11248	We	
114-2	11249-11252	can	
114-3	11253-11258	avoid	
114-4	11259-11269	generating	
114-5	11270-11274	very	
114-6	11275-11278	big	
114-7	11279-11288	partition	
114-8	11289-11292	for	
114-9	11293-11296	the	
114-10	11297-11301	sort	
114-11	11302-11307	merge	
114-12	11308-11312	join	
114-13	11312-11313	.	

#Text=Overall, it will be much faster.
115-1	11314-11321	Overall	
115-2	11321-11322	,	
115-3	11323-11325	it	
115-4	11326-11330	will	
115-5	11331-11333	be	
115-6	11334-11338	much	
115-7	11339-11345	faster	
115-8	11345-11346	.	

#Text=Based on a terabyte of TPC-DS benchmark, without statistics, Spark 3.0 can make Q7 eight times faster and also achieve two times fast
#Text=and speed up for Q5 and more than 1.1 speed up for another 26 queries.
116-1	11347-11352	Based	
116-2	11353-11355	on	
116-3	11356-11357	a	
116-4	11358-11366	terabyte	
116-5	11367-11369	of	
116-6	11370-11376	TPC-DS	
116-7	11377-11386	benchmark	
116-8	11386-11387	,	
116-9	11388-11395	without	
116-10	11396-11406	statistics	
116-11	11406-11407	,	
116-12	11408-11413	Spark	
116-13	11414-11417	3.0	
116-14	11418-11421	can	
116-15	11422-11426	make	
116-16	11427-11429	Q7	
116-17	11430-11435	eight	
116-18	11436-11441	times	
116-19	11442-11448	faster	
116-20	11449-11452	and	
116-21	11453-11457	also	
116-22	11458-11465	achieve	
116-23	11466-11469	two	
116-24	11470-11475	times	
116-25	11476-11480	fast	
116-26	11481-11484	and	
116-27	11485-11490	speed	
116-28	11491-11493	up	
116-29	11494-11497	for	
116-30	11498-11500	Q5	
116-31	11501-11504	and	
116-32	11505-11509	more	
116-33	11510-11514	than	
116-34	11515-11518	1.1	
116-35	11519-11524	speed	
116-36	11525-11527	up	
116-37	11528-11531	for	
116-38	11532-11539	another	
116-39	11540-11542	26	
116-40	11543-11550	queries	
116-41	11550-11551	.	

#Text=So this is just
#Text=the beginning.
117-1	11552-11554	So	
117-2	11555-11559	this	
117-3	11560-11562	is	
117-4	11563-11567	just	
117-5	11568-11571	the	
117-6	11572-11581	beginning	
117-7	11581-11582	.	

#Text=In the future releases, we will continue to improve the compiler and
#Text=introduce more new adaptive rules.
118-1	11583-11585	In	
118-2	11586-11589	the	
118-3	11590-11596	future	
118-4	11597-11605	releases	
118-5	11605-11606	,	
118-6	11607-11609	we	
118-7	11610-11614	will	
118-8	11615-11623	continue	
118-9	11624-11626	to	
118-10	11627-11634	improve	
118-11	11635-11638	the	
118-12	11639-11647	compiler	
118-13	11648-11651	and	
118-14	11652-11661	introduce	
118-15	11662-11666	more	
118-16	11667-11670	new	
118-17	11671-11679	adaptive	
118-18	11680-11685	rules	
118-19	11685-11686	.	

#Text=Dynamic Partition Pruning
#Text=The second performance features I want to highlight is dynamic partition pruning.
119-1	11687-11694	Dynamic	
119-2	11695-11704	Partition	
119-3	11705-11712	Pruning	
119-4	11713-11716	The	
119-5	11717-11723	second	
119-6	11724-11735	performance	
119-7	11736-11744	features	
119-8	11745-11746	I	
119-9	11747-11751	want	
119-10	11752-11754	to	
119-11	11755-11764	highlight	
119-12	11765-11767	is	
119-13	11768-11775	dynamic	
119-14	11776-11785	partition	
119-15	11786-11793	pruning	
119-16	11793-11794	.	

#Text=So this is another runtime optimization rule.
120-1	11795-11797	So	
120-2	11798-11802	this	
120-3	11803-11805	is	
120-4	11806-11813	another	
120-5	11814-11821	runtime	
120-6	11822-11834	optimization	
120-7	11835-11839	rule	
120-8	11839-11840	.	

#Text=Basically, dynamic partition pruning is to
#Text=avoid partition scanning based on the queried results of the other query fragments.
121-1	11841-11850	Basically	
121-2	11850-11851	,	
121-3	11852-11859	dynamic	
121-4	11860-11869	partition	
121-5	11870-11877	pruning	
121-6	11878-11880	is	
121-7	11881-11883	to	
121-8	11884-11889	avoid	
121-9	11890-11899	partition	
121-10	11900-11908	scanning	
121-11	11909-11914	based	
121-12	11915-11917	on	
121-13	11918-11921	the	
121-14	11922-11929	queried	
121-15	11930-11937	results	
121-16	11938-11940	of	
121-17	11941-11944	the	
121-18	11945-11950	other	
121-19	11951-11956	query	
121-20	11957-11966	fragments	
121-21	11966-11967	.	

#Text=It is
#Text=important for star schema queries.
122-1	11968-11970	It	
122-2	11971-11973	is	
122-3	11974-11983	important	
122-4	11984-11987	for	
122-5	11988-11992	star	
122-6	11993-11999	schema	
122-7	12000-12007	queries	
122-8	12007-12008	.	

#Text=We can achieve a significant speed up in TPC-DS
#Text=queries.
123-1	12009-12011	We	
123-2	12012-12015	can	
123-3	12016-12023	achieve	
123-4	12024-12025	a	
123-5	12026-12037	significant	
123-6	12038-12043	speed	
123-7	12044-12046	up	
123-8	12047-12049	in	
123-9	12050-12056	TPC-DS	
123-10	12057-12064	queries	
123-11	12064-12065	.	

#Text=So this is a number, in a TPC-DS benchmark, 60 out of 102 queries show a significant
#Text=speed up between 2 times and 18 times.
124-1	12066-12068	So	
124-2	12069-12073	this	
124-3	12074-12076	is	
124-4	12077-12078	a	
124-5	12079-12085	number	
124-6	12085-12086	,	
124-7	12087-12089	in	
124-8	12090-12091	a	
124-9	12092-12098	TPC-DS	
124-10	12099-12108	benchmark	
124-11	12108-12109	,	
124-12	12110-12112	60	
124-13	12113-12116	out	
124-14	12117-12119	of	
124-15	12120-12123	102	
124-16	12124-12131	queries	
124-17	12132-12136	show	
124-18	12137-12138	a	
124-19	12139-12150	significant	
124-20	12151-12156	speed	
124-21	12157-12159	up	
124-22	12160-12167	between	
124-23	12168-12169	2	
124-24	12170-12175	times	
124-25	12176-12179	and	
124-26	12180-12182	18	
124-27	12183-12188	times	
124-28	12188-12189	.	

#Text=It is to prune the partitions that joins read
#Text=from the fact table T1 by identifying those partitions that result from filtering the
#Text=dimension table, T2.
125-1	12190-12192	It	
125-2	12193-12195	is	
125-3	12196-12198	to	
125-4	12199-12204	prune	
125-5	12205-12208	the	
125-6	12209-12219	partitions	
125-7	12220-12224	that	
125-8	12225-12230	joins	
125-9	12231-12235	read	
125-10	12236-12240	from	
125-11	12241-12244	the	
125-12	12245-12249	fact	
125-13	12250-12255	table	
125-14	12256-12258	T1	
125-15	12259-12261	by	
125-16	12262-12273	identifying	
125-17	12274-12279	those	
125-18	12280-12290	partitions	
125-19	12291-12295	that	
125-20	12296-12302	result	
125-21	12303-12307	from	
125-22	12308-12317	filtering	
125-23	12318-12321	the	
125-24	12322-12331	dimension	
125-25	12332-12337	table	
125-26	12337-12338	,	
125-27	12339-12341	T2	
125-28	12341-12342	.	

#Text=Let us explain it step by step.
126-1	12343-12346	Let	
126-2	12347-12349	us	
126-3	12350-12357	explain	
126-4	12358-12360	it	
126-5	12361-12365	step	
126-6	12366-12368	by	
126-7	12369-12373	step	
126-8	12373-12374	.	

#Text=First, we will do the filter push down
#Text=in the left side.
127-1	12375-12380	First	
127-2	12380-12381	,	
127-3	12382-12384	we	
127-4	12385-12389	will	
127-5	12390-12392	do	
127-6	12393-12396	the	
127-7	12397-12403	filter	
127-8	12404-12408	push	
127-9	12409-12413	down	
127-10	12414-12416	in	
127-11	12417-12420	the	
127-12	12421-12425	left	
127-13	12426-12430	side	
127-14	12430-12431	.	

#Text=And on the right side, we can generate a new filter for the partition
#Text=column PP because join P is a partition column.
128-1	12432-12435	And	
128-2	12436-12438	on	
128-3	12439-12442	the	
128-4	12443-12448	right	
128-5	12449-12453	side	
128-6	12453-12454	,	
128-7	12455-12457	we	
128-8	12458-12461	can	
128-9	12462-12470	generate	
128-10	12471-12472	a	
128-11	12473-12476	new	
128-12	12477-12483	filter	
128-13	12484-12487	for	
128-14	12488-12491	the	
128-15	12492-12501	partition	
128-16	12502-12508	column	
128-17	12509-12511	PP	
128-18	12512-12519	because	
128-19	12520-12524	join	
128-20	12525-12526	P	
128-21	12527-12529	is	
128-22	12530-12531	a	
128-23	12532-12541	partition	
128-24	12542-12548	column	
128-25	12548-12549	.	

#Text=Then we get the query results of the left
#Text=side.
129-1	12550-12554	Then	
129-2	12555-12557	we	
129-3	12558-12561	get	
129-4	12562-12565	the	
129-5	12566-12571	query	
129-6	12572-12579	results	
129-7	12580-12582	of	
129-8	12583-12586	the	
129-9	12587-12591	left	
129-10	12592-12596	side	
129-11	12596-12597	.	

#Text=We can reuse our query results and generate the lists of constant values, EPP, and filter
#Text=result.
130-1	12598-12600	We	
130-2	12601-12604	can	
130-3	12605-12610	reuse	
130-4	12611-12614	our	
130-5	12615-12620	query	
130-6	12621-12628	results	
130-7	12629-12632	and	
130-8	12633-12641	generate	
130-9	12642-12645	the	
130-10	12646-12651	lists	
130-11	12652-12654	of	
130-12	12655-12663	constant	
130-13	12664-12670	values	
130-14	12670-12671	,	
130-15	12672-12675	EPP	
130-16	12675-12676	,	
130-17	12677-12680	and	
130-18	12681-12687	filter	
130-19	12688-12694	result	
130-20	12694-12695	.	

#Text=Now, we can push down the in filter in the right side.
131-1	12696-12699	Now	
131-2	12699-12700	,	
131-3	12701-12703	we	
131-4	12704-12707	can	
131-5	12708-12712	push	
131-6	12713-12717	down	
131-7	12718-12721	the	
131-8	12722-12724	in	
131-9	12725-12731	filter	
131-10	12732-12734	in	
131-11	12735-12738	the	
131-12	12739-12744	right	
131-13	12745-12749	side	
131-14	12749-12750	.	

#Text=This will avoid scanning
#Text=all the partitions of the huge fact table, T1.
132-1	12751-12755	This	
132-2	12756-12760	will	
132-3	12761-12766	avoid	
132-4	12767-12775	scanning	
132-5	12776-12779	all	
132-6	12780-12783	the	
132-7	12784-12794	partitions	
132-8	12795-12797	of	
132-9	12798-12801	the	
132-10	12802-12806	huge	
132-11	12807-12811	fact	
132-12	12812-12817	table	
132-13	12817-12818	,	
132-14	12819-12821	T1	
132-15	12821-12822	.	

#Text=For this example, we can avoid scanning
#Text=90% of partitioning.
133-1	12823-12826	For	
133-2	12827-12831	this	
133-3	12832-12839	example	
133-4	12839-12840	,	
133-5	12841-12843	we	
133-6	12844-12847	can	
133-7	12848-12853	avoid	
133-8	12854-12862	scanning	
133-9	12863-12866	90%	
133-10	12867-12869	of	
133-11	12870-12882	partitioning	
133-12	12882-12883	.	

#Text=With this dynamic partition pruning, we can achieve 33 times speed up.
134-1	12884-12888	With	
134-2	12889-12893	this	
134-3	12894-12901	dynamic	
134-4	12902-12911	partition	
134-5	12912-12919	pruning	
134-6	12919-12920	,	
134-7	12921-12923	we	
134-8	12924-12927	can	
134-9	12928-12935	achieve	
134-10	12936-12938	33	
134-11	12939-12944	times	
134-12	12945-12950	speed	
134-13	12951-12953	up	
134-14	12953-12954	.	

#Text=JOIN Optimizer Hints
#Text=So the last performance feature is join hints.
135-1	12955-12959	JOIN	
135-2	12960-12969	Optimizer	
135-3	12970-12975	Hints	
135-4	12976-12978	So	
135-5	12979-12982	the	
135-6	12983-12987	last	
135-7	12988-12999	performance	
135-8	13000-13007	feature	
135-9	13008-13010	is	
135-10	13011-13015	join	
135-11	13016-13021	hints	
135-12	13021-13022	.	

#Text=Join hints are very common
#Text=optimizer hints.
136-1	13023-13027	Join	
136-2	13028-13033	hints	
136-3	13034-13037	are	
136-4	13038-13042	very	
136-5	13043-13049	common	
136-6	13050-13059	optimizer	
136-7	13060-13065	hints	
136-8	13065-13066	.	

#Text=It can influence the optimizer to choose an expected join strategies.
137-1	13067-13069	It	
137-2	13070-13073	can	
137-3	13074-13083	influence	
137-4	13084-13087	the	
137-5	13088-13097	optimizer	
137-6	13098-13100	to	
137-7	13101-13107	choose	
137-8	13108-13110	an	
137-9	13111-13119	expected	
137-10	13120-13124	join	
137-11	13125-13135	strategies	
137-12	13135-13136	.	

#Text=Previously,
#Text=we already have a broadcast hash join.
138-1	13137-13147	Previously	
138-2	13147-13148	,	
138-3	13149-13151	we	
138-4	13152-13159	already	
138-5	13160-13164	have	
138-6	13165-13166	a	
138-7	13167-13176	broadcast	
138-8	13177-13181	hash	
138-9	13182-13186	join	
138-10	13186-13187	.	

#Text=In this release, we also add the hints for the
#Text=other three join strategies: sort merge join, shuffle hash join, and the shuffle nested
#Text=loop join.
139-1	13188-13190	In	
139-2	13191-13195	this	
139-3	13196-13203	release	
139-4	13203-13204	,	
139-5	13205-13207	we	
139-6	13208-13212	also	
139-7	13213-13216	add	
139-8	13217-13220	the	
139-9	13221-13226	hints	
139-10	13227-13230	for	
139-11	13231-13234	the	
139-12	13235-13240	other	
139-13	13241-13246	three	
139-14	13247-13251	join	
139-15	13252-13262	strategies	
139-16	13262-13263	:	
139-17	13264-13268	sort	
139-18	13269-13274	merge	
139-19	13275-13279	join	
139-20	13279-13280	,	
139-21	13281-13288	shuffle	
139-22	13289-13293	hash	
139-23	13294-13298	join	
139-24	13298-13299	,	
139-25	13300-13303	and	
139-26	13304-13307	the	
139-27	13308-13315	shuffle	
139-28	13316-13322	nested	
139-29	13323-13327	loop	
139-30	13328-13332	join	
139-31	13332-13333	.	

#Text=Please remember, this should be used very carefully.
140-1	13334-13340	Please	
140-2	13341-13349	remember	
140-3	13349-13350	,	
140-4	13351-13355	this	
140-5	13356-13362	should	
140-6	13363-13365	be	
140-7	13366-13370	used	
140-8	13371-13375	very	
140-9	13376-13385	carefully	
140-10	13385-13386	.	

#Text=It is difficult to manage
#Text=over time because it is sensitive to your workloads.
141-1	13387-13389	It	
141-2	13390-13392	is	
141-3	13393-13402	difficult	
141-4	13403-13405	to	
141-5	13406-13412	manage	
141-6	13413-13417	over	
141-7	13418-13422	time	
141-8	13423-13430	because	
141-9	13431-13433	it	
141-10	13434-13436	is	
141-11	13437-13446	sensitive	
141-12	13447-13449	to	
141-13	13450-13454	your	
141-14	13455-13464	workloads	
141-15	13464-13465	.	

#Text=If your workloads’ patterns are
#Text=not stable, the hint could even make your query much slower.
142-1	13466-13468	If	
142-2	13469-13473	your	
142-3	13474-13483	workloads	
142-4	13483-13484	’	
142-5	13485-13493	patterns	
142-6	13494-13497	are	
142-7	13498-13501	not	
142-8	13502-13508	stable	
142-9	13508-13509	,	
142-10	13510-13513	the	
142-11	13514-13518	hint	
142-12	13519-13524	could	
142-13	13525-13529	even	
142-14	13530-13534	make	
142-15	13535-13539	your	
142-16	13540-13545	query	
142-17	13546-13550	much	
142-18	13551-13557	slower	
142-19	13557-13558	.	

#Text=Here are examples how to
#Text=use these hints in the SQL queries.
143-1	13559-13563	Here	
143-2	13564-13567	are	
143-3	13568-13576	examples	
143-4	13577-13580	how	
143-5	13581-13583	to	
143-6	13584-13587	use	
143-7	13588-13593	these	
143-8	13594-13599	hints	
143-9	13600-13602	in	
143-10	13603-13606	the	
143-11	13607-13610	SQL	
143-12	13611-13618	queries	
143-13	13618-13619	.	

#Text=You also can do the same thing in the DataFrame API.
144-1	13620-13623	You	
144-2	13624-13628	also	
144-3	13629-13632	can	
144-4	13633-13635	do	
144-5	13636-13639	the	
144-6	13640-13644	same	
144-7	13645-13650	thing	
144-8	13651-13653	in	
144-9	13654-13657	the	
144-10	13658-13667	DataFrame	
144-11	13668-13671	API	
144-12	13671-13672	.	

#Text=When we decide the join strategies, [our leads are different here?].
145-1	13673-13677	When	
145-2	13678-13680	we	
145-3	13681-13687	decide	
145-4	13688-13691	the	
145-5	13692-13696	join	
145-6	13697-13707	strategies	
145-7	13707-13708	,	
145-8	13709-13710	[	
145-9	13710-13713	our	
145-10	13714-13719	leads	
145-11	13720-13723	are	
145-12	13724-13733	different	
145-13	13734-13738	here	
145-14	13738-13739	?	
145-15	13739-13740	]	
145-16	13740-13741	.	

#Text=So a broadcast
#Text=hash join requires one side to be small, no shuffle, no sort, so it performs very fast.
146-1	13742-13744	So	
146-2	13745-13746	a	
146-3	13747-13756	broadcast	
146-4	13757-13761	hash	
146-5	13762-13766	join	
146-6	13767-13775	requires	
146-7	13776-13779	one	
146-8	13780-13784	side	
146-9	13785-13787	to	
146-10	13788-13790	be	
146-11	13791-13796	small	
146-12	13796-13797	,	
146-13	13798-13800	no	
146-14	13801-13808	shuffle	
146-15	13808-13809	,	
146-16	13810-13812	no	
146-17	13813-13817	sort	
146-18	13817-13818	,	
146-19	13819-13821	so	
146-20	13822-13824	it	
146-21	13825-13833	performs	
146-22	13834-13838	very	
146-23	13839-13843	fast	
146-24	13843-13844	.	

#Text=For the shuffle hash join, it needs to shuffle the data but no sort is needed.
147-1	13845-13848	For	
147-2	13849-13852	the	
147-3	13853-13860	shuffle	
147-4	13861-13865	hash	
147-5	13866-13870	join	
147-6	13870-13871	,	
147-7	13872-13874	it	
147-8	13875-13880	needs	
147-9	13881-13883	to	
147-10	13884-13891	shuffle	
147-11	13892-13895	the	
147-12	13896-13900	data	
147-13	13901-13904	but	
147-14	13905-13907	no	
147-15	13908-13912	sort	
147-16	13913-13915	is	
147-17	13916-13922	needed	
147-18	13922-13923	.	

#Text=So it can
#Text=handle the large tables but will still hit out of memory if the data is skewed.
148-1	13924-13926	So	
148-2	13927-13929	it	
148-3	13930-13933	can	
148-4	13934-13940	handle	
148-5	13941-13944	the	
148-6	13945-13950	large	
148-7	13951-13957	tables	
148-8	13958-13961	but	
148-9	13962-13966	will	
148-10	13967-13972	still	
148-11	13973-13976	hit	
148-12	13977-13980	out	
148-13	13981-13983	of	
148-14	13984-13990	memory	
148-15	13991-13993	if	
148-16	13994-13997	the	
148-17	13998-14002	data	
148-18	14003-14005	is	
148-19	14006-14012	skewed	
148-20	14012-14013	.	

#Text=Sort
#Text=merge join is much more robust.
149-1	14014-14018	Sort	
149-2	14019-14024	merge	
149-3	14025-14029	join	
149-4	14030-14032	is	
149-5	14033-14037	much	
149-6	14038-14042	more	
149-7	14043-14049	robust	
149-8	14049-14050	.	

#Text=It can handle any data size.
150-1	14051-14053	It	
150-2	14054-14057	can	
150-3	14058-14064	handle	
150-4	14065-14068	any	
150-5	14069-14073	data	
150-6	14074-14078	size	
150-7	14078-14079	.	

#Text=It needs to shuffle and salt
#Text=data slower in most cases when the table size is small compared with a broadcast hash join.
151-1	14080-14082	It	
151-2	14083-14088	needs	
151-3	14089-14091	to	
151-4	14092-14099	shuffle	
151-5	14100-14103	and	
151-6	14104-14108	salt	
151-7	14109-14113	data	
151-8	14114-14120	slower	
151-9	14121-14123	in	
151-10	14124-14128	most	
151-11	14129-14134	cases	
151-12	14135-14139	when	
151-13	14140-14143	the	
151-14	14144-14149	table	
151-15	14150-14154	size	
151-16	14155-14157	is	
151-17	14158-14163	small	
151-18	14164-14172	compared	
151-19	14173-14177	with	
151-20	14178-14179	a	
151-21	14180-14189	broadcast	
151-22	14190-14194	hash	
151-23	14195-14199	join	
151-24	14199-14200	.	

#Text=And also, shuffle nested loop join, it doesn’t require the join keys, unlike the other three
#Text=join strategies.
152-1	14201-14204	And	
152-2	14205-14209	also	
152-3	14209-14210	,	
152-4	14211-14218	shuffle	
152-5	14219-14225	nested	
152-6	14226-14230	loop	
152-7	14231-14235	join	
152-8	14235-14236	,	
152-9	14237-14239	it	
152-10	14240-14245	doesn	
152-11	14245-14246	’	
152-12	14246-14247	t	
152-13	14248-14255	require	
152-14	14256-14259	the	
152-15	14260-14264	join	
152-16	14265-14269	keys	
152-17	14269-14270	,	
152-18	14271-14277	unlike	
152-19	14278-14281	the	
152-20	14282-14287	other	
152-21	14288-14293	three	
152-22	14294-14298	join	
152-23	14299-14309	strategies	
152-24	14309-14310	.	

#Text=Richer APIs: new features and simplify development
#Text=To enable new use cases and simplify the Spark application development,
#Text=this release delivers a new capability and enhanced interesting features.
153-1	14311-14317	Richer	
153-2	14318-14322	APIs	
153-3	14322-14323	:	
153-4	14324-14327	new	
153-5	14328-14336	features	
153-6	14337-14340	and	
153-7	14341-14349	simplify	
153-8	14350-14361	development	
153-9	14362-14364	To	
153-10	14365-14371	enable	
153-11	14372-14375	new	
153-12	14376-14379	use	
153-13	14380-14385	cases	
153-14	14386-14389	and	
153-15	14390-14398	simplify	
153-16	14399-14402	the	
153-17	14403-14408	Spark	
153-18	14409-14420	application	
153-19	14421-14432	development	
153-20	14432-14433	,	
153-21	14434-14438	this	
153-22	14439-14446	release	
153-23	14447-14455	delivers	
153-24	14456-14457	a	
153-25	14458-14461	new	
153-26	14462-14472	capability	
153-27	14473-14476	and	
153-28	14477-14485	enhanced	
153-29	14486-14497	interesting	
153-30	14498-14506	features	
153-31	14506-14507	.	

#Text=Pandas UDF
#Text=Let’s, first,
#Text=talk about Pandas UDF.
154-1	14508-14514	Pandas	
154-2	14515-14518	UDF	
154-3	14519-14522	Let	
154-4	14522-14523	’	
154-5	14523-14524	s	
154-6	14524-14525	,	
154-7	14526-14531	first	
154-8	14531-14532	,	
154-9	14533-14537	talk	
154-10	14538-14543	about	
154-11	14544-14550	Pandas	
154-12	14551-14554	UDF	
154-13	14554-14555	.	

#Text=This is a pretty popular performance features for the PySpark users.
155-1	14556-14560	This	
155-2	14561-14563	is	
155-3	14564-14565	a	
155-4	14566-14572	pretty	
155-5	14573-14580	popular	
155-6	14581-14592	performance	
155-7	14593-14601	features	
155-8	14602-14605	for	
155-9	14606-14609	the	
155-10	14610-14617	PySpark	
155-11	14618-14623	users	
155-12	14623-14624	.	

#Text=So let us talk about the history of UDF support in PySpark.
156-1	14625-14627	So	
156-2	14628-14631	let	
156-3	14632-14634	us	
156-4	14635-14639	talk	
156-5	14640-14645	about	
156-6	14646-14649	the	
156-7	14650-14657	history	
156-8	14658-14660	of	
156-9	14661-14664	UDF	
156-10	14665-14672	support	
156-11	14673-14675	in	
156-12	14676-14683	PySpark	
156-13	14683-14684	.	

#Text=In the first release of Python
#Text=support, 2013, we already support Python lambda functions for RDD API.
157-1	14685-14687	In	
157-2	14688-14691	the	
157-3	14692-14697	first	
157-4	14698-14705	release	
157-5	14706-14708	of	
157-6	14709-14715	Python	
157-7	14716-14723	support	
157-8	14723-14724	,	
157-9	14725-14729	2013	
157-10	14729-14730	,	
157-11	14731-14733	we	
157-12	14734-14741	already	
157-13	14742-14749	support	
157-14	14750-14756	Python	
157-15	14757-14763	lambda	
157-16	14764-14773	functions	
157-17	14774-14777	for	
157-18	14778-14781	RDD	
157-19	14782-14785	API	
157-20	14785-14786	.	

#Text=Then in 2014, users
#Text=can register Python UDF for Spark SQL.
158-1	14787-14791	Then	
158-2	14792-14794	in	
158-3	14795-14799	2014	
158-4	14799-14800	,	
158-5	14801-14806	users	
158-6	14807-14810	can	
158-7	14811-14819	register	
158-8	14820-14826	Python	
158-9	14827-14830	UDF	
158-10	14831-14834	for	
158-11	14835-14840	Spark	
158-12	14841-14844	SQL	
158-13	14844-14845	.	

#Text=Starting from Spark 2.0, Python UDF registration is
#Text=session-based.
159-1	14846-14854	Starting	
159-2	14855-14859	from	
159-3	14860-14865	Spark	
159-4	14866-14869	2.0	
159-5	14869-14870	,	
159-6	14871-14877	Python	
159-7	14878-14881	UDF	
159-8	14882-14894	registration	
159-9	14895-14897	is	
159-10	14898-14911	session-based	
159-11	14911-14912	.	

#Text=And then next year, users can register the use of Java UDF in Python API.
160-1	14913-14916	And	
160-2	14917-14921	then	
160-3	14922-14926	next	
160-4	14927-14931	year	
160-5	14931-14932	,	
160-6	14933-14938	users	
160-7	14939-14942	can	
160-8	14943-14951	register	
160-9	14952-14955	the	
160-10	14956-14959	use	
160-11	14960-14962	of	
160-12	14963-14967	Java	
160-13	14968-14971	UDF	
160-14	14972-14974	in	
160-15	14975-14981	Python	
160-16	14982-14985	API	
160-17	14985-14986	.	

#Text=In 2018, we introduced Pandas UDF.
161-1	14987-14989	In	
161-2	14990-14994	2018	
161-3	14994-14995	,	
161-4	14996-14998	we	
161-5	14999-15009	introduced	
161-6	15010-15016	Pandas	
161-7	15017-15020	UDF	
161-8	15020-15021	.	

#Text=In this release, we redesigned the interface for Pandas
#Text=UDF by using the Python tab hints and added more tabs for the Pandas UDFs.
162-1	15022-15024	In	
162-2	15025-15029	this	
162-3	15030-15037	release	
162-4	15037-15038	,	
162-5	15039-15041	we	
162-6	15042-15052	redesigned	
162-7	15053-15056	the	
162-8	15057-15066	interface	
162-9	15067-15070	for	
162-10	15071-15077	Pandas	
162-11	15078-15081	UDF	
162-12	15082-15084	by	
162-13	15085-15090	using	
162-14	15091-15094	the	
162-15	15095-15101	Python	
162-16	15102-15105	tab	
162-17	15106-15111	hints	
162-18	15112-15115	and	
162-19	15116-15121	added	
162-20	15122-15126	more	
162-21	15127-15131	tabs	
162-22	15132-15135	for	
162-23	15136-15139	the	
162-24	15140-15146	Pandas	
162-25	15147-15151	UDFs	
162-26	15151-15152	.	

#Text=To adjust our compatibility with the old Pandas UDFs from Apache Spark 2.0
#Text=with the Python 2.6 and above, Python [inaudible] such as pandas.Series, Pandas DataFrame, cube
#Text=hole, and the iterator can be used to impress new Pandas UDF types.
163-1	15153-15155	To	
163-2	15156-15162	adjust	
163-3	15163-15166	our	
163-4	15167-15180	compatibility	
163-5	15181-15185	with	
163-6	15186-15189	the	
163-7	15190-15193	old	
163-8	15194-15200	Pandas	
163-9	15201-15205	UDFs	
163-10	15206-15210	from	
163-11	15211-15217	Apache	
163-12	15218-15223	Spark	
163-13	15224-15227	2.0	
163-14	15228-15232	with	
163-15	15233-15236	the	
163-16	15237-15243	Python	
163-17	15244-15247	2.6	
163-18	15248-15251	and	
163-19	15252-15257	above	
163-20	15257-15258	,	
163-21	15259-15265	Python	
163-22	15266-15267	[	
163-23	15267-15276	inaudible	
163-24	15276-15277	]	
163-25	15278-15282	such	
163-26	15283-15285	as	
163-27	15286-15299	pandas.Series	
163-28	15299-15300	,	
163-29	15301-15307	Pandas	
163-30	15308-15317	DataFrame	
163-31	15317-15318	,	
163-32	15319-15323	cube	
163-33	15324-15328	hole	
163-34	15328-15329	,	
163-35	15330-15333	and	
163-36	15334-15337	the	
163-37	15338-15346	iterator	
163-38	15347-15350	can	
163-39	15351-15353	be	
163-40	15354-15358	used	
163-41	15359-15361	to	
163-42	15362-15369	impress	
163-43	15370-15373	new	
163-44	15374-15380	Pandas	
163-45	15381-15384	UDF	
163-46	15385-15390	types	
163-47	15390-15391	.	

#Text=For example, in Spark
#Text=2.3, we have a Scala UDF.
164-1	15392-15395	For	
164-2	15396-15403	example	
164-3	15403-15404	,	
164-4	15405-15407	in	
164-5	15408-15413	Spark	
164-6	15414-15417	2.3	
164-7	15417-15418	,	
164-8	15419-15421	we	
164-9	15422-15426	have	
164-10	15427-15428	a	
164-11	15429-15434	Scala	
164-12	15435-15438	UDF	
164-13	15438-15439	.	

#Text=The input is a pandas.Series and its output is also pandas.Series.
165-1	15440-15443	The	
165-2	15444-15449	input	
165-3	15450-15452	is	
165-4	15453-15454	a	
165-5	15455-15468	pandas.Series	
165-6	15469-15472	and	
165-7	15473-15476	its	
165-8	15477-15483	output	
165-9	15484-15486	is	
165-10	15487-15491	also	
165-11	15492-15505	pandas.Series	
165-12	15505-15506	.	

#Text=In Spark
#Text=2.0, we do not require users to remember any UDF types.
166-1	15507-15509	In	
166-2	15510-15515	Spark	
166-3	15516-15519	2.0	
166-4	15519-15520	,	
166-5	15521-15523	we	
166-6	15524-15526	do	
166-7	15527-15530	not	
166-8	15531-15538	require	
166-9	15539-15544	users	
166-10	15545-15547	to	
166-11	15548-15556	remember	
166-12	15557-15560	any	
166-13	15561-15564	UDF	
166-14	15565-15570	types	
166-15	15570-15571	.	

#Text=You just need to specify the input
#Text=and the output types.
167-1	15572-15575	You	
167-2	15576-15580	just	
167-3	15581-15585	need	
167-4	15586-15588	to	
167-5	15589-15596	specify	
167-6	15597-15600	the	
167-7	15601-15606	input	
167-8	15607-15610	and	
167-9	15611-15614	the	
167-10	15615-15621	output	
167-11	15622-15627	types	
167-12	15627-15628	.	

#Text=In Spark 2.3, we also have a Grouped Map Pandas UDF, so input is
#Text=a Pandas DataFrame, and the output is also Pandas DataFrames.
168-1	15629-15631	In	
168-2	15632-15637	Spark	
168-3	15638-15641	2.3	
168-4	15641-15642	,	
168-5	15643-15645	we	
168-6	15646-15650	also	
168-7	15651-15655	have	
168-8	15656-15657	a	
168-9	15658-15665	Grouped	
168-10	15666-15669	Map	
168-11	15670-15676	Pandas	
168-12	15677-15680	UDF	
168-13	15680-15681	,	
168-14	15682-15684	so	
168-15	15685-15690	input	
168-16	15691-15693	is	
168-17	15694-15695	a	
168-18	15696-15702	Pandas	
168-19	15703-15712	DataFrame	
168-20	15712-15713	,	
168-21	15714-15717	and	
168-22	15718-15721	the	
168-23	15722-15728	output	
168-24	15729-15731	is	
168-25	15732-15736	also	
168-26	15737-15743	Pandas	
168-27	15744-15754	DataFrames	
168-28	15754-15755	.	

#Text=Old vs New Pandas UDF interface
#Text=This slide shows the difference between the old and the new interface.
169-1	15756-15759	Old	
169-2	15760-15762	vs	
169-3	15763-15766	New	
169-4	15767-15773	Pandas	
169-5	15774-15777	UDF	
169-6	15778-15787	interface	
169-7	15788-15792	This	
169-8	15793-15798	slide	
169-9	15799-15804	shows	
169-10	15805-15808	the	
169-11	15809-15819	difference	
169-12	15820-15827	between	
169-13	15828-15831	the	
169-14	15832-15835	old	
169-15	15836-15839	and	
169-16	15840-15843	the	
169-17	15844-15847	new	
169-18	15848-15857	interface	
169-19	15857-15858	.	

#Text=The
#Text=same here.
170-1	15859-15862	The	
170-2	15863-15867	same	
170-3	15868-15872	here	
170-4	15872-15873	.	

#Text=The new interface can also be used for the existing Grouped Aggregate Pandas
#Text=UDFs.
171-1	15874-15877	The	
171-2	15878-15881	new	
171-3	15882-15891	interface	
171-4	15892-15895	can	
171-5	15896-15900	also	
171-6	15901-15903	be	
171-7	15904-15908	used	
171-8	15909-15912	for	
171-9	15913-15916	the	
171-10	15917-15925	existing	
171-11	15926-15933	Grouped	
171-12	15934-15943	Aggregate	
171-13	15944-15950	Pandas	
171-14	15951-15955	UDFs	
171-15	15955-15956	.	

#Text=In addition, the old Pandas UDF was split into two API categories: Pandas UDFs
#Text=and Pandas function APIs.
172-1	15957-15959	In	
172-2	15960-15968	addition	
172-3	15968-15969	,	
172-4	15970-15973	the	
172-5	15974-15977	old	
172-6	15978-15984	Pandas	
172-7	15985-15988	UDF	
172-8	15989-15992	was	
172-9	15993-15998	split	
172-10	15999-16003	into	
172-11	16004-16007	two	
172-12	16008-16011	API	
172-13	16012-16022	categories	
172-14	16022-16023	:	
172-15	16024-16030	Pandas	
172-16	16031-16035	UDFs	
172-17	16036-16039	and	
172-18	16040-16046	Pandas	
172-19	16047-16055	function	
172-20	16056-16060	APIs	
172-21	16060-16061	.	

#Text=You can treat Pandas UDFs in the same way that you use the other
#Text=PySpark column instance.
173-1	16062-16065	You	
173-2	16066-16069	can	
173-3	16070-16075	treat	
173-4	16076-16082	Pandas	
173-5	16083-16087	UDFs	
173-6	16088-16090	in	
173-7	16091-16094	the	
173-8	16095-16099	same	
173-9	16100-16103	way	
173-10	16104-16108	that	
173-11	16109-16112	you	
173-12	16113-16116	use	
173-13	16117-16120	the	
173-14	16121-16126	other	
173-15	16127-16134	PySpark	
173-16	16135-16141	column	
173-17	16142-16150	instance	
173-18	16150-16151	.	

#Text=For example, here, calculate the values.
174-1	16152-16155	For	
174-2	16156-16163	example	
174-3	16163-16164	,	
174-4	16165-16169	here	
174-5	16169-16170	,	
174-6	16171-16180	calculate	
174-7	16181-16184	the	
174-8	16185-16191	values	
174-9	16191-16192	.	

#Text=You are calling the
#Text=Pandas UDF calculate.
175-1	16193-16196	You	
175-2	16197-16200	are	
175-3	16201-16208	calling	
175-4	16209-16212	the	
175-5	16213-16219	Pandas	
175-6	16220-16223	UDF	
175-7	16224-16233	calculate	
175-8	16233-16234	.	

#Text=We do support the new Pandas UDF types from iterators of series
#Text=to iterator other series and from iterators of multiple series to iterator of series.
176-1	16235-16237	We	
176-2	16238-16240	do	
176-3	16241-16248	support	
176-4	16249-16252	the	
176-5	16253-16256	new	
176-6	16257-16263	Pandas	
176-7	16264-16267	UDF	
176-8	16268-16273	types	
176-9	16274-16278	from	
176-10	16279-16288	iterators	
176-11	16289-16291	of	
176-12	16292-16298	series	
176-13	16299-16301	to	
176-14	16302-16310	iterator	
176-15	16311-16316	other	
176-16	16317-16323	series	
176-17	16324-16327	and	
176-18	16328-16332	from	
176-19	16333-16342	iterators	
176-20	16343-16345	of	
176-21	16346-16354	multiple	
176-22	16355-16361	series	
176-23	16362-16364	to	
176-24	16365-16373	iterator	
176-25	16374-16376	of	
176-26	16377-16383	series	
176-27	16383-16384	.	

#Text=So this is useful for [inaudible] state initialization of your Pandas UDFs and also useful for Pandas
#Text=UDF parquet.
177-1	16385-16387	So	
177-2	16388-16392	this	
177-3	16393-16395	is	
177-4	16396-16402	useful	
177-5	16403-16406	for	
177-6	16407-16408	[	
177-7	16408-16417	inaudible	
177-8	16417-16418	]	
177-9	16419-16424	state	
177-10	16425-16439	initialization	
177-11	16440-16442	of	
177-12	16443-16447	your	
177-13	16448-16454	Pandas	
177-14	16455-16459	UDFs	
177-15	16460-16463	and	
177-16	16464-16468	also	
177-17	16469-16475	useful	
177-18	16476-16479	for	
177-19	16480-16486	Pandas	
177-20	16487-16490	UDF	
177-21	16491-16498	parquet	
177-22	16498-16499	.	

#Text=However, you can now use Pandas function APIs with this column instance.
178-1	16500-16507	However	
178-2	16507-16508	,	
178-3	16509-16512	you	
178-4	16513-16516	can	
178-5	16517-16520	now	
178-6	16521-16524	use	
178-7	16525-16531	Pandas	
178-8	16532-16540	function	
178-9	16541-16545	APIs	
178-10	16546-16550	with	
178-11	16551-16555	this	
178-12	16556-16562	column	
178-13	16563-16571	instance	
178-14	16571-16572	.	

#Text=Here
#Text=are these two examples: map Pandas function API and the core group, the map Pandas UDF,
#Text=the APIs.
179-1	16573-16577	Here	
179-2	16578-16581	are	
179-3	16582-16587	these	
179-4	16588-16591	two	
179-5	16592-16600	examples	
179-6	16600-16601	:	
179-7	16602-16605	map	
179-8	16606-16612	Pandas	
179-9	16613-16621	function	
179-10	16622-16625	API	
179-11	16626-16629	and	
179-12	16630-16633	the	
179-13	16634-16638	core	
179-14	16639-16644	group	
179-15	16644-16645	,	
179-16	16646-16649	the	
179-17	16650-16653	map	
179-18	16654-16660	Pandas	
179-19	16661-16664	UDF	
179-20	16664-16665	,	
179-21	16666-16669	the	
179-22	16670-16674	APIs	
179-23	16674-16675	.	

#Text=These APIs are newly added in these units.
180-1	16676-16681	These	
180-2	16682-16686	APIs	
180-3	16687-16690	are	
180-4	16691-16696	newly	
180-5	16697-16702	added	
180-6	16703-16705	in	
180-7	16706-16711	these	
180-8	16712-16717	units	
180-9	16717-16718	.	

#Text=Back to Wenchen
#Text=So next, Wenchen will go over the remaining
#Text=features and provide a deep dive into accumulator with Scalar.
181-1	16719-16723	Back	
181-2	16724-16726	to	
181-3	16727-16734	Wenchen	
181-4	16735-16737	So	
181-5	16738-16742	next	
181-6	16742-16743	,	
181-7	16744-16751	Wenchen	
181-8	16752-16756	will	
181-9	16757-16759	go	
181-10	16760-16764	over	
181-11	16765-16768	the	
181-12	16769-16778	remaining	
181-13	16779-16787	features	
181-14	16788-16791	and	
181-15	16792-16799	provide	
181-16	16800-16801	a	
181-17	16802-16806	deep	
181-18	16807-16811	dive	
181-19	16812-16816	into	
181-20	16817-16828	accumulator	
181-21	16829-16833	with	
181-22	16834-16840	Scalar	
181-23	16840-16841	.	

#Text=Please welcome Wenchen.
182-1	16842-16848	Please	
182-2	16849-16856	welcome	
182-3	16857-16864	Wenchen	
182-4	16864-16865	.	

#Text=Thanks, Xiao, for the first half of the talk.
183-1	16866-16872	Thanks	
183-2	16872-16873	,	
183-3	16874-16878	Xiao	
183-4	16878-16879	,	
183-5	16880-16883	for	
183-6	16884-16887	the	
183-7	16888-16893	first	
183-8	16894-16898	half	
183-9	16899-16901	of	
183-10	16902-16905	the	
183-11	16906-16910	talk	
183-12	16910-16911	.	

#Text=Now, let me take over from
#Text=here and introduce the remaining Spark 3.0 features.
184-1	16912-16915	Now	
184-2	16915-16916	,	
184-3	16917-16920	let	
184-4	16921-16923	me	
184-5	16924-16928	take	
184-6	16929-16933	over	
184-7	16934-16938	from	
184-8	16939-16943	here	
184-9	16944-16947	and	
184-10	16948-16957	introduce	
184-11	16958-16961	the	
184-12	16962-16971	remaining	
184-13	16972-16977	Spark	
184-14	16978-16981	3.0	
184-15	16982-16990	features	
184-16	16990-16991	.	

#Text=Accelerator-aware Scheduling
#Text=I will start with, straight away,
#Text=our scheduler.
185-1	16992-17009	Accelerator-aware	
185-2	17010-17020	Scheduling	
185-3	17021-17022	I	
185-4	17023-17027	will	
185-5	17028-17033	start	
185-6	17034-17038	with	
185-7	17038-17039	,	
185-8	17040-17048	straight	
185-9	17049-17053	away	
185-10	17053-17054	,	
185-11	17055-17058	our	
185-12	17059-17068	scheduler	
185-13	17068-17069	.	

#Text=In 2018 Spark Summit, we already announced the new project [inaudible].
186-1	17070-17072	In	
186-2	17073-17077	2018	
186-3	17078-17083	Spark	
186-4	17084-17090	Summit	
186-5	17090-17091	,	
186-6	17092-17094	we	
186-7	17095-17102	already	
186-8	17103-17112	announced	
186-9	17113-17116	the	
186-10	17117-17120	new	
186-11	17121-17128	project	
186-12	17129-17130	[	
186-13	17130-17139	inaudible	
186-14	17139-17140	]	
186-15	17140-17141	.	

#Text=As
#Text=you’re now aware, our scheduler is part of this project.
187-1	17142-17144	As	
187-2	17145-17148	you	
187-3	17148-17149	’	
187-4	17149-17151	re	
187-5	17152-17155	now	
187-6	17156-17161	aware	
187-7	17161-17162	,	
187-8	17163-17166	our	
187-9	17167-17176	scheduler	
187-10	17177-17179	is	
187-11	17180-17184	part	
187-12	17185-17187	of	
187-13	17188-17192	this	
187-14	17193-17200	project	
187-15	17200-17201	.	

#Text=It can be widely used for executing
#Text=special workloads.
188-1	17202-17204	It	
188-2	17205-17208	can	
188-3	17209-17211	be	
188-4	17212-17218	widely	
188-5	17219-17223	used	
188-6	17224-17227	for	
188-7	17228-17237	executing	
188-8	17238-17245	special	
188-9	17246-17255	workloads	
188-10	17255-17256	.	

#Text=In this release, we support standalone, YARN, and Kubernetes scheduler
#Text=scheduler backend.
189-1	17257-17259	In	
189-2	17260-17264	this	
189-3	17265-17272	release	
189-4	17272-17273	,	
189-5	17274-17276	we	
189-6	17277-17284	support	
189-7	17285-17295	standalone	
189-8	17295-17296	,	
189-9	17297-17301	YARN	
189-10	17301-17302	,	
189-11	17303-17306	and	
189-12	17307-17317	Kubernetes	
189-13	17318-17327	scheduler	
189-14	17328-17337	scheduler	
189-15	17338-17345	backend	
189-16	17345-17346	.	

#Text=So far, users need to specify the require resources using a [inaudible]
#Text=configs.
190-1	17347-17349	So	
190-2	17350-17353	far	
190-3	17353-17354	,	
190-4	17355-17360	users	
190-5	17361-17365	need	
190-6	17366-17368	to	
190-7	17369-17376	specify	
190-8	17377-17380	the	
190-9	17381-17388	require	
190-10	17389-17398	resources	
190-11	17399-17404	using	
190-12	17405-17406	a	
190-13	17407-17408	[	
190-14	17408-17417	inaudible	
190-15	17417-17418	]	
190-16	17419-17426	configs	
190-17	17426-17427	.	

#Text=In the future, we will support the job, stage, and task levels.
191-1	17428-17430	In	
191-2	17431-17434	the	
191-3	17435-17441	future	
191-4	17441-17442	,	
191-5	17443-17445	we	
191-6	17446-17450	will	
191-7	17451-17458	support	
191-8	17459-17462	the	
191-9	17463-17466	job	
191-10	17466-17467	,	
191-11	17468-17473	stage	
191-12	17473-17474	,	
191-13	17475-17478	and	
191-14	17479-17483	task	
191-15	17484-17490	levels	
191-16	17490-17491	.	

#Text=To further understand
#Text=this feature, let’s look at the workflow.
192-1	17492-17494	To	
192-2	17495-17502	further	
192-3	17503-17513	understand	
192-4	17514-17518	this	
192-5	17519-17526	feature	
192-6	17526-17527	,	
192-7	17528-17531	let	
192-8	17531-17532	’	
192-9	17532-17533	s	
192-10	17534-17538	look	
192-11	17539-17541	at	
192-12	17542-17545	the	
192-13	17546-17554	workflow	
192-14	17554-17555	.	

#Text=Ideally, the cost manager should be able to
#Text=automatically discover resources, like GPUs.
193-1	17556-17563	Ideally	
193-2	17563-17564	,	
193-3	17565-17568	the	
193-4	17569-17573	cost	
193-5	17574-17581	manager	
193-6	17582-17588	should	
193-7	17589-17591	be	
193-8	17592-17596	able	
193-9	17597-17599	to	
193-10	17600-17613	automatically	
193-11	17614-17622	discover	
193-12	17623-17632	resources	
193-13	17632-17633	,	
193-14	17634-17638	like	
193-15	17639-17643	GPUs	
193-16	17643-17644	.	

#Text=When the user submits an application with
#Text=resource request, Spark should pass the resources request to a cluster manager and then the cluster
#Text=manager cooperates to allocate and launch executors with the required resources.
194-1	17645-17649	When	
194-2	17650-17653	the	
194-3	17654-17658	user	
194-4	17659-17666	submits	
194-5	17667-17669	an	
194-6	17670-17681	application	
194-7	17682-17686	with	
194-8	17687-17695	resource	
194-9	17696-17703	request	
194-10	17703-17704	,	
194-11	17705-17710	Spark	
194-12	17711-17717	should	
194-13	17718-17722	pass	
194-14	17723-17726	the	
194-15	17727-17736	resources	
194-16	17737-17744	request	
194-17	17745-17747	to	
194-18	17748-17749	a	
194-19	17750-17757	cluster	
194-20	17758-17765	manager	
194-21	17766-17769	and	
194-22	17770-17774	then	
194-23	17775-17778	the	
194-24	17779-17786	cluster	
194-25	17787-17794	manager	
194-26	17795-17805	cooperates	
194-27	17806-17808	to	
194-28	17809-17817	allocate	
194-29	17818-17821	and	
194-30	17822-17828	launch	
194-31	17829-17838	executors	
194-32	17839-17843	with	
194-33	17844-17847	the	
194-34	17848-17856	required	
194-35	17857-17866	resources	
194-36	17866-17867	.	

#Text=After
#Text=Spark job is submitted, Spark should schedule tasks on available executors, and the cluster
#Text=manager should track the results usage and perform dynamic resource allocation.
195-1	17868-17873	After	
195-2	17874-17879	Spark	
195-3	17880-17883	job	
195-4	17884-17886	is	
195-5	17887-17896	submitted	
195-6	17896-17897	,	
195-7	17898-17903	Spark	
195-8	17904-17910	should	
195-9	17911-17919	schedule	
195-10	17920-17925	tasks	
195-11	17926-17928	on	
195-12	17929-17938	available	
195-13	17939-17948	executors	
195-14	17948-17949	,	
195-15	17950-17953	and	
195-16	17954-17957	the	
195-17	17958-17965	cluster	
195-18	17966-17973	manager	
195-19	17974-17980	should	
195-20	17981-17986	track	
195-21	17987-17990	the	
195-22	17991-17998	results	
195-23	17999-18004	usage	
195-24	18005-18008	and	
195-25	18009-18016	perform	
195-26	18017-18024	dynamic	
195-27	18025-18033	resource	
195-28	18034-18044	allocation	
195-29	18044-18045	.	

#Text=For example,
#Text=when there are too many pending tasks, the cluster manager should allocate more executors
#Text=to run more tasks at the same time.
196-1	18046-18049	For	
196-2	18050-18057	example	
196-3	18057-18058	,	
196-4	18059-18063	when	
196-5	18064-18069	there	
196-6	18070-18073	are	
196-7	18074-18077	too	
196-8	18078-18082	many	
196-9	18083-18090	pending	
196-10	18091-18096	tasks	
196-11	18096-18097	,	
196-12	18098-18101	the	
196-13	18102-18109	cluster	
196-14	18110-18117	manager	
196-15	18118-18124	should	
196-16	18125-18133	allocate	
196-17	18134-18138	more	
196-18	18139-18148	executors	
196-19	18149-18151	to	
196-20	18152-18155	run	
196-21	18156-18160	more	
196-22	18161-18166	tasks	
196-23	18167-18169	at	
196-24	18170-18173	the	
196-25	18174-18178	same	
196-26	18179-18183	time	
196-27	18183-18184	.	

#Text=When a task is running, the user shall be able to
#Text=retrieve the assigned resources and use them in their code.
197-1	18185-18189	When	
197-2	18190-18191	a	
197-3	18192-18196	task	
197-4	18197-18199	is	
197-5	18200-18207	running	
197-6	18207-18208	,	
197-7	18209-18212	the	
197-8	18213-18217	user	
197-9	18218-18223	shall	
197-10	18224-18226	be	
197-11	18227-18231	able	
197-12	18232-18234	to	
197-13	18235-18243	retrieve	
197-14	18244-18247	the	
197-15	18248-18256	assigned	
197-16	18257-18266	resources	
197-17	18267-18270	and	
197-18	18271-18274	use	
197-19	18275-18279	them	
197-20	18280-18282	in	
197-21	18283-18288	their	
197-22	18289-18293	code	
197-23	18293-18294	.	

#Text=In the meanwhile, cluster manager
#Text=shall monitor and recover failed executions.
198-1	18295-18297	In	
198-2	18298-18301	the	
198-3	18302-18311	meanwhile	
198-4	18311-18312	,	
198-5	18313-18320	cluster	
198-6	18321-18328	manager	
198-7	18329-18334	shall	
198-8	18335-18342	monitor	
198-9	18343-18346	and	
198-10	18347-18354	recover	
198-11	18355-18361	failed	
198-12	18362-18372	executions	
198-13	18372-18373	.	

#Text=Now, let’s look at how can a cluster manager discover resources and how
#Text=can users request resources.
199-1	18374-18377	Now	
199-2	18377-18378	,	
199-3	18379-18382	let	
199-4	18382-18383	’	
199-5	18383-18384	s	
199-6	18385-18389	look	
199-7	18390-18392	at	
199-8	18393-18396	how	
199-9	18397-18400	can	
199-10	18401-18402	a	
199-11	18403-18410	cluster	
199-12	18411-18418	manager	
199-13	18419-18427	discover	
199-14	18428-18437	resources	
199-15	18438-18441	and	
199-16	18442-18445	how	
199-17	18446-18449	can	
199-18	18450-18455	users	
199-19	18456-18463	request	
199-20	18464-18473	resources	
199-21	18473-18474	.	

#Text=As an admin of the cluster, I can specify a script to auto discover executors.
200-1	18475-18477	As	
200-2	18478-18480	an	
200-3	18481-18486	admin	
200-4	18487-18489	of	
200-5	18490-18493	the	
200-6	18494-18501	cluster	
200-7	18501-18502	,	
200-8	18503-18504	I	
200-9	18505-18508	can	
200-10	18509-18516	specify	
200-11	18517-18518	a	
200-12	18519-18525	script	
200-13	18526-18528	to	
200-14	18529-18533	auto	
200-15	18534-18542	discover	
200-16	18543-18552	executors	
200-17	18552-18553	.	

#Text=The discovery script can be specified separately on Java as executors.
201-1	18554-18557	The	
201-2	18558-18567	discovery	
201-3	18568-18574	script	
201-4	18575-18578	can	
201-5	18579-18581	be	
201-6	18582-18591	specified	
201-7	18592-18602	separately	
201-8	18603-18605	on	
201-9	18606-18610	Java	
201-10	18611-18613	as	
201-11	18614-18623	executors	
201-12	18623-18624	.	

#Text=We also provided an example to auto discover Nvidia GPU resources.
202-1	18625-18627	We	
202-2	18628-18632	also	
202-3	18633-18641	provided	
202-4	18642-18644	an	
202-5	18645-18652	example	
202-6	18653-18655	to	
202-7	18656-18660	auto	
202-8	18661-18669	discover	
202-9	18670-18676	Nvidia	
202-10	18677-18680	GPU	
202-11	18681-18690	resources	
202-12	18690-18691	.	

#Text=You can adjust
#Text=this example script for other kinds of resources.
203-1	18692-18695	You	
203-2	18696-18699	can	
203-3	18700-18706	adjust	
203-4	18707-18711	this	
203-5	18712-18719	example	
203-6	18720-18726	script	
203-7	18727-18730	for	
203-8	18731-18736	other	
203-9	18737-18742	kinds	
203-10	18743-18745	of	
203-11	18746-18755	resources	
203-12	18755-18756	.	

#Text=Then as a user of Spark, I can request resources
#Text=at the application level.
204-1	18757-18761	Then	
204-2	18762-18764	as	
204-3	18765-18766	a	
204-4	18767-18771	user	
204-5	18772-18774	of	
204-6	18775-18780	Spark	
204-7	18780-18781	,	
204-8	18782-18783	I	
204-9	18784-18787	can	
204-10	18788-18795	request	
204-11	18796-18805	resources	
204-12	18806-18808	at	
204-13	18809-18812	the	
204-14	18813-18824	application	
204-15	18825-18830	level	
204-16	18830-18831	.	

#Text=I can use the config spark.executor.resource.
205-1	18832-18833	I	
205-2	18834-18837	can	
205-3	18838-18841	use	
205-4	18842-18845	the	
205-5	18846-18852	config	
205-6	18853-18876	spark.executor.resource	
205-7	18876-18877	.	

#Text={resourceName}.amount
#Text=and the corresponding config for Java to specify the executors amount on the Java and executors.
206-1	18877-18878	{	
206-2	18878-18890	resourceName	
206-3	18890-18891	}	
206-4	18891-18892	.	
206-5	18892-18898	amount	
206-6	18899-18902	and	
206-7	18903-18906	the	
206-8	18907-18920	corresponding	
206-9	18921-18927	config	
206-10	18928-18931	for	
206-11	18932-18936	Java	
206-12	18937-18939	to	
206-13	18940-18947	specify	
206-14	18948-18951	the	
206-15	18952-18961	executors	
206-16	18962-18968	amount	
206-17	18969-18971	on	
206-18	18972-18975	the	
206-19	18976-18980	Java	
206-20	18981-18984	and	
206-21	18985-18994	executors	
206-22	18994-18995	.	

#Text=Also, I can use the config spark.task.resource.
207-1	18996-19000	Also	
207-2	19000-19001	,	
207-3	19002-19003	I	
207-4	19004-19007	can	
207-5	19008-19011	use	
207-6	19012-19015	the	
207-7	19016-19022	config	
207-8	19023-19042	spark.task.resource	
207-9	19042-19043	.	

#Text={resourceName}.amount to specify the executors required by each
#Text=task.
208-1	19043-19044	{	
208-2	19044-19056	resourceName	
208-3	19056-19057	}	
208-4	19057-19058	.	
208-5	19058-19064	amount	
208-6	19065-19067	to	
208-7	19068-19075	specify	
208-8	19076-19079	the	
208-9	19080-19089	executors	
208-10	19090-19098	required	
208-11	19099-19101	by	
208-12	19102-19106	each	
208-13	19107-19111	task	
208-14	19111-19112	.	

#Text=As I mentioned earlier, we will support more time-proven labor later, like the job
#Text=or stage labor.
209-1	19113-19115	As	
209-2	19116-19117	I	
209-3	19118-19127	mentioned	
209-4	19128-19135	earlier	
209-5	19135-19136	,	
209-6	19137-19139	we	
209-7	19140-19144	will	
209-8	19145-19152	support	
209-9	19153-19157	more	
209-10	19158-19169	time-proven	
209-11	19170-19175	labor	
209-12	19176-19181	later	
209-13	19181-19182	,	
209-14	19183-19187	like	
209-15	19188-19191	the	
209-16	19192-19195	job	
209-17	19196-19198	or	
209-18	19199-19204	stage	
209-19	19205-19210	labor	
209-20	19210-19211	.	

#Text=Please stay tuned.
210-1	19212-19218	Please	
210-2	19219-19223	stay	
210-3	19224-19229	tuned	
210-4	19229-19230	.	

#Text=Retrieve Assigned Accelerators
#Text=Next, we’ll see how you can leverage the assigned executors to actually
#Text=execute your workloads, which is probably the most important part to the users.
211-1	19231-19239	Retrieve	
211-2	19240-19248	Assigned	
211-3	19249-19261	Accelerators	
211-4	19262-19266	Next	
211-5	19266-19267	,	
211-6	19268-19270	we	
211-7	19270-19271	’	
211-8	19271-19273	ll	
211-9	19274-19277	see	
211-10	19278-19281	how	
211-11	19282-19285	you	
211-12	19286-19289	can	
211-13	19290-19298	leverage	
211-14	19299-19302	the	
211-15	19303-19311	assigned	
211-16	19312-19321	executors	
211-17	19322-19324	to	
211-18	19325-19333	actually	
211-19	19334-19341	execute	
211-20	19342-19346	your	
211-21	19347-19356	workloads	
211-22	19356-19357	,	
211-23	19358-19363	which	
211-24	19364-19366	is	
211-25	19367-19375	probably	
211-26	19376-19379	the	
211-27	19380-19384	most	
211-28	19385-19394	important	
211-29	19395-19399	part	
211-30	19400-19402	to	
211-31	19403-19406	the	
211-32	19407-19412	users	
211-33	19412-19413	.	

#Text=So as
#Text=a user of Spark, I can retrieve the assigned executors from the task content.
212-1	19414-19416	So	
212-2	19417-19419	as	
212-3	19420-19421	a	
212-4	19422-19426	user	
212-5	19427-19429	of	
212-6	19430-19435	Spark	
212-7	19435-19436	,	
212-8	19437-19438	I	
212-9	19439-19442	can	
212-10	19443-19451	retrieve	
212-11	19452-19455	the	
212-12	19456-19464	assigned	
212-13	19465-19474	executors	
212-14	19475-19479	from	
212-15	19480-19483	the	
212-16	19484-19488	task	
212-17	19489-19496	content	
212-18	19496-19497	.	

#Text=Here is an
#Text=example in PySpark.
213-1	19498-19502	Here	
213-2	19503-19505	is	
213-3	19506-19508	an	
213-4	19509-19516	example	
213-5	19517-19519	in	
213-6	19520-19527	PySpark	
213-7	19527-19528	.	

#Text=The contents of resources returns a map from the resource name to resource
#Text=info.
214-1	19529-19532	The	
214-2	19533-19541	contents	
214-3	19542-19544	of	
214-4	19545-19554	resources	
214-5	19555-19562	returns	
214-6	19563-19564	a	
214-7	19565-19568	map	
214-8	19569-19573	from	
214-9	19574-19577	the	
214-10	19578-19586	resource	
214-11	19587-19591	name	
214-12	19592-19594	to	
214-13	19595-19603	resource	
214-14	19604-19608	info	
214-15	19608-19609	.	

#Text=In the example, we request for GPUs, and we can take the GPU address from the resource
#Text=map.
215-1	19610-19612	In	
215-2	19613-19616	the	
215-3	19617-19624	example	
215-4	19624-19625	,	
215-5	19626-19628	we	
215-6	19629-19636	request	
215-7	19637-19640	for	
215-8	19641-19645	GPUs	
215-9	19645-19646	,	
215-10	19647-19650	and	
215-11	19651-19653	we	
215-12	19654-19657	can	
215-13	19658-19662	take	
215-14	19663-19666	the	
215-15	19667-19670	GPU	
215-16	19671-19678	address	
215-17	19679-19683	from	
215-18	19684-19687	the	
215-19	19688-19696	resource	
215-20	19697-19700	map	
215-21	19700-19701	.	

#Text=Then we launch the TensorFlow to train my model within GPUs.
216-1	19702-19706	Then	
216-2	19707-19709	we	
216-3	19710-19716	launch	
216-4	19717-19720	the	
216-5	19721-19731	TensorFlow	
216-6	19732-19734	to	
216-7	19735-19740	train	
216-8	19741-19743	my	
216-9	19744-19749	model	
216-10	19750-19756	within	
216-11	19757-19761	GPUs	
216-12	19761-19762	.	

#Text=Spark will take care
#Text=of the resource allocation and acceleration and also monitor the executors here for failure recovery, which makes my life much easier.
217-1	19763-19768	Spark	
217-2	19769-19773	will	
217-3	19774-19778	take	
217-4	19779-19783	care	
217-5	19784-19786	of	
217-6	19787-19790	the	
217-7	19791-19799	resource	
217-8	19800-19810	allocation	
217-9	19811-19814	and	
217-10	19815-19827	acceleration	
217-11	19828-19831	and	
217-12	19832-19836	also	
217-13	19837-19844	monitor	
217-14	19845-19848	the	
217-15	19849-19858	executors	
217-16	19859-19863	here	
217-17	19864-19867	for	
217-18	19868-19875	failure	
217-19	19876-19884	recovery	
217-20	19884-19885	,	
217-21	19886-19891	which	
217-22	19892-19897	makes	
217-23	19898-19900	my	
217-24	19901-19905	life	
217-25	19906-19910	much	
217-26	19911-19917	easier	
217-27	19917-19918	.	

#Text=Cluster Manager Support
#Text=As I mentioned earlier, the executor aware
#Text=of scheduling support has been added to standalone, YARN, and Kubernetes cost manager.
218-1	19919-19926	Cluster	
218-2	19927-19934	Manager	
218-3	19935-19942	Support	
218-4	19943-19945	As	
218-5	19946-19947	I	
218-6	19948-19957	mentioned	
218-7	19958-19965	earlier	
218-8	19965-19966	,	
218-9	19967-19970	the	
218-10	19971-19979	executor	
218-11	19980-19985	aware	
218-12	19986-19988	of	
218-13	19989-19999	scheduling	
218-14	20000-20007	support	
218-15	20008-20011	has	
218-16	20012-20016	been	
218-17	20017-20022	added	
218-18	20023-20025	to	
218-19	20026-20036	standalone	
218-20	20036-20037	,	
218-21	20038-20042	YARN	
218-22	20042-20043	,	
218-23	20044-20047	and	
218-24	20048-20058	Kubernetes	
218-25	20059-20063	cost	
218-26	20064-20071	manager	
218-27	20071-20072	.	

#Text=You can
#Text=check the Spark JIRA tickets to see more details.
219-1	20073-20076	You	
219-2	20077-20080	can	
219-3	20081-20086	check	
219-4	20087-20090	the	
219-5	20091-20096	Spark	
219-6	20097-20101	JIRA	
219-7	20102-20109	tickets	
219-8	20110-20112	to	
219-9	20113-20116	see	
219-10	20117-20121	more	
219-11	20122-20129	details	
219-12	20129-20130	.	

#Text=Unfortunately, the Mesos support is still
#Text=not available.
220-1	20131-20144	Unfortunately	
220-2	20144-20145	,	
220-3	20146-20149	the	
220-4	20150-20155	Mesos	
220-5	20156-20163	support	
220-6	20164-20166	is	
220-7	20167-20172	still	
220-8	20173-20176	not	
220-9	20177-20186	available	
220-10	20186-20187	.	

#Text=We’d really appreciate it if any Mesos expert has interest and is willing
#Text=to help the Spark community to add the Mesos support.
221-1	20188-20190	We	
221-2	20190-20191	’	
221-3	20191-20192	d	
221-4	20193-20199	really	
221-5	20200-20210	appreciate	
221-6	20211-20213	it	
221-7	20214-20216	if	
221-8	20217-20220	any	
221-9	20221-20226	Mesos	
221-10	20227-20233	expert	
221-11	20234-20237	has	
221-12	20238-20246	interest	
221-13	20247-20250	and	
221-14	20251-20253	is	
221-15	20254-20261	willing	
221-16	20262-20264	to	
221-17	20265-20269	help	
221-18	20270-20273	the	
221-19	20274-20279	Spark	
221-20	20280-20289	community	
221-21	20290-20292	to	
221-22	20293-20296	add	
221-23	20297-20300	the	
221-24	20301-20306	Mesos	
221-25	20307-20314	support	
221-26	20314-20315	.	

#Text=Please leave a comment in the [inaudible]
#Text=if you want to work on it.
222-1	20316-20322	Please	
222-2	20323-20328	leave	
222-3	20329-20330	a	
222-4	20331-20338	comment	
222-5	20339-20341	in	
222-6	20342-20345	the	
222-7	20346-20347	[	
222-8	20347-20356	inaudible	
222-9	20356-20357	]	
222-10	20358-20360	if	
222-11	20361-20364	you	
222-12	20365-20369	want	
222-13	20370-20372	to	
222-14	20373-20377	work	
222-15	20378-20380	on	
222-16	20381-20383	it	
222-17	20383-20384	.	

#Text=Thanks in advance.
223-1	20385-20391	Thanks	
223-2	20392-20394	in	
223-3	20395-20402	advance	
223-4	20402-20403	.	

#Text=Improved Spark Web UI for Accelerators
#Text=Last but not the least, we also improved the Spark Web UI to show all
#Text=the discovery resources on the executor page.
224-1	20404-20412	Improved	
224-2	20413-20418	Spark	
224-3	20419-20422	Web	
224-4	20423-20425	UI	
224-5	20426-20429	for	
224-6	20430-20442	Accelerators	
224-7	20443-20447	Last	
224-8	20448-20451	but	
224-9	20452-20455	not	
224-10	20456-20459	the	
224-11	20460-20465	least	
224-12	20465-20466	,	
224-13	20467-20469	we	
224-14	20470-20474	also	
224-15	20475-20483	improved	
224-16	20484-20487	the	
224-17	20488-20493	Spark	
224-18	20494-20497	Web	
224-19	20498-20500	UI	
224-20	20501-20503	to	
224-21	20504-20508	show	
224-22	20509-20512	all	
224-23	20513-20516	the	
224-24	20517-20526	discovery	
224-25	20527-20536	resources	
224-26	20537-20539	on	
224-27	20540-20543	the	
224-28	20544-20552	executor	
224-29	20553-20557	page	
224-30	20557-20558	.	

#Text=In this page, we can see that there are GPUs
#Text=available on the executor one.
225-1	20559-20561	In	
225-2	20562-20566	this	
225-3	20567-20571	page	
225-4	20571-20572	,	
225-5	20573-20575	we	
225-6	20576-20579	can	
225-7	20580-20583	see	
225-8	20584-20588	that	
225-9	20589-20594	there	
225-10	20595-20598	are	
225-11	20599-20603	GPUs	
225-12	20604-20613	available	
225-13	20614-20616	on	
225-14	20617-20620	the	
225-15	20621-20629	executor	
225-16	20630-20633	one	
225-17	20633-20634	.	

#Text=You can check the Web UI to see how many executors
#Text=are available in the cluster, so you can better schedule your jobs.
#Text=32 New Built-in Functions
#Text=In this release, we also
#Text=introduced 32 new built-in functions and add high auto functions in the Scalar API.
226-1	20635-20638	You	
226-2	20639-20642	can	
226-3	20643-20648	check	
226-4	20649-20652	the	
226-5	20653-20656	Web	
226-6	20657-20659	UI	
226-7	20660-20662	to	
226-8	20663-20666	see	
226-9	20667-20670	how	
226-10	20671-20675	many	
226-11	20676-20685	executors	
226-12	20686-20689	are	
226-13	20690-20699	available	
226-14	20700-20702	in	
226-15	20703-20706	the	
226-16	20707-20714	cluster	
226-17	20714-20715	,	
226-18	20716-20718	so	
226-19	20719-20722	you	
226-20	20723-20726	can	
226-21	20727-20733	better	
226-22	20734-20742	schedule	
226-23	20743-20747	your	
226-24	20748-20752	jobs	
226-25	20752-20753	.	
226-26	20754-20756	32	
226-27	20757-20760	New	
226-28	20761-20769	Built-in	
226-29	20770-20779	Functions	
226-30	20780-20782	In	
226-31	20783-20787	this	
226-32	20788-20795	release	
226-33	20795-20796	,	
226-34	20797-20799	we	
226-35	20800-20804	also	
226-36	20805-20815	introduced	
226-37	20816-20818	32	
226-38	20819-20822	new	
226-39	20823-20831	built-in	
226-40	20832-20841	functions	
226-41	20842-20845	and	
226-42	20846-20849	add	
226-43	20850-20854	high	
226-44	20855-20859	auto	
226-45	20860-20869	functions	
226-46	20870-20872	in	
226-47	20873-20876	the	
226-48	20877-20883	Scalar	
226-49	20884-20887	API	
226-50	20887-20888	.	

#Text=The
#Text=Spark community pays a lot of attention to compatibility.
227-1	20889-20892	The	
227-2	20893-20898	Spark	
227-3	20899-20908	community	
227-4	20909-20913	pays	
227-5	20914-20915	a	
227-6	20916-20919	lot	
227-7	20920-20922	of	
227-8	20923-20932	attention	
227-9	20933-20935	to	
227-10	20936-20949	compatibility	
227-11	20949-20950	.	

#Text=We have investigated many other
#Text=ecosystems, like the PostgreSQL, and implemented many commonly used functions in Spark.
228-1	20951-20953	We	
228-2	20954-20958	have	
228-3	20959-20971	investigated	
228-4	20972-20976	many	
228-5	20977-20982	other	
228-6	20983-20993	ecosystems	
228-7	20993-20994	,	
228-8	20995-20999	like	
228-9	21000-21003	the	
228-10	21004-21014	PostgreSQL	
228-11	21014-21015	,	
228-12	21016-21019	and	
228-13	21020-21031	implemented	
228-14	21032-21036	many	
228-15	21037-21045	commonly	
228-16	21046-21050	used	
228-17	21051-21060	functions	
228-18	21061-21063	in	
228-19	21064-21069	Spark	
228-20	21069-21070	.	

#Text=Hopefully,
#Text=these new built-in functions can make it faster to build your queries as you don’t need to
#Text=waste time to learn a lot of UDFs.
229-1	21071-21080	Hopefully	
229-2	21080-21081	,	
229-3	21082-21087	these	
229-4	21088-21091	new	
229-5	21092-21100	built-in	
229-6	21101-21110	functions	
229-7	21111-21114	can	
229-8	21115-21119	make	
229-9	21120-21122	it	
229-10	21123-21129	faster	
229-11	21130-21132	to	
229-12	21133-21138	build	
229-13	21139-21143	your	
229-14	21144-21151	queries	
229-15	21152-21154	as	
229-16	21155-21158	you	
229-17	21159-21162	don	
229-18	21162-21163	’	
229-19	21163-21164	t	
229-20	21165-21169	need	
229-21	21170-21172	to	
229-22	21173-21178	waste	
229-23	21179-21183	time	
229-24	21184-21186	to	
229-25	21187-21192	learn	
229-26	21193-21194	a	
229-27	21195-21198	lot	
229-28	21199-21201	of	
229-29	21202-21206	UDFs	
229-30	21206-21207	.	

#Text=Due to the time limitations, I can’t go over all
#Text=the functions here, so let me just introduce some map type functions as an example.
230-1	21208-21211	Due	
230-2	21212-21214	to	
230-3	21215-21218	the	
230-4	21219-21223	time	
230-5	21224-21235	limitations	
230-6	21235-21236	,	
230-7	21237-21238	I	
230-8	21239-21242	can	
230-9	21242-21243	’	
230-10	21243-21244	t	
230-11	21245-21247	go	
230-12	21248-21252	over	
230-13	21253-21256	all	
230-14	21257-21260	the	
230-15	21261-21270	functions	
230-16	21271-21275	here	
230-17	21275-21276	,	
230-18	21277-21279	so	
230-19	21280-21283	let	
230-20	21284-21286	me	
230-21	21287-21291	just	
230-22	21292-21301	introduce	
230-23	21302-21306	some	
230-24	21307-21310	map	
230-25	21311-21315	type	
230-26	21316-21325	functions	
230-27	21326-21328	as	
230-28	21329-21331	an	
230-29	21332-21339	example	
230-30	21339-21340	.	

#Text=When you deal with map type values, it’s common to get the keys and values
#Text=for the map as an array.
231-1	21341-21345	When	
231-2	21346-21349	you	
231-3	21350-21354	deal	
231-4	21355-21359	with	
231-5	21360-21363	map	
231-6	21364-21368	type	
231-7	21369-21375	values	
231-8	21375-21376	,	
231-9	21377-21379	it	
231-10	21379-21380	’	
231-11	21380-21381	s	
231-12	21382-21388	common	
231-13	21389-21391	to	
231-14	21392-21395	get	
231-15	21396-21399	the	
231-16	21400-21404	keys	
231-17	21405-21408	and	
231-18	21409-21415	values	
231-19	21416-21419	for	
231-20	21420-21423	the	
231-21	21424-21427	map	
231-22	21428-21430	as	
231-23	21431-21433	an	
231-24	21434-21439	array	
231-25	21439-21440	.	

#Text=There are two functions, map keys and map values can do
#Text=this for you.
232-1	21441-21446	There	
232-2	21447-21450	are	
232-3	21451-21454	two	
232-4	21455-21464	functions	
232-5	21464-21465	,	
232-6	21466-21469	map	
232-7	21470-21474	keys	
232-8	21475-21478	and	
232-9	21479-21482	map	
232-10	21483-21489	values	
232-11	21490-21493	can	
232-12	21494-21496	do	
232-13	21497-21501	this	
232-14	21502-21505	for	
232-15	21506-21509	you	
232-16	21509-21510	.	

#Text=The example is from the Databricks runtime notebook.
233-1	21511-21514	The	
233-2	21515-21522	example	
233-3	21523-21525	is	
233-4	21526-21530	from	
233-5	21531-21534	the	
233-6	21535-21545	Databricks	
233-7	21546-21553	runtime	
233-8	21554-21562	notebook	
233-9	21562-21563	.	

#Text=Or you may want to do
#Text=something more complicated, like creating a new map by transforming the original map
#Text=where it’s a keys and a map values functions.
234-1	21564-21566	Or	
234-2	21567-21570	you	
234-3	21571-21574	may	
234-4	21575-21579	want	
234-5	21580-21582	to	
234-6	21583-21585	do	
234-7	21586-21595	something	
234-8	21596-21600	more	
234-9	21601-21612	complicated	
234-10	21612-21613	,	
234-11	21614-21618	like	
234-12	21619-21627	creating	
234-13	21628-21629	a	
234-14	21630-21633	new	
234-15	21634-21637	map	
234-16	21638-21640	by	
234-17	21641-21653	transforming	
234-18	21654-21657	the	
234-19	21658-21666	original	
234-20	21667-21670	map	
234-21	21671-21676	where	
234-22	21677-21679	it	
234-23	21679-21680	’	
234-24	21680-21681	s	
234-25	21682-21683	a	
234-26	21684-21688	keys	
234-27	21689-21692	and	
234-28	21693-21694	a	
234-29	21695-21698	map	
234-30	21699-21705	values	
234-31	21706-21715	functions	
234-32	21715-21716	.	

#Text=So if there are two functions, transform keys
#Text=and transform values can do this for you, and you just need to write a handler function
#Text=to specify the transformation logic.
235-1	21717-21719	So	
235-2	21720-21722	if	
235-3	21723-21728	there	
235-4	21729-21732	are	
235-5	21733-21736	two	
235-6	21737-21746	functions	
235-7	21746-21747	,	
235-8	21748-21757	transform	
235-9	21758-21762	keys	
235-10	21763-21766	and	
235-11	21767-21776	transform	
235-12	21777-21783	values	
235-13	21784-21787	can	
235-14	21788-21790	do	
235-15	21791-21795	this	
235-16	21796-21799	for	
235-17	21800-21803	you	
235-18	21803-21804	,	
235-19	21805-21808	and	
235-20	21809-21812	you	
235-21	21813-21817	just	
235-22	21818-21822	need	
235-23	21823-21825	to	
235-24	21826-21831	write	
235-25	21832-21833	a	
235-26	21834-21841	handler	
235-27	21842-21850	function	
235-28	21851-21853	to	
235-29	21854-21861	specify	
235-30	21862-21865	the	
235-31	21866-21880	transformation	
235-32	21881-21886	logic	
235-33	21886-21887	.	

#Text=As I mentioned earlier, the functions
#Text=also have Scalar APIs rather than the SQL API.
236-1	21888-21890	As	
236-2	21891-21892	I	
236-3	21893-21902	mentioned	
236-4	21903-21910	earlier	
236-5	21910-21911	,	
236-6	21912-21915	the	
236-7	21916-21925	functions	
236-8	21926-21930	also	
236-9	21931-21935	have	
236-10	21936-21942	Scalar	
236-11	21943-21947	APIs	
236-12	21948-21954	rather	
236-13	21955-21959	than	
236-14	21960-21963	the	
236-15	21964-21967	SQL	
236-16	21968-21971	API	
236-17	21971-21972	.	

#Text=Here is an example about how to do the
#Text=same thing, but it’s a Scalar API.
237-1	21973-21977	Here	
237-2	21978-21980	is	
237-3	21981-21983	an	
237-4	21984-21991	example	
237-5	21992-21997	about	
237-6	21998-22001	how	
237-7	22002-22004	to	
237-8	22005-22007	do	
237-9	22008-22011	the	
237-10	22012-22016	same	
237-11	22017-22022	thing	
237-12	22022-22023	,	
237-13	22024-22027	but	
237-14	22028-22030	it	
237-15	22030-22031	’	
237-16	22031-22032	s	
237-17	22033-22034	a	
237-18	22035-22041	Scalar	
237-19	22042-22045	API	
237-20	22045-22046	.	

#Text=You can just write a normal Scala function, which
#Text=takes the [kernel?]
238-1	22047-22050	You	
238-2	22051-22054	can	
238-3	22055-22059	just	
238-4	22060-22065	write	
238-5	22066-22067	a	
238-6	22068-22074	normal	
238-7	22075-22080	Scala	
238-8	22081-22089	function	
238-9	22089-22090	,	
238-10	22091-22096	which	
238-11	22097-22102	takes	
238-12	22103-22106	the	
238-13	22107-22108	[	
238-14	22108-22114	kernel	
238-15	22114-22115	?	
238-16	22115-22116	]	

#Text=objects as the input to have the same effect as the SQL API.
239-1	22117-22124	objects	
239-2	22125-22127	as	
239-3	22128-22131	the	
239-4	22132-22137	input	
239-5	22138-22140	to	
239-6	22141-22145	have	
239-7	22146-22149	the	
239-8	22150-22154	same	
239-9	22155-22161	effect	
239-10	22162-22164	as	
239-11	22165-22168	the	
239-12	22169-22172	SQL	
239-13	22173-22176	API	
239-14	22176-22177	.	

#Text=Monitoring and Debuggability
#Text=This release also includes many enhancements and makes the monitoring
#Text=more comprehensive and stable.
240-1	22178-22188	Monitoring	
240-2	22189-22192	and	
240-3	22193-22206	Debuggability	
240-4	22207-22211	This	
240-5	22212-22219	release	
240-6	22220-22224	also	
240-7	22225-22233	includes	
240-8	22234-22238	many	
240-9	22239-22251	enhancements	
240-10	22252-22255	and	
240-11	22256-22261	makes	
240-12	22262-22265	the	
240-13	22266-22276	monitoring	
240-14	22277-22281	more	
240-15	22282-22295	comprehensive	
240-16	22296-22299	and	
240-17	22300-22306	stable	
240-18	22306-22307	.	

#Text=We can make it easier to close out and get back to your
#Text=Spark applications.
241-1	22308-22310	We	
241-2	22311-22314	can	
241-3	22315-22319	make	
241-4	22320-22322	it	
241-5	22323-22329	easier	
241-6	22330-22332	to	
241-7	22333-22338	close	
241-8	22339-22342	out	
241-9	22343-22346	and	
241-10	22347-22350	get	
241-11	22351-22355	back	
241-12	22356-22358	to	
241-13	22359-22363	your	
241-14	22364-22369	Spark	
241-15	22370-22382	applications	
241-16	22382-22383	.	

#Text=Structured Streaming UI
#Text=The first feature I will talk to you about is the new UI for the Spark
#Text=streaming.
242-1	22384-22394	Structured	
242-2	22395-22404	Streaming	
242-3	22405-22407	UI	
242-4	22408-22411	The	
242-5	22412-22417	first	
242-6	22418-22425	feature	
242-7	22426-22427	I	
242-8	22428-22432	will	
242-9	22433-22437	talk	
242-10	22438-22440	to	
242-11	22441-22444	you	
242-12	22445-22450	about	
242-13	22451-22453	is	
242-14	22454-22457	the	
242-15	22458-22461	new	
242-16	22462-22464	UI	
242-17	22465-22468	for	
242-18	22469-22472	the	
242-19	22473-22478	Spark	
242-20	22479-22488	streaming	
242-21	22488-22489	.	

#Text=Here, the drive to show it– Spark streaming was initially introduced in Spark
#Text=2.0.
243-1	22490-22494	Here	
243-2	22494-22495	,	
243-3	22496-22499	the	
243-4	22500-22505	drive	
243-5	22506-22508	to	
243-6	22509-22513	show	
243-7	22514-22516	it	
243-8	22516-22517	–	
243-9	22518-22523	Spark	
243-10	22524-22533	streaming	
243-11	22534-22537	was	
243-12	22538-22547	initially	
243-13	22548-22558	introduced	
243-14	22559-22561	in	
243-15	22562-22567	Spark	
243-16	22568-22571	2.0	
243-17	22571-22572	.	

#Text=This release has the dedicated– it was Spark web UI for inspection of these streaming
#Text=jobs.
244-1	22573-22577	This	
244-2	22578-22585	release	
244-3	22586-22589	has	
244-4	22590-22593	the	
244-5	22594-22603	dedicated	
244-6	22603-22604	–	
244-7	22605-22607	it	
244-8	22608-22611	was	
244-9	22612-22617	Spark	
244-10	22618-22621	web	
244-11	22622-22624	UI	
244-12	22625-22628	for	
244-13	22629-22639	inspection	
244-14	22640-22642	of	
244-15	22643-22648	these	
244-16	22649-22658	streaming	
244-17	22659-22663	jobs	
244-18	22663-22664	.	

#Text=This UI offers two sets of statistics: one, abbreviate information of [completed?]
245-1	22665-22669	This	
245-2	22670-22672	UI	
245-3	22673-22679	offers	
245-4	22680-22683	two	
245-5	22684-22688	sets	
245-6	22689-22691	of	
245-7	22692-22702	statistics	
245-8	22702-22703	:	
245-9	22704-22707	one	
245-10	22707-22708	,	
245-11	22709-22719	abbreviate	
245-12	22720-22731	information	
245-13	22732-22734	of	
245-14	22735-22736	[	
245-15	22736-22745	completed	
245-16	22745-22746	?	
245-17	22746-22747	]	

#Text=streaming queries and two, detailed statistics information about the streaming query including
#Text=the input rate, processor rate, input loads, [inaudible], operation duration and others.
246-1	22748-22757	streaming	
246-2	22758-22765	queries	
246-3	22766-22769	and	
246-4	22770-22773	two	
246-5	22773-22774	,	
246-6	22775-22783	detailed	
246-7	22784-22794	statistics	
246-8	22795-22806	information	
246-9	22807-22812	about	
246-10	22813-22816	the	
246-11	22817-22826	streaming	
246-12	22827-22832	query	
246-13	22833-22842	including	
246-14	22843-22846	the	
246-15	22847-22852	input	
246-16	22853-22857	rate	
246-17	22857-22858	,	
246-18	22859-22868	processor	
246-19	22869-22873	rate	
246-20	22873-22874	,	
246-21	22875-22880	input	
246-22	22881-22886	loads	
246-23	22886-22887	,	
246-24	22888-22889	[	
246-25	22889-22898	inaudible	
246-26	22898-22899	]	
246-27	22899-22900	,	
246-28	22901-22910	operation	
246-29	22911-22919	duration	
246-30	22920-22923	and	
246-31	22924-22930	others	
246-32	22930-22931	.	

#Text=More specifically, the input rate and processor rate means how many records per second the
#Text=streaming software produces and the Spark streaming engine processes.
247-1	22932-22936	More	
247-2	22937-22949	specifically	
247-3	22949-22950	,	
247-4	22951-22954	the	
247-5	22955-22960	input	
247-6	22961-22965	rate	
247-7	22966-22969	and	
247-8	22970-22979	processor	
247-9	22980-22984	rate	
247-10	22985-22990	means	
247-11	22991-22994	how	
247-12	22995-22999	many	
247-13	23000-23007	records	
247-14	23008-23011	per	
247-15	23012-23018	second	
247-16	23019-23022	the	
247-17	23023-23032	streaming	
247-18	23033-23041	software	
247-19	23042-23050	produces	
247-20	23051-23054	and	
247-21	23055-23058	the	
247-22	23059-23064	Spark	
247-23	23065-23074	streaming	
247-24	23075-23081	engine	
247-25	23082-23091	processes	
247-26	23091-23092	.	

#Text=It can give you
#Text=a sense about if the streaming engine is fast enough to process the continuous input data.
248-1	23093-23095	It	
248-2	23096-23099	can	
248-3	23100-23104	give	
248-4	23105-23108	you	
248-5	23109-23110	a	
248-6	23111-23116	sense	
248-7	23117-23122	about	
248-8	23123-23125	if	
248-9	23126-23129	the	
248-10	23130-23139	streaming	
248-11	23140-23146	engine	
248-12	23147-23149	is	
248-13	23150-23154	fast	
248-14	23155-23161	enough	
248-15	23162-23164	to	
248-16	23165-23172	process	
248-17	23173-23176	the	
248-18	23177-23187	continuous	
248-19	23188-23193	input	
248-20	23194-23198	data	
248-21	23198-23199	.	

#Text=Similarly, you can tell it from the past duration as well.
249-1	23200-23209	Similarly	
249-2	23209-23210	,	
249-3	23211-23214	you	
249-4	23215-23218	can	
249-5	23219-23223	tell	
249-6	23224-23226	it	
249-7	23227-23231	from	
249-8	23232-23235	the	
249-9	23236-23240	past	
249-10	23241-23249	duration	
249-11	23250-23252	as	
249-12	23253-23257	well	
249-13	23257-23258	.	

#Text=If many batch takes more time than
#Text=the micro-batch [inaudible], it means the engine is not fast enough to process your
#Text=data, and you may need to enable the [inaudible] feature to make the source produce the data
#Text=slower.
250-1	23259-23261	If	
250-2	23262-23266	many	
250-3	23267-23272	batch	
250-4	23273-23278	takes	
250-5	23279-23283	more	
250-6	23284-23288	time	
250-7	23289-23293	than	
250-8	23294-23297	the	
250-9	23298-23309	micro-batch	
250-10	23310-23311	[	
250-11	23311-23320	inaudible	
250-12	23320-23321	]	
250-13	23321-23322	,	
250-14	23323-23325	it	
250-15	23326-23331	means	
250-16	23332-23335	the	
250-17	23336-23342	engine	
250-18	23343-23345	is	
250-19	23346-23349	not	
250-20	23350-23354	fast	
250-21	23355-23361	enough	
250-22	23362-23364	to	
250-23	23365-23372	process	
250-24	23373-23377	your	
250-25	23378-23382	data	
250-26	23382-23383	,	
250-27	23384-23387	and	
250-28	23388-23391	you	
250-29	23392-23395	may	
250-30	23396-23400	need	
250-31	23401-23403	to	
250-32	23404-23410	enable	
250-33	23411-23414	the	
250-34	23415-23416	[	
250-35	23416-23425	inaudible	
250-36	23425-23426	]	
250-37	23427-23434	feature	
250-38	23435-23437	to	
250-39	23438-23442	make	
250-40	23443-23446	the	
250-41	23447-23453	source	
250-42	23454-23461	produce	
250-43	23462-23465	the	
250-44	23466-23470	data	
250-45	23471-23477	slower	
250-46	23477-23478	.	

#Text=And so operating time is also a very useful matrix.
251-1	23479-23482	And	
251-2	23483-23485	so	
251-3	23486-23495	operating	
251-4	23496-23500	time	
251-5	23501-23503	is	
251-6	23504-23508	also	
251-7	23509-23510	a	
251-8	23511-23515	very	
251-9	23516-23522	useful	
251-10	23523-23529	matrix	
251-11	23529-23530	.	

#Text=It tells you the time spent
#Text=on each operator so that you can know where is the bottleneck in your query.
252-1	23531-23533	It	
252-2	23534-23539	tells	
252-3	23540-23543	you	
252-4	23544-23547	the	
252-5	23548-23552	time	
252-6	23553-23558	spent	
252-7	23559-23561	on	
252-8	23562-23566	each	
252-9	23567-23575	operator	
252-10	23576-23578	so	
252-11	23579-23583	that	
252-12	23584-23587	you	
252-13	23588-23591	can	
252-14	23592-23596	know	
252-15	23597-23602	where	
252-16	23603-23605	is	
252-17	23606-23609	the	
252-18	23610-23620	bottleneck	
252-19	23621-23623	in	
252-20	23624-23628	your	
252-21	23629-23634	query	
252-22	23634-23635	.	

#Text=DDL and DML enhancements
#Text=We also have many different enhancements in DDL and DML commands.
253-1	23636-23639	DDL	
253-2	23640-23643	and	
253-3	23644-23647	DML	
253-4	23648-23660	enhancements	
253-5	23661-23663	We	
253-6	23664-23668	also	
253-7	23669-23673	have	
253-8	23674-23678	many	
253-9	23679-23688	different	
253-10	23689-23701	enhancements	
253-11	23702-23704	in	
253-12	23705-23708	DDL	
253-13	23709-23712	and	
253-14	23713-23716	DML	
253-15	23717-23725	commands	
253-16	23725-23726	.	

#Text=Let
#Text=me talk about the improvements in the EXPLAIN command as an example.
254-1	23727-23730	Let	
254-2	23731-23733	me	
254-3	23734-23738	talk	
254-4	23739-23744	about	
254-5	23745-23748	the	
254-6	23749-23761	improvements	
254-7	23762-23764	in	
254-8	23765-23768	the	
254-9	23769-23776	EXPLAIN	
254-10	23777-23784	command	
254-11	23785-23787	as	
254-12	23788-23790	an	
254-13	23791-23798	example	
254-14	23798-23799	.	

#Text=This is a typical output
#Text=of the EXPLAIN command.
255-1	23800-23804	This	
255-2	23805-23807	is	
255-3	23808-23809	a	
255-4	23810-23817	typical	
255-5	23818-23824	output	
255-6	23825-23827	of	
255-7	23828-23831	the	
255-8	23832-23839	EXPLAIN	
255-9	23840-23847	command	
255-10	23847-23848	.	

#Text=You have many operators in the query plan tree and some operators
#Text=have other additional information.
256-1	23849-23852	You	
256-2	23853-23857	have	
256-3	23858-23862	many	
256-4	23863-23872	operators	
256-5	23873-23875	in	
256-6	23876-23879	the	
256-7	23880-23885	query	
256-8	23886-23890	plan	
256-9	23891-23895	tree	
256-10	23896-23899	and	
256-11	23900-23904	some	
256-12	23905-23914	operators	
256-13	23915-23919	have	
256-14	23920-23925	other	
256-15	23926-23936	additional	
256-16	23937-23948	information	
256-17	23948-23949	.	

#Text=Reading plans is critical for understanding and attuning
#Text=queries.
257-1	23950-23957	Reading	
257-2	23958-23963	plans	
257-3	23964-23966	is	
257-4	23967-23975	critical	
257-5	23976-23979	for	
257-6	23980-23993	understanding	
257-7	23994-23997	and	
257-8	23998-24006	attuning	
257-9	24007-24014	queries	
257-10	24014-24015	.	

#Text=The existing solution looks [inaudible], and, as a stream of each operator, can be
#Text=very wide or even truncated.
258-1	24016-24019	The	
258-2	24020-24028	existing	
258-3	24029-24037	solution	
258-4	24038-24043	looks	
258-5	24044-24045	[	
258-6	24045-24054	inaudible	
258-7	24054-24055	]	
258-8	24055-24056	,	
258-9	24057-24060	and	
258-10	24060-24061	,	
258-11	24062-24064	as	
258-12	24065-24066	a	
258-13	24067-24073	stream	
258-14	24074-24076	of	
258-15	24077-24081	each	
258-16	24082-24090	operator	
258-17	24090-24091	,	
258-18	24092-24095	can	
258-19	24096-24098	be	
258-20	24099-24103	very	
258-21	24104-24108	wide	
258-22	24109-24111	or	
258-23	24112-24116	even	
258-24	24117-24126	truncated	
258-25	24126-24127	.	

#Text=And it becomes wider and wider each release as we add more
#Text=and more information in the operator to help debugging.
259-1	24128-24131	And	
259-2	24132-24134	it	
259-3	24135-24142	becomes	
259-4	24143-24148	wider	
259-5	24149-24152	and	
259-6	24153-24158	wider	
259-7	24159-24163	each	
259-8	24164-24171	release	
259-9	24172-24174	as	
259-10	24175-24177	we	
259-11	24178-24181	add	
259-12	24182-24186	more	
259-13	24187-24190	and	
259-14	24191-24195	more	
259-15	24196-24207	information	
259-16	24208-24210	in	
259-17	24211-24214	the	
259-18	24215-24223	operator	
259-19	24224-24226	to	
259-20	24227-24231	help	
259-21	24232-24241	debugging	
259-22	24241-24242	.	

#Text=This release, we enhance the EXPLAIN command with a new formatted mode and also provided a capability to dump the plans to
#Text=the files.
260-1	24243-24247	This	
260-2	24248-24255	release	
260-3	24255-24256	,	
260-4	24257-24259	we	
260-5	24260-24267	enhance	
260-6	24268-24271	the	
260-7	24272-24279	EXPLAIN	
260-8	24280-24287	command	
260-9	24288-24292	with	
260-10	24293-24294	a	
260-11	24295-24298	new	
260-12	24299-24308	formatted	
260-13	24309-24313	mode	
260-14	24314-24317	and	
260-15	24318-24322	also	
260-16	24323-24331	provided	
260-17	24332-24333	a	
260-18	24334-24344	capability	
260-19	24345-24347	to	
260-20	24348-24352	dump	
260-21	24353-24356	the	
260-22	24357-24362	plans	
260-23	24363-24365	to	
260-24	24366-24369	the	
260-25	24370-24375	files	
260-26	24375-24376	.	

#Text=You can see it becomes much easier to read and understand.
261-1	24377-24380	You	
261-2	24381-24384	can	
261-3	24385-24388	see	
261-4	24389-24391	it	
261-5	24392-24399	becomes	
261-6	24400-24404	much	
261-7	24405-24411	easier	
261-8	24412-24414	to	
261-9	24415-24419	read	
261-10	24420-24423	and	
261-11	24424-24434	understand	
261-12	24434-24435	.	

#Text=So here is a very
#Text=simple plan tree at the beginning.
262-1	24436-24438	So	
262-2	24439-24443	here	
262-3	24444-24446	is	
262-4	24447-24448	a	
262-5	24449-24453	very	
262-6	24454-24460	simple	
262-7	24461-24465	plan	
262-8	24466-24470	tree	
262-9	24471-24473	at	
262-10	24474-24477	the	
262-11	24478-24487	beginning	
262-12	24487-24488	.	

#Text=Then follows a detailed section for each operator.
263-1	24489-24493	Then	
263-2	24494-24501	follows	
263-3	24502-24503	a	
263-4	24504-24512	detailed	
263-5	24513-24520	section	
263-6	24521-24524	for	
263-7	24525-24529	each	
263-8	24530-24538	operator	
263-9	24538-24539	.	

#Text=This
#Text=makes it very easy to get an overview of the query by looking at the plan tree.
264-1	24540-24544	This	
264-2	24545-24550	makes	
264-3	24551-24553	it	
264-4	24554-24558	very	
264-5	24559-24563	easy	
264-6	24564-24566	to	
264-7	24567-24570	get	
264-8	24571-24573	an	
264-9	24574-24582	overview	
264-10	24583-24585	of	
264-11	24586-24589	the	
264-12	24590-24595	query	
264-13	24596-24598	by	
264-14	24599-24606	looking	
264-15	24607-24609	at	
264-16	24610-24613	the	
264-17	24614-24618	plan	
264-18	24619-24623	tree	
264-19	24623-24624	.	

#Text=It also
#Text=makes it very easy to see the details of each operator as the information is now stacked
#Text=vertically.
265-1	24625-24627	It	
265-2	24628-24632	also	
265-3	24633-24638	makes	
265-4	24639-24641	it	
265-5	24642-24646	very	
265-6	24647-24651	easy	
265-7	24652-24654	to	
265-8	24655-24658	see	
265-9	24659-24662	the	
265-10	24663-24670	details	
265-11	24671-24673	of	
265-12	24674-24678	each	
265-13	24679-24687	operator	
265-14	24688-24690	as	
265-15	24691-24694	the	
265-16	24695-24706	information	
265-17	24707-24709	is	
265-18	24710-24713	now	
265-19	24714-24721	stacked	
265-20	24722-24732	vertically	
265-21	24732-24733	.	

#Text=And in the end, there is a section to show all the subqueries.
266-1	24734-24737	And	
266-2	24738-24740	in	
266-3	24741-24744	the	
266-4	24745-24748	end	
266-5	24748-24749	,	
266-6	24750-24755	there	
266-7	24756-24758	is	
266-8	24759-24760	a	
266-9	24761-24768	section	
266-10	24769-24771	to	
266-11	24772-24776	show	
266-12	24777-24780	all	
266-13	24781-24784	the	
266-14	24785-24795	subqueries	
266-15	24795-24796	.	

#Text=In the future
#Text=releases, we will add more and more useful information for each operator.
267-1	24797-24799	In	
267-2	24800-24803	the	
267-3	24804-24810	future	
267-4	24811-24819	releases	
267-5	24819-24820	,	
267-6	24821-24823	we	
267-7	24824-24828	will	
267-8	24829-24832	add	
267-9	24833-24837	more	
267-10	24838-24841	and	
267-11	24842-24846	more	
267-12	24847-24853	useful	
267-13	24854-24865	information	
267-14	24866-24869	for	
267-15	24870-24874	each	
267-16	24875-24883	operator	
267-17	24883-24884	.	

#Text=This release, we also introduced a new API to define your own metrics to observe data quality.
268-1	24885-24889	This	
268-2	24890-24897	release	
268-3	24897-24898	,	
268-4	24899-24901	we	
268-5	24902-24906	also	
268-6	24907-24917	introduced	
268-7	24918-24919	a	
268-8	24920-24923	new	
268-9	24924-24927	API	
268-10	24928-24930	to	
268-11	24931-24937	define	
268-12	24938-24942	your	
268-13	24943-24946	own	
268-14	24947-24954	metrics	
268-15	24955-24957	to	
268-16	24958-24965	observe	
268-17	24966-24970	data	
268-18	24971-24978	quality	
268-19	24978-24979	.	

#Text=Data quality is very important to many applications.
269-1	24980-24984	Data	
269-2	24985-24992	quality	
269-3	24993-24995	is	
269-4	24996-25000	very	
269-5	25001-25010	important	
269-6	25011-25013	to	
269-7	25014-25018	many	
269-8	25019-25031	applications	
269-9	25031-25032	.	

#Text=It’s usually easy to
#Text=define metrics for data quality by some [other?]
270-1	25033-25035	It	
270-2	25035-25036	’	
270-3	25036-25037	s	
270-4	25038-25045	usually	
270-5	25046-25050	easy	
270-6	25051-25053	to	
270-7	25054-25060	define	
270-8	25061-25068	metrics	
270-9	25069-25072	for	
270-10	25073-25077	data	
270-11	25078-25085	quality	
270-12	25086-25088	by	
270-13	25089-25093	some	
270-14	25094-25095	[	
270-15	25095-25100	other	
270-16	25100-25101	?	
270-17	25101-25102	]	

#Text=function, for example, but it’s also hard
#Text=to calculate the metrics, especially for streaming queries.
271-1	25103-25111	function	
271-2	25111-25112	,	
271-3	25113-25116	for	
271-4	25117-25124	example	
271-5	25124-25125	,	
271-6	25126-25129	but	
271-7	25130-25132	it	
271-8	25132-25133	’	
271-9	25133-25134	s	
271-10	25135-25139	also	
271-11	25140-25144	hard	
271-12	25145-25147	to	
271-13	25148-25157	calculate	
271-14	25158-25161	the	
271-15	25162-25169	metrics	
271-16	25169-25170	,	
271-17	25171-25181	especially	
271-18	25182-25185	for	
271-19	25186-25195	streaming	
271-20	25196-25203	queries	
271-21	25203-25204	.	

#Text=For example, you want to keep monitoring
#Text=the data quality of your streaming source.
272-1	25205-25208	For	
272-2	25209-25216	example	
272-3	25216-25217	,	
272-4	25218-25221	you	
272-5	25222-25226	want	
272-6	25227-25229	to	
272-7	25230-25234	keep	
272-8	25235-25245	monitoring	
272-9	25246-25249	the	
272-10	25250-25254	data	
272-11	25255-25262	quality	
272-12	25263-25265	of	
272-13	25266-25270	your	
272-14	25271-25280	streaming	
272-15	25281-25287	source	
272-16	25287-25288	.	

#Text=You can simply define the metrics as the percentage of the error records.
273-1	25289-25292	You	
273-2	25293-25296	can	
273-3	25297-25303	simply	
273-4	25304-25310	define	
273-5	25311-25314	the	
273-6	25315-25322	metrics	
273-7	25323-25325	as	
273-8	25326-25329	the	
273-9	25330-25340	percentage	
273-10	25341-25343	of	
273-11	25344-25347	the	
273-12	25348-25353	error	
273-13	25354-25361	records	
273-14	25361-25362	.	

#Text=Then you can do two things.
274-1	25363-25367	Then	
274-2	25368-25371	you	
274-3	25372-25375	can	
274-4	25376-25378	do	
274-5	25379-25382	two	
274-6	25383-25389	things	
274-7	25389-25390	.	

#Text=Make it a habit.
275-1	25391-25395	Make	
275-2	25396-25398	it	
275-3	25399-25400	a	
275-4	25401-25406	habit	
275-5	25406-25407	.	

#Text=One, code observe
#Text=method of the streaming error rate to define your metrics with a name and the start
#Text=of stream.
276-1	25408-25411	One	
276-2	25411-25412	,	
276-3	25413-25417	code	
276-4	25418-25425	observe	
276-5	25426-25432	method	
276-6	25433-25435	of	
276-7	25436-25439	the	
276-8	25440-25449	streaming	
276-9	25450-25455	error	
276-10	25456-25460	rate	
276-11	25461-25463	to	
276-12	25464-25470	define	
276-13	25471-25475	your	
276-14	25476-25483	metrics	
276-15	25484-25488	with	
276-16	25489-25490	a	
276-17	25491-25495	name	
276-18	25496-25499	and	
276-19	25500-25503	the	
276-20	25504-25509	start	
276-21	25510-25512	of	
276-22	25513-25519	stream	
276-23	25519-25520	.	

#Text=So this example, the name is data quality and the matrix, it just will count
#Text=the error record and see how many percent of it in the total lookups.
277-1	25521-25523	So	
277-2	25524-25528	this	
277-3	25529-25536	example	
277-4	25536-25537	,	
277-5	25538-25541	the	
277-6	25542-25546	name	
277-7	25547-25549	is	
277-8	25550-25554	data	
277-9	25555-25562	quality	
277-10	25563-25566	and	
277-11	25567-25570	the	
277-12	25571-25577	matrix	
277-13	25577-25578	,	
277-14	25579-25581	it	
277-15	25582-25586	just	
277-16	25587-25591	will	
277-17	25592-25597	count	
277-18	25598-25601	the	
277-19	25602-25607	error	
277-20	25608-25614	record	
277-21	25615-25618	and	
277-22	25619-25622	see	
277-23	25623-25626	how	
277-24	25627-25631	many	
277-25	25632-25639	percent	
277-26	25640-25642	of	
277-27	25643-25645	it	
277-28	25646-25648	in	
277-29	25649-25652	the	
277-30	25653-25658	total	
277-31	25659-25666	lookups	
277-32	25666-25667	.	

#Text=Two, you add a
#Text=listener to watch the streaming process events, and in the case of your matrix, the name,
#Text=do whatever you want to do, such as sending an email if there are more than 5% error data.
278-1	25668-25671	Two	
278-2	25671-25672	,	
278-3	25673-25676	you	
278-4	25677-25680	add	
278-5	25681-25682	a	
278-6	25683-25691	listener	
278-7	25692-25694	to	
278-8	25695-25700	watch	
278-9	25701-25704	the	
278-10	25705-25714	streaming	
278-11	25715-25722	process	
278-12	25723-25729	events	
278-13	25729-25730	,	
278-14	25731-25734	and	
278-15	25735-25737	in	
278-16	25738-25741	the	
278-17	25742-25746	case	
278-18	25747-25749	of	
278-19	25750-25754	your	
278-20	25755-25761	matrix	
278-21	25761-25762	,	
278-22	25763-25766	the	
278-23	25767-25771	name	
278-24	25771-25772	,	
278-25	25773-25775	do	
278-26	25776-25784	whatever	
278-27	25785-25788	you	
278-28	25789-25793	want	
278-29	25794-25796	to	
278-30	25797-25799	do	
278-31	25799-25800	,	
278-32	25801-25805	such	
278-33	25806-25808	as	
278-34	25809-25816	sending	
278-35	25817-25819	an	
278-36	25820-25825	email	
278-37	25826-25828	if	
278-38	25829-25834	there	
278-39	25835-25838	are	
278-40	25839-25843	more	
278-41	25844-25848	than	
278-42	25849-25851	5%	
278-43	25852-25857	error	
278-44	25858-25862	data	
278-45	25862-25863	.	

#Text=SQL Compatibility
#Text=Now, let’s move to the next topic.
279-1	25864-25867	SQL	
279-2	25868-25881	Compatibility	
279-3	25882-25885	Now	
279-4	25885-25886	,	
279-5	25887-25890	let	
279-6	25890-25891	’	
279-7	25891-25892	s	
279-8	25893-25897	move	
279-9	25898-25900	to	
279-10	25901-25904	the	
279-11	25905-25909	next	
279-12	25910-25915	topic	
279-13	25915-25916	.	

#Text=SQL compatibility is also super critical
#Text=for workloads mapped from the other database systems through Spark SQL.
280-1	25917-25920	SQL	
280-2	25921-25934	compatibility	
280-3	25935-25937	is	
280-4	25938-25942	also	
280-5	25943-25948	super	
280-6	25949-25957	critical	
280-7	25958-25961	for	
280-8	25962-25971	workloads	
280-9	25972-25978	mapped	
280-10	25979-25983	from	
280-11	25984-25987	the	
280-12	25988-25993	other	
280-13	25994-26002	database	
280-14	26003-26010	systems	
280-15	26011-26018	through	
280-16	26019-26024	Spark	
280-17	26025-26028	SQL	
280-18	26028-26029	.	

#Text=In this release,
#Text=we introduced the ANSI store assignment policy for table insertion.
281-1	26030-26032	In	
281-2	26033-26037	this	
281-3	26038-26045	release	
281-4	26045-26046	,	
281-5	26047-26049	we	
281-6	26050-26060	introduced	
281-7	26061-26064	the	
281-8	26065-26069	ANSI	
281-9	26070-26075	store	
281-10	26076-26086	assignment	
281-11	26087-26093	policy	
281-12	26094-26097	for	
281-13	26098-26103	table	
281-14	26104-26113	insertion	
281-15	26113-26114	.	

#Text=We added runtime overall
#Text=checking with respect to ANSI results keywords into the parser.
282-1	26115-26117	We	
282-2	26118-26123	added	
282-3	26124-26131	runtime	
282-4	26132-26139	overall	
282-5	26140-26148	checking	
282-6	26149-26153	with	
282-7	26154-26161	respect	
282-8	26162-26164	to	
282-9	26165-26169	ANSI	
282-10	26170-26177	results	
282-11	26178-26186	keywords	
282-12	26187-26191	into	
282-13	26192-26195	the	
282-14	26196-26202	parser	
282-15	26202-26203	.	

#Text=We also switched the calendar
#Text=to the widely-used calendar which is the ISO and SQL standard.
283-1	26204-26206	We	
283-2	26207-26211	also	
283-3	26212-26220	switched	
283-4	26221-26224	the	
283-5	26225-26233	calendar	
283-6	26234-26236	to	
283-7	26237-26240	the	
283-8	26241-26252	widely-used	
283-9	26253-26261	calendar	
283-10	26262-26267	which	
283-11	26268-26270	is	
283-12	26271-26274	the	
283-13	26275-26278	ISO	
283-14	26279-26282	and	
283-15	26283-26286	SQL	
283-16	26287-26295	standard	
283-17	26295-26296	.	

#Text=Let’s look at how the first
#Text=two features can help you to enforce data quality.
284-1	26297-26300	Let	
284-2	26300-26301	’	
284-3	26301-26302	s	
284-4	26303-26307	look	
284-5	26308-26310	at	
284-6	26311-26314	how	
284-7	26315-26318	the	
284-8	26319-26324	first	
284-9	26325-26328	two	
284-10	26329-26337	features	
284-11	26338-26341	can	
284-12	26342-26346	help	
284-13	26347-26350	you	
284-14	26351-26353	to	
284-15	26354-26361	enforce	
284-16	26362-26366	data	
284-17	26367-26374	quality	
284-18	26374-26375	.	

#Text=I say more about the assignment.
285-1	26376-26377	I	
285-2	26378-26381	say	
285-3	26382-26386	more	
285-4	26387-26392	about	
285-5	26393-26396	the	
285-6	26397-26407	assignment	
285-7	26407-26408	.	

#Text=It’s something like assigning a value to a variable in programming language.
286-1	26409-26411	It	
286-2	26411-26412	’	
286-3	26412-26413	s	
286-4	26414-26423	something	
286-5	26424-26428	like	
286-6	26429-26438	assigning	
286-7	26439-26440	a	
286-8	26441-26446	value	
286-9	26447-26449	to	
286-10	26450-26451	a	
286-11	26452-26460	variable	
286-12	26461-26463	in	
286-13	26464-26475	programming	
286-14	26476-26484	language	
286-15	26484-26485	.	

#Text=In the SQL
#Text=world, it is table insertion or upsert, which is kind of assigning values to a table column.
287-1	26486-26488	In	
287-2	26489-26492	the	
287-3	26493-26496	SQL	
287-4	26497-26502	world	
287-5	26502-26503	,	
287-6	26504-26506	it	
287-7	26507-26509	is	
287-8	26510-26515	table	
287-9	26516-26525	insertion	
287-10	26526-26528	or	
287-11	26529-26535	upsert	
287-12	26535-26536	,	
287-13	26537-26542	which	
287-14	26543-26545	is	
287-15	26546-26550	kind	
287-16	26551-26553	of	
287-17	26554-26563	assigning	
287-18	26564-26570	values	
287-19	26571-26573	to	
287-20	26574-26575	a	
287-21	26576-26581	table	
287-22	26582-26588	column	
287-23	26588-26589	.	

#Text=Now, let’s see an example.
288-1	26590-26593	Now	
288-2	26593-26594	,	
288-3	26595-26598	let	
288-4	26598-26599	’	
288-5	26599-26600	s	
288-6	26601-26604	see	
288-7	26605-26607	an	
288-8	26608-26615	example	
288-9	26615-26616	.	

#Text=Assume there is a table with two columns, I and J, which are type int and
#Text=type string.
289-1	26617-26623	Assume	
289-2	26624-26629	there	
289-3	26630-26632	is	
289-4	26633-26634	a	
289-5	26635-26640	table	
289-6	26641-26645	with	
289-7	26646-26649	two	
289-8	26650-26657	columns	
289-9	26657-26658	,	
289-10	26659-26660	I	
289-11	26661-26664	and	
289-12	26665-26666	J	
289-13	26666-26667	,	
289-14	26668-26673	which	
289-15	26674-26677	are	
289-16	26678-26682	type	
289-17	26683-26686	int	
289-18	26687-26690	and	
289-19	26691-26695	type	
289-20	26696-26702	string	
289-21	26702-26703	.	

#Text=If we write a int value to the string column, it’s totally okay.
290-1	26704-26706	If	
290-2	26707-26709	we	
290-3	26710-26715	write	
290-4	26716-26717	a	
290-5	26718-26721	int	
290-6	26722-26727	value	
290-7	26728-26730	to	
290-8	26731-26734	the	
290-9	26735-26741	string	
290-10	26742-26748	column	
290-11	26748-26749	,	
290-12	26750-26752	it	
290-13	26752-26753	’	
290-14	26753-26754	s	
290-15	26755-26762	totally	
290-16	26763-26767	okay	
290-17	26767-26768	.	

#Text=It’s totally
#Text=safe.
291-1	26769-26771	It	
291-2	26771-26772	’	
291-3	26772-26773	s	
291-4	26774-26781	totally	
291-5	26782-26786	safe	
291-6	26786-26787	.	

#Text=However, if we write a string value to the int column, it’s risky.
292-1	26788-26795	However	
292-2	26795-26796	,	
292-3	26797-26799	if	
292-4	26800-26802	we	
292-5	26803-26808	write	
292-6	26809-26810	a	
292-7	26811-26817	string	
292-8	26818-26823	value	
292-9	26824-26826	to	
292-10	26827-26830	the	
292-11	26831-26834	int	
292-12	26835-26841	column	
292-13	26841-26842	,	
292-14	26843-26845	it	
292-15	26845-26846	’	
292-16	26846-26847	s	
292-17	26848-26853	risky	
292-18	26853-26854	.	

#Text=The string
#Text=value is very likely to not be in integer form, and Spark will fail and worry about
#Text=it.
293-1	26855-26858	The	
293-2	26859-26865	string	
293-3	26866-26871	value	
293-4	26872-26874	is	
293-5	26875-26879	very	
293-6	26880-26886	likely	
293-7	26887-26889	to	
293-8	26890-26893	not	
293-9	26894-26896	be	
293-10	26897-26899	in	
293-11	26900-26907	integer	
293-12	26908-26912	form	
293-13	26912-26913	,	
293-14	26914-26917	and	
293-15	26918-26923	Spark	
293-16	26924-26928	will	
293-17	26929-26933	fail	
293-18	26934-26937	and	
293-19	26938-26943	worry	
293-20	26944-26949	about	
293-21	26950-26952	it	
293-22	26952-26953	.	

#Text=If you do believe your string values are safe to be inserted into an int column, you
#Text=can add a cast manually to bypass the type check in Spark.
294-1	26954-26956	If	
294-2	26957-26960	you	
294-3	26961-26963	do	
294-4	26964-26971	believe	
294-5	26972-26976	your	
294-6	26977-26983	string	
294-7	26984-26990	values	
294-8	26991-26994	are	
294-9	26995-26999	safe	
294-10	27000-27002	to	
294-11	27003-27005	be	
294-12	27006-27014	inserted	
294-13	27015-27019	into	
294-14	27020-27022	an	
294-15	27023-27026	int	
294-16	27027-27033	column	
294-17	27033-27034	,	
294-18	27035-27038	you	
294-19	27039-27042	can	
294-20	27043-27046	add	
294-21	27047-27048	a	
294-22	27049-27053	cast	
294-23	27054-27062	manually	
294-24	27063-27065	to	
294-25	27066-27072	bypass	
294-26	27073-27076	the	
294-27	27077-27081	type	
294-28	27082-27087	check	
294-29	27088-27090	in	
294-30	27091-27096	Spark	
294-31	27096-27097	.	

#Text=We can also write long type
#Text=of values to the int column, and Spark will do the overflow check at runtime.
295-1	27098-27100	We	
295-2	27101-27104	can	
295-3	27105-27109	also	
295-4	27110-27115	write	
295-5	27116-27120	long	
295-6	27121-27125	type	
295-7	27126-27128	of	
295-8	27129-27135	values	
295-9	27136-27138	to	
295-10	27139-27142	the	
295-11	27143-27146	int	
295-12	27147-27153	column	
295-13	27153-27154	,	
295-14	27155-27158	and	
295-15	27159-27164	Spark	
295-16	27165-27169	will	
295-17	27170-27172	do	
295-18	27173-27176	the	
295-19	27177-27185	overflow	
295-20	27186-27191	check	
295-21	27192-27194	at	
295-22	27195-27202	runtime	
295-23	27202-27203	.	

#Text=If your
#Text=input data is invalid, Spark will be show exception at runtime to tell you about it.
296-1	27204-27206	If	
296-2	27207-27211	your	
296-3	27212-27217	input	
296-4	27218-27222	data	
296-5	27223-27225	is	
296-6	27226-27233	invalid	
296-7	27233-27234	,	
296-8	27235-27240	Spark	
296-9	27241-27245	will	
296-10	27246-27248	be	
296-11	27249-27253	show	
296-12	27254-27263	exception	
296-13	27264-27266	at	
296-14	27267-27274	runtime	
296-15	27275-27277	to	
296-16	27278-27282	tell	
296-17	27283-27286	you	
296-18	27287-27292	about	
296-19	27293-27295	it	
296-20	27295-27296	.	

#Text=In this example, the integer one is okay, but the larger value below can’t fit the integer
#Text=type, and you’ll receive this error if you run this table insertion command which tells
#Text=you about the overflow problem.
297-1	27297-27299	In	
297-2	27300-27304	this	
297-3	27305-27312	example	
297-4	27312-27313	,	
297-5	27314-27317	the	
297-6	27318-27325	integer	
297-7	27326-27329	one	
297-8	27330-27332	is	
297-9	27333-27337	okay	
297-10	27337-27338	,	
297-11	27339-27342	but	
297-12	27343-27346	the	
297-13	27347-27353	larger	
297-14	27354-27359	value	
297-15	27360-27365	below	
297-16	27366-27369	can	
297-17	27369-27370	’	
297-18	27370-27371	t	
297-19	27372-27375	fit	
297-20	27376-27379	the	
297-21	27380-27387	integer	
297-22	27388-27392	type	
297-23	27392-27393	,	
297-24	27394-27397	and	
297-25	27398-27401	you	
297-26	27401-27402	’	
297-27	27402-27404	ll	
297-28	27405-27412	receive	
297-29	27413-27417	this	
297-30	27418-27423	error	
297-31	27424-27426	if	
297-32	27427-27430	you	
297-33	27431-27434	run	
297-34	27435-27439	this	
297-35	27440-27445	table	
297-36	27446-27455	insertion	
297-37	27456-27463	command	
297-38	27464-27469	which	
297-39	27470-27475	tells	
297-40	27476-27479	you	
297-41	27480-27485	about	
297-42	27486-27489	the	
297-43	27490-27498	overflow	
297-44	27499-27506	problem	
297-45	27506-27507	.	

#Text=Built-in Data Source Enhancements
#Text=Also, this release enhances built-in data sources.
298-1	27508-27516	Built-in	
298-2	27517-27521	Data	
298-3	27522-27528	Source	
298-4	27529-27541	Enhancements	
298-5	27542-27546	Also	
298-6	27546-27547	,	
298-7	27548-27552	this	
298-8	27553-27560	release	
298-9	27561-27569	enhances	
298-10	27570-27578	built-in	
298-11	27579-27583	data	
298-12	27584-27591	sources	
298-13	27591-27592	.	

#Text=For example, to
#Text=populate data source, we can’t do nested column and filter pushdown.
299-1	27593-27596	For	
299-2	27597-27604	example	
299-3	27604-27605	,	
299-4	27606-27608	to	
299-5	27609-27617	populate	
299-6	27618-27622	data	
299-7	27623-27629	source	
299-8	27629-27630	,	
299-9	27631-27633	we	
299-10	27634-27637	can	
299-11	27637-27638	’	
299-12	27638-27639	t	
299-13	27640-27642	do	
299-14	27643-27649	nested	
299-15	27650-27656	column	
299-16	27657-27660	and	
299-17	27661-27667	filter	
299-18	27668-27676	pushdown	
299-19	27676-27677	.	

#Text=Also, we support
#Text=[inaudible] for CSV files.
300-1	27678-27682	Also	
300-2	27682-27683	,	
300-3	27684-27686	we	
300-4	27687-27694	support	
300-5	27695-27696	[	
300-6	27696-27705	inaudible	
300-7	27705-27706	]	
300-8	27707-27710	for	
300-9	27711-27714	CSV	
300-10	27715-27720	files	
300-11	27720-27721	.	

#Text=This release also introduced a new [inaudible] resource and
#Text=also a new [inaudible] resource for testing and benchmarking.
301-1	27722-27726	This	
301-2	27727-27734	release	
301-3	27735-27739	also	
301-4	27740-27750	introduced	
301-5	27751-27752	a	
301-6	27753-27756	new	
301-7	27757-27758	[	
301-8	27758-27767	inaudible	
301-9	27767-27768	]	
301-10	27769-27777	resource	
301-11	27778-27781	and	
301-12	27782-27786	also	
301-13	27787-27788	a	
301-14	27789-27792	new	
301-15	27793-27794	[	
301-16	27794-27803	inaudible	
301-17	27803-27804	]	
301-18	27805-27813	resource	
301-19	27814-27817	for	
301-20	27818-27825	testing	
301-21	27826-27829	and	
301-22	27830-27842	benchmarking	
301-23	27842-27843	.	

#Text=Let me further introduce
#Text=the origin of nested columns in Parquet and ORC resource.
302-1	27844-27847	Let	
302-2	27848-27850	me	
302-3	27851-27858	further	
302-4	27859-27868	introduce	
302-5	27869-27872	the	
302-6	27873-27879	origin	
302-7	27880-27882	of	
302-8	27883-27889	nested	
302-9	27890-27897	columns	
302-10	27898-27900	in	
302-11	27901-27908	Parquet	
302-12	27909-27912	and	
302-13	27913-27916	ORC	
302-14	27917-27925	resource	
302-15	27925-27926	.	

#Text=The first one is a kind of [baloney?].
303-1	27927-27930	The	
303-2	27931-27936	first	
303-3	27937-27940	one	
303-4	27941-27943	is	
303-5	27944-27945	a	
303-6	27946-27950	kind	
303-7	27951-27953	of	
303-8	27954-27955	[	
303-9	27955-27962	baloney	
303-10	27962-27963	?	
303-11	27963-27964	]	
303-12	27964-27965	.	

#Text=[inaudible] like [inaudible] and [ORC?]
304-1	27966-27967	[	
304-2	27967-27976	inaudible	
304-3	27976-27977	]	
304-4	27978-27982	like	
304-5	27983-27984	[	
304-6	27984-27993	inaudible	
304-7	27993-27994	]	
304-8	27995-27998	and	
304-9	27999-28000	[	
304-10	28000-28003	ORC	
304-11	28003-28004	?	
304-12	28004-28005	]	

#Text=, we can skip reading some [inaudible] in the blocks
#Text=if they don’t contain the columns we need.
305-1	28005-28006	,	
305-2	28007-28009	we	
305-3	28010-28013	can	
305-4	28014-28018	skip	
305-5	28019-28026	reading	
305-6	28027-28031	some	
305-7	28032-28033	[	
305-8	28033-28042	inaudible	
305-9	28042-28043	]	
305-10	28044-28046	in	
305-11	28047-28050	the	
305-12	28051-28057	blocks	
305-13	28058-28060	if	
305-14	28061-28065	they	
305-15	28066-28069	don	
305-16	28069-28070	’	
305-17	28070-28071	t	
305-18	28072-28079	contain	
305-19	28080-28083	the	
305-20	28084-28091	columns	
305-21	28092-28094	we	
305-22	28095-28099	need	
305-23	28099-28100	.	

#Text=This [technique?]
306-1	28101-28105	This	
306-2	28106-28107	[	
306-3	28107-28116	technique	
306-4	28116-28117	?	
306-5	28117-28118	]	

#Text=can be applied to nested
#Text=columns as well in Spark 2.0.
307-1	28119-28122	can	
307-2	28123-28125	be	
307-3	28126-28133	applied	
307-4	28134-28136	to	
307-5	28137-28143	nested	
307-6	28144-28151	columns	
307-7	28152-28154	as	
307-8	28155-28159	well	
307-9	28160-28162	in	
307-10	28163-28168	Spark	
307-11	28169-28172	2.0	
307-12	28172-28173	.	

#Text=To check if your query– in Spark 3.0.
308-1	28174-28176	To	
308-2	28177-28182	check	
308-3	28183-28185	if	
308-4	28186-28190	your	
308-5	28191-28196	query	
308-6	28196-28197	–	
308-7	28198-28200	in	
308-8	28201-28206	Spark	
308-9	28207-28210	3.0	
308-10	28210-28211	.	

#Text=To check if your
#Text=query can benefit from this [inaudible] or not, you can run the EXPLAIN command and see
#Text=if the read schema over the file scan note strips the [inaudible] nested columns.
309-1	28212-28214	To	
309-2	28215-28220	check	
309-3	28221-28223	if	
309-4	28224-28228	your	
309-5	28229-28234	query	
309-6	28235-28238	can	
309-7	28239-28246	benefit	
309-8	28247-28251	from	
309-9	28252-28256	this	
309-10	28257-28258	[	
309-11	28258-28267	inaudible	
309-12	28267-28268	]	
309-13	28269-28271	or	
309-14	28272-28275	not	
309-15	28275-28276	,	
309-16	28277-28280	you	
309-17	28281-28284	can	
309-18	28285-28288	run	
309-19	28289-28292	the	
309-20	28293-28300	EXPLAIN	
309-21	28301-28308	command	
309-22	28309-28312	and	
309-23	28313-28316	see	
309-24	28317-28319	if	
309-25	28320-28323	the	
309-26	28324-28328	read	
309-27	28329-28335	schema	
309-28	28336-28340	over	
309-29	28341-28344	the	
309-30	28345-28349	file	
309-31	28350-28354	scan	
309-32	28355-28359	note	
309-33	28360-28366	strips	
309-34	28367-28370	the	
309-35	28371-28372	[	
309-36	28372-28381	inaudible	
309-37	28381-28382	]	
309-38	28383-28389	nested	
309-39	28390-28397	columns	
309-40	28397-28398	.	

#Text=In
#Text=this example, only the nested column is inserted, so the read schema only contains A.
310-1	28399-28401	In	
310-2	28402-28406	this	
310-3	28407-28414	example	
310-4	28414-28415	,	
310-5	28416-28420	only	
310-6	28421-28424	the	
310-7	28425-28431	nested	
310-8	28432-28438	column	
310-9	28439-28441	is	
310-10	28442-28450	inserted	
310-11	28450-28451	,	
310-12	28452-28454	so	
310-13	28455-28458	the	
310-14	28459-28463	read	
310-15	28464-28470	schema	
310-16	28471-28475	only	
310-17	28476-28484	contains	
310-18	28485-28486	A	
310-19	28486-28487	.	

#Text=[inaudible] is also a very popular technical [inaudible].
311-1	28488-28489	[	
311-2	28489-28498	inaudible	
311-3	28498-28499	]	
311-4	28500-28502	is	
311-5	28503-28507	also	
311-6	28508-28509	a	
311-7	28510-28514	very	
311-8	28515-28522	popular	
311-9	28523-28532	technical	
311-10	28533-28534	[	
311-11	28534-28543	inaudible	
311-12	28543-28544	]	
311-13	28544-28545	.	

#Text=Similarly,
#Text=you can also check the expand result and see if the [pushed?]
312-1	28546-28555	Similarly	
312-2	28555-28556	,	
312-3	28557-28560	you	
312-4	28561-28564	can	
312-5	28565-28569	also	
312-6	28570-28575	check	
312-7	28576-28579	the	
312-8	28580-28586	expand	
312-9	28587-28593	result	
312-10	28594-28597	and	
312-11	28598-28601	see	
312-12	28602-28604	if	
312-13	28605-28608	the	
312-14	28609-28610	[	
312-15	28610-28616	pushed	
312-16	28616-28617	?	
312-17	28617-28618	]	

#Text=filters over the file scan
#Text=note contains the name of column filters.
313-1	28619-28626	filters	
313-2	28627-28631	over	
313-3	28632-28635	the	
313-4	28636-28640	file	
313-5	28641-28645	scan	
313-6	28646-28650	note	
313-7	28651-28659	contains	
313-8	28660-28663	the	
313-9	28664-28668	name	
313-10	28669-28671	of	
313-11	28672-28678	column	
313-12	28679-28686	filters	
313-13	28686-28687	.	

#Text=In this example, we do have a filter where
#Text=it’s nested column A, and it does appear in the [pushed?]
314-1	28688-28690	In	
314-2	28691-28695	this	
314-3	28696-28703	example	
314-4	28703-28704	,	
314-5	28705-28707	we	
314-6	28708-28710	do	
314-7	28711-28715	have	
314-8	28716-28717	a	
314-9	28718-28724	filter	
314-10	28725-28730	where	
314-11	28731-28733	it	
314-12	28733-28734	’	
314-13	28734-28735	s	
314-14	28736-28742	nested	
314-15	28743-28749	column	
314-16	28750-28751	A	
314-17	28751-28752	,	
314-18	28753-28756	and	
314-19	28757-28759	it	
314-20	28760-28764	does	
314-21	28765-28771	appear	
314-22	28772-28774	in	
314-23	28775-28778	the	
314-24	28779-28780	[	
314-25	28780-28786	pushed	
314-26	28786-28787	?	
314-27	28787-28788	]	

#Text=filter, which makes this version
#Text=happen in this query.
315-1	28789-28795	filter	
315-2	28795-28796	,	
315-3	28797-28802	which	
315-4	28803-28808	makes	
315-5	28809-28813	this	
315-6	28814-28821	version	
315-7	28822-28828	happen	
315-8	28829-28831	in	
315-9	28832-28836	this	
315-10	28837-28842	query	
315-11	28842-28843	.	

#Text=Catalog plugin API
#Text=This release also expands other efforts on the extensibility and ecosystem
#Text=like the v2 API enhancements, Java 11, Hadoop, and [inaudible] support.
316-1	28844-28851	Catalog	
316-2	28852-28858	plugin	
316-3	28859-28862	API	
316-4	28863-28867	This	
316-5	28868-28875	release	
316-6	28876-28880	also	
316-7	28881-28888	expands	
316-8	28889-28894	other	
316-9	28895-28902	efforts	
316-10	28903-28905	on	
316-11	28906-28909	the	
316-12	28910-28923	extensibility	
316-13	28924-28927	and	
316-14	28928-28937	ecosystem	
316-15	28938-28942	like	
316-16	28943-28946	the	
316-17	28947-28949	v2	
316-18	28950-28953	API	
316-19	28954-28966	enhancements	
316-20	28966-28967	,	
316-21	28968-28972	Java	
316-22	28973-28975	11	
316-23	28975-28976	,	
316-24	28977-28983	Hadoop	
316-25	28983-28984	,	
316-26	28985-28988	and	
316-27	28989-28990	[	
316-28	28990-28999	inaudible	
316-29	28999-29000	]	
316-30	29001-29008	support	
316-31	29008-29009	.	

#Text=[inaudible]
#Text=API.
317-1	29010-29011	[	
317-2	29011-29020	inaudible	
317-3	29020-29021	]	
317-4	29022-29025	API	
317-5	29025-29026	.	

#Text=This release extends the [inaudible] to API by adding the Catalog plugin.
318-1	29027-29031	This	
318-2	29032-29039	release	
318-3	29040-29047	extends	
318-4	29048-29051	the	
318-5	29052-29053	[	
318-6	29053-29062	inaudible	
318-7	29062-29063	]	
318-8	29064-29066	to	
318-9	29067-29070	API	
318-10	29071-29073	by	
318-11	29074-29080	adding	
318-12	29081-29084	the	
318-13	29085-29092	Catalog	
318-14	29093-29099	plugin	
318-15	29099-29100	.	

#Text=The Catalog plug-in API allows users to reject their own [inaudible] and take over the [inaudible]
#Text=data operations from Spark.
319-1	29101-29104	The	
319-2	29105-29112	Catalog	
319-3	29113-29120	plug-in	
319-4	29121-29124	API	
319-5	29125-29131	allows	
319-6	29132-29137	users	
319-7	29138-29140	to	
319-8	29141-29147	reject	
319-9	29148-29153	their	
319-10	29154-29157	own	
319-11	29158-29159	[	
319-12	29159-29168	inaudible	
319-13	29168-29169	]	
319-14	29170-29173	and	
319-15	29174-29178	take	
319-16	29179-29183	over	
319-17	29184-29187	the	
319-18	29188-29189	[	
319-19	29189-29198	inaudible	
319-20	29198-29199	]	
319-21	29200-29204	data	
319-22	29205-29215	operations	
319-23	29216-29220	from	
319-24	29221-29226	Spark	
319-25	29226-29227	.	

#Text=This can give end users a more seamless experience to assist
#Text=external tables.
320-1	29228-29232	This	
320-2	29233-29236	can	
320-3	29237-29241	give	
320-4	29242-29245	end	
320-5	29246-29251	users	
320-6	29252-29253	a	
320-7	29254-29258	more	
320-8	29259-29267	seamless	
320-9	29268-29278	experience	
320-10	29279-29281	to	
320-11	29282-29288	assist	
320-12	29289-29297	external	
320-13	29298-29304	tables	
320-14	29304-29305	.	

#Text=Now, end users [inaudible] reject [inaudible] and manipulate the tables
#Text=[inaudible], where before, end users have to reject each table.
321-1	29306-29309	Now	
321-2	29309-29310	,	
321-3	29311-29314	end	
321-4	29315-29320	users	
321-5	29321-29322	[	
321-6	29322-29331	inaudible	
321-7	29331-29332	]	
321-8	29333-29339	reject	
321-9	29340-29341	[	
321-10	29341-29350	inaudible	
321-11	29350-29351	]	
321-12	29352-29355	and	
321-13	29356-29366	manipulate	
321-14	29367-29370	the	
321-15	29371-29377	tables	
321-16	29378-29379	[	
321-17	29379-29388	inaudible	
321-18	29388-29389	]	
321-19	29389-29390	,	
321-20	29391-29396	where	
321-21	29397-29403	before	
321-22	29403-29404	,	
321-23	29405-29408	end	
321-24	29409-29414	users	
321-25	29415-29419	have	
321-26	29420-29422	to	
321-27	29423-29429	reject	
321-28	29430-29434	each	
321-29	29435-29440	table	
321-30	29440-29441	.	

#Text=For example, let’s say
#Text=you have rejected a MySQL connector [inaudible] named MySQL.
322-1	29442-29445	For	
322-2	29446-29453	example	
322-3	29453-29454	,	
322-4	29455-29458	let	
322-5	29458-29459	’	
322-6	29459-29460	s	
322-7	29461-29464	say	
322-8	29465-29468	you	
322-9	29469-29473	have	
322-10	29474-29482	rejected	
322-11	29483-29484	a	
322-12	29485-29490	MySQL	
322-13	29491-29500	connector	
322-14	29501-29502	[	
322-15	29502-29511	inaudible	
322-16	29511-29512	]	
322-17	29513-29518	named	
322-18	29519-29524	MySQL	
322-19	29524-29525	.	

#Text=You can use SELECT to get data
#Text=from existing MySQL table.
323-1	29526-29529	You	
323-2	29530-29533	can	
323-3	29534-29537	use	
323-4	29538-29544	SELECT	
323-5	29545-29547	to	
323-6	29548-29551	get	
323-7	29552-29556	data	
323-8	29557-29561	from	
323-9	29562-29570	existing	
323-10	29571-29576	MySQL	
323-11	29577-29582	table	
323-12	29582-29583	.	

#Text=We can also INSERT into a MySQL table with Spark’s [inaudible].
324-1	29584-29586	We	
324-2	29587-29590	can	
324-3	29591-29595	also	
324-4	29596-29602	INSERT	
324-5	29603-29607	into	
324-6	29608-29609	a	
324-7	29610-29615	MySQL	
324-8	29616-29621	table	
324-9	29622-29626	with	
324-10	29627-29632	Spark	
324-11	29632-29633	’	
324-12	29633-29634	s	
324-13	29635-29636	[	
324-14	29636-29645	inaudible	
324-15	29645-29646	]	
324-16	29646-29647	.	

#Text=You can also create an outer tables in MySQL with Spark, which was just not possible before,
#Text=because before, we don’t have the Catalog plug-in.
325-1	29648-29651	You	
325-2	29652-29655	can	
325-3	29656-29660	also	
325-4	29661-29667	create	
325-5	29668-29670	an	
325-6	29671-29676	outer	
325-7	29677-29683	tables	
325-8	29684-29686	in	
325-9	29687-29692	MySQL	
325-10	29693-29697	with	
325-11	29698-29703	Spark	
325-12	29703-29704	,	
325-13	29705-29710	which	
325-14	29711-29714	was	
325-15	29715-29719	just	
325-16	29720-29723	not	
325-17	29724-29732	possible	
325-18	29733-29739	before	
325-19	29739-29740	,	
325-20	29741-29748	because	
325-21	29749-29755	before	
325-22	29755-29756	,	
325-23	29757-29759	we	
325-24	29760-29763	don	
325-25	29763-29764	’	
325-26	29764-29765	t	
325-27	29766-29770	have	
325-28	29771-29774	the	
325-29	29775-29782	Catalog	
325-30	29783-29790	plug-in	
325-31	29790-29791	.	

#Text=Now this example will be available
#Text=in Spark 3.1 when we finish [inaudible].
326-1	29792-29795	Now	
326-2	29796-29800	this	
326-3	29801-29808	example	
326-4	29809-29813	will	
326-5	29814-29816	be	
326-6	29817-29826	available	
326-7	29827-29829	in	
326-8	29830-29835	Spark	
326-9	29836-29839	3.1	
326-10	29840-29844	when	
326-11	29845-29847	we	
326-12	29848-29854	finish	
326-13	29855-29856	[	
326-14	29856-29865	inaudible	
326-15	29865-29866	]	
326-16	29866-29867	.	

#Text=When to use Data Source V2 API?
327-1	29868-29872	When	
327-2	29873-29875	to	
327-3	29876-29879	use	
327-4	29880-29884	Data	
327-5	29885-29891	Source	
327-6	29892-29894	V2	
327-7	29895-29898	API	
327-8	29898-29899	?	

#Text=Some people may have a question.
328-1	29900-29904	Some	
328-2	29905-29911	people	
328-3	29912-29915	may	
328-4	29916-29920	have	
328-5	29921-29922	a	
328-6	29923-29931	question	
328-7	29931-29932	.	

#Text=Now Spark has both – it has a V1 and a V2
#Text=APIs – which one should I use?
329-1	29933-29936	Now	
329-2	29937-29942	Spark	
329-3	29943-29946	has	
329-4	29947-29951	both	
329-5	29952-29953	–	
329-6	29954-29956	it	
329-7	29957-29960	has	
329-8	29961-29962	a	
329-9	29963-29965	V1	
329-10	29966-29969	and	
329-11	29970-29971	a	
329-12	29972-29974	V2	
329-13	29975-29979	APIs	
329-14	29980-29981	–	
329-15	29982-29987	which	
329-16	29988-29991	one	
329-17	29992-29998	should	
329-18	29999-30000	I	
329-19	30001-30004	use	
329-20	30004-30005	?	

#Text=In general, we want everyone to move to V2 [inaudible].
330-1	30006-30008	In	
330-2	30009-30016	general	
330-3	30016-30017	,	
330-4	30018-30020	we	
330-5	30021-30025	want	
330-6	30026-30034	everyone	
330-7	30035-30037	to	
330-8	30038-30042	move	
330-9	30043-30045	to	
330-10	30046-30048	V2	
330-11	30049-30050	[	
330-12	30050-30059	inaudible	
330-13	30059-30060	]	
330-14	30060-30061	.	

#Text=But the V2 API is not ready yet as we need more feedback to polish the API.
331-1	30062-30065	But	
331-2	30066-30069	the	
331-3	30070-30072	V2	
331-4	30073-30076	API	
331-5	30077-30079	is	
331-6	30080-30083	not	
331-7	30084-30089	ready	
331-8	30090-30093	yet	
331-9	30094-30096	as	
331-10	30097-30099	we	
331-11	30100-30104	need	
331-12	30105-30109	more	
331-13	30110-30118	feedback	
331-14	30119-30121	to	
331-15	30122-30128	polish	
331-16	30129-30132	the	
331-17	30133-30136	API	
331-18	30136-30137	.	

#Text=Here are
#Text=some tips about when to pick the V2 API.
332-1	30138-30142	Here	
332-2	30143-30146	are	
332-3	30147-30151	some	
332-4	30152-30156	tips	
332-5	30157-30162	about	
332-6	30163-30167	when	
332-7	30168-30170	to	
332-8	30171-30175	pick	
332-9	30176-30179	the	
332-10	30180-30182	V2	
332-11	30183-30186	API	
332-12	30186-30187	.	

#Text=So if you want [inaudible], the catalogue function
#Text=it is, so it has to be the V2 because V1 API doesn’t have this ability.
333-1	30188-30190	So	
333-2	30191-30193	if	
333-3	30194-30197	you	
333-4	30198-30202	want	
333-5	30203-30204	[	
333-6	30204-30213	inaudible	
333-7	30213-30214	]	
333-8	30214-30215	,	
333-9	30216-30219	the	
333-10	30220-30229	catalogue	
333-11	30230-30238	function	
333-12	30239-30241	it	
333-13	30242-30244	is	
333-14	30244-30245	,	
333-15	30246-30248	so	
333-16	30249-30251	it	
333-17	30252-30255	has	
333-18	30256-30258	to	
333-19	30259-30261	be	
333-20	30262-30265	the	
333-21	30266-30268	V2	
333-22	30269-30276	because	
333-23	30277-30279	V1	
333-24	30280-30283	API	
333-25	30284-30289	doesn	
333-26	30289-30290	’	
333-27	30290-30291	t	
333-28	30292-30296	have	
333-29	30297-30301	this	
333-30	30302-30309	ability	
333-31	30309-30310	.	

#Text=If you want to
#Text=support both versions streaming in your data source, then you should use V2 because in
#Text=V1, the streaming and the [inaudible] are different APIs which makes it harder to reuse
#Text=the code.
334-1	30311-30313	If	
334-2	30314-30317	you	
334-3	30318-30322	want	
334-4	30323-30325	to	
334-5	30326-30333	support	
334-6	30334-30338	both	
334-7	30339-30347	versions	
334-8	30348-30357	streaming	
334-9	30358-30360	in	
334-10	30361-30365	your	
334-11	30366-30370	data	
334-12	30371-30377	source	
334-13	30377-30378	,	
334-14	30379-30383	then	
334-15	30384-30387	you	
334-16	30388-30394	should	
334-17	30395-30398	use	
334-18	30399-30401	V2	
334-19	30402-30409	because	
334-20	30410-30412	in	
334-21	30413-30415	V1	
334-22	30415-30416	,	
334-23	30417-30420	the	
334-24	30421-30430	streaming	
334-25	30431-30434	and	
334-26	30435-30438	the	
334-27	30439-30440	[	
334-28	30440-30449	inaudible	
334-29	30449-30450	]	
334-30	30451-30454	are	
334-31	30455-30464	different	
334-32	30465-30469	APIs	
334-33	30470-30475	which	
334-34	30476-30481	makes	
334-35	30482-30484	it	
334-36	30485-30491	harder	
334-37	30492-30494	to	
334-38	30495-30500	reuse	
334-39	30501-30504	the	
334-40	30505-30509	code	
334-41	30509-30510	.	

#Text=And if you are sensitive to the scan performance, then you can try the V2
#Text=API because it allows you to report the data provisioning to [inaudible] in Spark, and
#Text=also it allows you to implement [inaudible] reader for better performance.
335-1	30511-30514	And	
335-2	30515-30517	if	
335-3	30518-30521	you	
335-4	30522-30525	are	
335-5	30526-30535	sensitive	
335-6	30536-30538	to	
335-7	30539-30542	the	
335-8	30543-30547	scan	
335-9	30548-30559	performance	
335-10	30559-30560	,	
335-11	30561-30565	then	
335-12	30566-30569	you	
335-13	30570-30573	can	
335-14	30574-30577	try	
335-15	30578-30581	the	
335-16	30582-30584	V2	
335-17	30585-30588	API	
335-18	30589-30596	because	
335-19	30597-30599	it	
335-20	30600-30606	allows	
335-21	30607-30610	you	
335-22	30611-30613	to	
335-23	30614-30620	report	
335-24	30621-30624	the	
335-25	30625-30629	data	
335-26	30630-30642	provisioning	
335-27	30643-30645	to	
335-28	30646-30647	[	
335-29	30647-30656	inaudible	
335-30	30656-30657	]	
335-31	30658-30660	in	
335-32	30661-30666	Spark	
335-33	30666-30667	,	
335-34	30668-30671	and	
335-35	30672-30676	also	
335-36	30677-30679	it	
335-37	30680-30686	allows	
335-38	30687-30690	you	
335-39	30691-30693	to	
335-40	30694-30703	implement	
335-41	30704-30705	[	
335-42	30705-30714	inaudible	
335-43	30714-30715	]	
335-44	30716-30722	reader	
335-45	30723-30726	for	
335-46	30727-30733	better	
335-47	30734-30745	performance	
335-48	30745-30746	.	

#Text=If you don’t
#Text=care about this stuff and just want to [inaudible] source once and you change it, please use
#Text=the V1 as V2 is not very stable.
336-1	30747-30749	If	
336-2	30750-30753	you	
336-3	30754-30757	don	
336-4	30757-30758	’	
336-5	30758-30759	t	
336-6	30760-30764	care	
336-7	30765-30770	about	
336-8	30771-30775	this	
336-9	30776-30781	stuff	
336-10	30782-30785	and	
336-11	30786-30790	just	
336-12	30791-30795	want	
336-13	30796-30798	to	
336-14	30799-30800	[	
336-15	30800-30809	inaudible	
336-16	30809-30810	]	
336-17	30811-30817	source	
336-18	30818-30822	once	
336-19	30823-30826	and	
336-20	30827-30830	you	
336-21	30831-30837	change	
336-22	30838-30840	it	
336-23	30840-30841	,	
336-24	30842-30848	please	
336-25	30849-30852	use	
336-26	30853-30856	the	
336-27	30857-30859	V1	
336-28	30860-30862	as	
336-29	30863-30865	V2	
336-30	30866-30868	is	
336-31	30869-30872	not	
336-32	30873-30877	very	
336-33	30878-30884	stable	
336-34	30884-30885	.	

#Text=Extensibility and Ecosystem
#Text=The ecosystem also evolves very fast.
337-1	30886-30899	Extensibility	
337-2	30900-30903	and	
337-3	30904-30913	Ecosystem	
337-4	30914-30917	The	
337-5	30918-30927	ecosystem	
337-6	30928-30932	also	
337-7	30933-30940	evolves	
337-8	30941-30945	very	
337-9	30946-30950	fast	
337-10	30950-30951	.	

#Text=In this release, Spark
#Text=can be better integrated into the ecosystem by supporting the newer version of these common
#Text=components like Java 11, Hadoop 3, Hadoop 3 [inaudible], and Hadoop 2.3 [inaudible].
338-1	30952-30954	In	
338-2	30955-30959	this	
338-3	30960-30967	release	
338-4	30967-30968	,	
338-5	30969-30974	Spark	
338-6	30975-30978	can	
338-7	30979-30981	be	
338-8	30982-30988	better	
338-9	30989-30999	integrated	
338-10	31000-31004	into	
338-11	31005-31008	the	
338-12	31009-31018	ecosystem	
338-13	31019-31021	by	
338-14	31022-31032	supporting	
338-15	31033-31036	the	
338-16	31037-31042	newer	
338-17	31043-31050	version	
338-18	31051-31053	of	
338-19	31054-31059	these	
338-20	31060-31066	common	
338-21	31067-31077	components	
338-22	31078-31082	like	
338-23	31083-31087	Java	
338-24	31088-31090	11	
338-25	31090-31091	,	
338-26	31092-31098	Hadoop	
338-27	31099-31100	3	
338-28	31100-31101	,	
338-29	31102-31108	Hadoop	
338-30	31109-31110	3	
338-31	31111-31112	[	
338-32	31112-31121	inaudible	
338-33	31121-31122	]	
338-34	31122-31123	,	
338-35	31124-31127	and	
338-36	31128-31134	Hadoop	
338-37	31135-31138	2.3	
338-38	31139-31140	[	
338-39	31140-31149	inaudible	
338-40	31149-31150	]	
338-41	31150-31151	.	

#Text=I want to mention some breaking changes here.
339-1	31152-31153	I	
339-2	31154-31158	want	
339-3	31159-31161	to	
339-4	31162-31169	mention	
339-5	31170-31174	some	
339-6	31175-31183	breaking	
339-7	31184-31191	changes	
339-8	31192-31196	here	
339-9	31196-31197	.	

#Text=Starting from this release, we’re only building Spark with Scala 2.12, so Scala 2.11 is no longer [inaudible].
340-1	31198-31206	Starting	
340-2	31207-31211	from	
340-3	31212-31216	this	
340-4	31217-31224	release	
340-5	31224-31225	,	
340-6	31226-31228	we	
340-7	31228-31229	’	
340-8	31229-31231	re	
340-9	31232-31236	only	
340-10	31237-31245	building	
340-11	31246-31251	Spark	
340-12	31252-31256	with	
340-13	31257-31262	Scala	
340-14	31263-31267	2.12	
340-15	31267-31268	,	
340-16	31269-31271	so	
340-17	31272-31277	Scala	
340-18	31278-31282	2.11	
340-19	31283-31285	is	
340-20	31286-31288	no	
340-21	31289-31295	longer	
340-22	31296-31297	[	
340-23	31297-31306	inaudible	
340-24	31306-31307	]	
340-25	31307-31308	.	

#Text=And we deprecated Python 2 too because it is end of life.
341-1	31309-31312	And	
341-2	31313-31315	we	
341-3	31316-31326	deprecated	
341-4	31327-31333	Python	
341-5	31334-31335	2	
341-6	31336-31339	too	
341-7	31340-31347	because	
341-8	31348-31350	it	
341-9	31351-31353	is	
341-10	31354-31357	end	
341-11	31358-31360	of	
341-12	31361-31365	life	
341-13	31365-31366	.	

#Text=In the download image, we put a build of Spark with different
#Text=[inaudible] and Hadoop combinations.
342-1	31367-31369	In	
342-2	31370-31373	the	
342-3	31374-31382	download	
342-4	31383-31388	image	
342-5	31388-31389	,	
342-6	31390-31392	we	
342-7	31393-31396	put	
342-8	31397-31398	a	
342-9	31399-31404	build	
342-10	31405-31407	of	
342-11	31408-31413	Spark	
342-12	31414-31418	with	
342-13	31419-31428	different	
342-14	31429-31430	[	
342-15	31430-31439	inaudible	
342-16	31439-31440	]	
342-17	31441-31444	and	
342-18	31445-31451	Hadoop	
342-19	31452-31464	combinations	
342-20	31464-31465	.	

#Text=By default, it will be Hadoop 2.7 and it would have 2.3
#Text=[exclusion?].
343-1	31466-31468	By	
343-2	31469-31476	default	
343-3	31476-31477	,	
343-4	31478-31480	it	
343-5	31481-31485	will	
343-6	31486-31488	be	
343-7	31489-31495	Hadoop	
343-8	31496-31499	2.7	
343-9	31500-31503	and	
343-10	31504-31506	it	
343-11	31507-31512	would	
343-12	31513-31517	have	
343-13	31518-31521	2.3	
343-14	31522-31523	[	
343-15	31523-31532	exclusion	
343-16	31532-31533	?	
343-17	31533-31534	]	
343-18	31534-31535	.	

#Text=There are another two [companies?]
344-1	31536-31541	There	
344-2	31542-31545	are	
344-3	31546-31553	another	
344-4	31554-31557	two	
344-5	31558-31559	[	
344-6	31559-31568	companies	
344-7	31568-31569	?	
344-8	31569-31570	]	

#Text=of previews available.
345-1	31571-31573	of	
345-2	31574-31582	previews	
345-3	31583-31592	available	
345-4	31592-31593	.	

#Text=One is Hadoop 2.7 and
#Text=Hadoop 1.2 execution, which is for people who can’t upgrade their end forms.
346-1	31594-31597	One	
346-2	31598-31600	is	
346-3	31601-31607	Hadoop	
346-4	31608-31611	2.7	
346-5	31612-31615	and	
346-6	31616-31622	Hadoop	
346-7	31623-31626	1.2	
346-8	31627-31636	execution	
346-9	31636-31637	,	
346-10	31638-31643	which	
346-11	31644-31646	is	
346-12	31647-31650	for	
346-13	31651-31657	people	
346-14	31658-31661	who	
346-15	31662-31665	can	
346-16	31665-31666	’	
346-17	31666-31667	t	
346-18	31668-31675	upgrade	
346-19	31676-31681	their	
346-20	31682-31685	end	
346-21	31686-31691	forms	
346-22	31691-31692	.	

#Text=The other
#Text=is Hadoop 3.2 and Hadoop 2.3 execution, which is for people who want to try Hadoop
#Text=3.
347-1	31693-31696	The	
347-2	31697-31702	other	
347-3	31703-31705	is	
347-4	31706-31712	Hadoop	
347-5	31713-31716	3.2	
347-6	31717-31720	and	
347-7	31721-31727	Hadoop	
347-8	31728-31731	2.3	
347-9	31732-31741	execution	
347-10	31741-31742	,	
347-11	31743-31748	which	
347-12	31749-31751	is	
347-13	31752-31755	for	
347-14	31756-31762	people	
347-15	31763-31766	who	
347-16	31767-31771	want	
347-17	31772-31774	to	
347-18	31775-31778	try	
347-19	31779-31785	Hadoop	
347-20	31786-31787	3	
347-21	31787-31788	.	

#Text=We also extend the support for different Hadoop and Hive versions from 0.12 to 3.1.
348-1	31789-31791	We	
348-2	31792-31796	also	
348-3	31797-31803	extend	
348-4	31804-31807	the	
348-5	31808-31815	support	
348-6	31816-31819	for	
348-7	31820-31829	different	
348-8	31830-31836	Hadoop	
348-9	31837-31840	and	
348-10	31841-31845	Hive	
348-11	31846-31854	versions	
348-12	31855-31859	from	
348-13	31860-31864	0.12	
348-14	31865-31867	to	
348-15	31868-31871	3.1	
348-16	31871-31872	.	

#Text=Documentation Improvements
#Text=Documentation improvements is the last existing news I want to share
#Text=with everyone.
349-1	31873-31886	Documentation	
349-2	31887-31899	Improvements	
349-3	31900-31913	Documentation	
349-4	31914-31926	improvements	
349-5	31927-31929	is	
349-6	31930-31933	the	
349-7	31934-31938	last	
349-8	31939-31947	existing	
349-9	31948-31952	news	
349-10	31953-31954	I	
349-11	31955-31959	want	
349-12	31960-31962	to	
349-13	31963-31968	share	
349-14	31969-31973	with	
349-15	31974-31982	everyone	
349-16	31982-31983	.	

#Text=How to read on a standard the web UI is a common question to many new Spark
#Text=users.
350-1	31984-31987	How	
350-2	31988-31990	to	
350-3	31991-31995	read	
350-4	31996-31998	on	
350-5	31999-32000	a	
350-6	32001-32009	standard	
350-7	32010-32013	the	
350-8	32014-32017	web	
350-9	32018-32020	UI	
350-10	32021-32023	is	
350-11	32024-32025	a	
350-12	32026-32032	common	
350-13	32033-32041	question	
350-14	32042-32044	to	
350-15	32045-32049	many	
350-16	32050-32053	new	
350-17	32054-32059	Spark	
350-18	32060-32065	users	
350-19	32065-32066	.	

#Text=This is especially true for Spark SQL users and Spark streaming users.
351-1	32067-32071	This	
351-2	32072-32074	is	
351-3	32075-32085	especially	
351-4	32086-32090	true	
351-5	32091-32094	for	
351-6	32095-32100	Spark	
351-7	32101-32104	SQL	
351-8	32105-32110	users	
351-9	32111-32114	and	
351-10	32115-32120	Spark	
351-11	32121-32130	streaming	
351-12	32131-32136	users	
351-13	32136-32137	.	

#Text=They are
#Text=using the [inaudible].
352-1	32138-32142	They	
352-2	32143-32146	are	
352-3	32147-32152	using	
352-4	32153-32156	the	
352-5	32157-32158	[	
352-6	32158-32167	inaudible	
352-7	32167-32168	]	
352-8	32168-32169	.	

#Text=They usually don’t know what it is, and what our jobs [inaudible].
353-1	32170-32174	They	
353-2	32175-32182	usually	
353-3	32183-32186	don	
353-4	32186-32187	’	
353-5	32187-32188	t	
353-6	32189-32193	know	
353-7	32194-32198	what	
353-8	32199-32201	it	
353-9	32202-32204	is	
353-10	32204-32205	,	
353-11	32206-32209	and	
353-12	32210-32214	what	
353-13	32215-32218	our	
353-14	32219-32223	jobs	
353-15	32224-32225	[	
353-16	32225-32234	inaudible	
353-17	32234-32235	]	
353-18	32235-32236	.	

#Text=Also, the [inaudible] are using many queries and matrix names, which are not very clear
#Text=to many users.
354-1	32237-32241	Also	
354-2	32241-32242	,	
354-3	32243-32246	the	
354-4	32247-32248	[	
354-5	32248-32257	inaudible	
354-6	32257-32258	]	
354-7	32259-32262	are	
354-8	32263-32268	using	
354-9	32269-32273	many	
354-10	32274-32281	queries	
354-11	32282-32285	and	
354-12	32286-32292	matrix	
354-13	32293-32298	names	
354-14	32298-32299	,	
354-15	32300-32305	which	
354-16	32306-32309	are	
354-17	32310-32313	not	
354-18	32314-32318	very	
354-19	32319-32324	clear	
354-20	32325-32327	to	
354-21	32328-32332	many	
354-22	32333-32338	users	
354-23	32338-32339	.	

#Text=Starting from this release, we add a new section for [inaudible] reading
#Text=the web UI.
355-1	32340-32348	Starting	
355-2	32349-32353	from	
355-3	32354-32358	this	
355-4	32359-32366	release	
355-5	32366-32367	,	
355-6	32368-32370	we	
355-7	32371-32374	add	
355-8	32375-32376	a	
355-9	32377-32380	new	
355-10	32381-32388	section	
355-11	32389-32392	for	
355-12	32393-32394	[	
355-13	32394-32403	inaudible	
355-14	32403-32404	]	
355-15	32405-32412	reading	
355-16	32413-32416	the	
355-17	32417-32420	web	
355-18	32421-32423	UI	
355-19	32423-32424	.	

#Text=It includes the [inaudible] job page and [inaudible] and also SQL streaming
#Text=[inaudible].
356-1	32425-32427	It	
356-2	32428-32436	includes	
356-3	32437-32440	the	
356-4	32441-32442	[	
356-5	32442-32451	inaudible	
356-6	32451-32452	]	
356-7	32453-32456	job	
356-8	32457-32461	page	
356-9	32462-32465	and	
356-10	32466-32467	[	
356-11	32467-32476	inaudible	
356-12	32476-32477	]	
356-13	32478-32481	and	
356-14	32482-32486	also	
356-15	32487-32490	SQL	
356-16	32491-32500	streaming	
356-17	32501-32502	[	
356-18	32502-32511	inaudible	
356-19	32511-32512	]	
356-20	32512-32513	.	

#Text=This is just a start.
357-1	32514-32518	This	
357-2	32519-32521	is	
357-3	32522-32526	just	
357-4	32527-32528	a	
357-5	32529-32534	start	
357-6	32534-32535	.	

#Text=We will continue to enhance it, then SQL reference.
358-1	32536-32538	We	
358-2	32539-32543	will	
358-3	32544-32552	continue	
358-4	32553-32555	to	
358-5	32556-32563	enhance	
358-6	32564-32566	it	
358-7	32566-32567	,	
358-8	32568-32572	then	
358-9	32573-32576	SQL	
358-10	32577-32586	reference	
358-11	32586-32587	.	

#Text=Finally, this release already has a SQL reference for Spark SQL.
359-1	32588-32595	Finally	
359-2	32595-32596	,	
359-3	32597-32601	this	
359-4	32602-32609	release	
359-5	32610-32617	already	
359-6	32618-32621	has	
359-7	32622-32623	a	
359-8	32624-32627	SQL	
359-9	32628-32637	reference	
359-10	32638-32641	for	
359-11	32642-32647	Spark	
359-12	32648-32651	SQL	
359-13	32651-32652	.	

#Text=Spark SQL
#Text=is the most popular and important component in Spark.
360-1	32653-32658	Spark	
360-2	32659-32662	SQL	
360-3	32663-32665	is	
360-4	32666-32669	the	
360-5	32670-32674	most	
360-6	32675-32682	popular	
360-7	32683-32686	and	
360-8	32687-32696	important	
360-9	32697-32706	component	
360-10	32707-32709	in	
360-11	32710-32715	Spark	
360-12	32715-32716	.	

#Text=However, we did not have our own
#Text=SQL reference to define the SQL [semantic?]
361-1	32717-32724	However	
361-2	32724-32725	,	
361-3	32726-32728	we	
361-4	32729-32732	did	
361-5	32733-32736	not	
361-6	32737-32741	have	
361-7	32742-32745	our	
361-8	32746-32749	own	
361-9	32750-32753	SQL	
361-10	32754-32763	reference	
361-11	32764-32766	to	
361-12	32767-32773	define	
361-13	32774-32777	the	
361-14	32778-32781	SQL	
361-15	32782-32783	[	
361-16	32783-32791	semantic	
361-17	32791-32792	?	
361-18	32792-32793	]	

#Text=and detailed behaviors.
362-1	32794-32797	and	
362-2	32798-32806	detailed	
362-3	32807-32816	behaviors	
362-4	32816-32817	.	

#Text=Let me quickly go
#Text=over the major chapters in SQL reference.
363-1	32818-32821	Let	
363-2	32822-32824	me	
363-3	32825-32832	quickly	
363-4	32833-32835	go	
363-5	32836-32840	over	
363-6	32841-32844	the	
363-7	32845-32850	major	
363-8	32851-32859	chapters	
363-9	32860-32862	in	
363-10	32863-32866	SQL	
363-11	32867-32876	reference	
363-12	32876-32877	.	

#Text=So we have a page to explain the ANSI components
#Text=of Spark.
364-1	32878-32880	So	
364-2	32881-32883	we	
364-3	32884-32888	have	
364-4	32889-32890	a	
364-5	32891-32895	page	
364-6	32896-32898	to	
364-7	32899-32906	explain	
364-8	32907-32910	the	
364-9	32911-32915	ANSI	
364-10	32916-32926	components	
364-11	32927-32929	of	
364-12	32930-32935	Spark	
364-13	32935-32936	.	

#Text=So as I mentioned before, we have SQL compatibility, but to avoid [correcting?]
365-1	32937-32939	So	
365-2	32940-32942	as	
365-3	32943-32944	I	
365-4	32945-32954	mentioned	
365-5	32955-32961	before	
365-6	32961-32962	,	
365-7	32963-32965	we	
365-8	32966-32970	have	
365-9	32971-32974	SQL	
365-10	32975-32988	compatibility	
365-11	32988-32989	,	
365-12	32990-32993	but	
365-13	32994-32996	to	
365-14	32997-33002	avoid	
365-15	33003-33004	[	
365-16	33004-33014	correcting	
365-17	33014-33015	?	
365-18	33015-33016	]	

#Text=the [effecting?]
366-1	33017-33020	the	
366-2	33021-33022	[	
366-3	33022-33031	effecting	
366-4	33031-33032	?	
366-5	33032-33033	]	

#Text=queries, we make it optional.
367-1	33034-33041	queries	
367-2	33041-33042	,	
367-3	33043-33045	we	
367-4	33046-33050	make	
367-5	33051-33053	it	
367-6	33054-33062	optional	
367-7	33062-33063	.	

#Text=So you can only enable the ANSI compatibility
#Text=by enabling this flag.
368-1	33064-33066	So	
368-2	33067-33070	you	
368-3	33071-33074	can	
368-4	33075-33079	only	
368-5	33080-33086	enable	
368-6	33087-33090	the	
368-7	33091-33095	ANSI	
368-8	33096-33109	compatibility	
368-9	33110-33112	by	
368-10	33113-33121	enabling	
368-11	33122-33126	this	
368-12	33127-33131	flag	
368-13	33131-33132	.	

#Text=You also have a page to explain the detailed semantic of each [inaudible],
#Text=so you can know what it means and what’s the behavior of them.
369-1	33133-33136	You	
369-2	33137-33141	also	
369-3	33142-33146	have	
369-4	33147-33148	a	
369-5	33149-33153	page	
369-6	33154-33156	to	
369-7	33157-33164	explain	
369-8	33165-33168	the	
369-9	33169-33177	detailed	
369-10	33178-33186	semantic	
369-11	33187-33189	of	
369-12	33190-33194	each	
369-13	33195-33196	[	
369-14	33196-33205	inaudible	
369-15	33205-33206	]	
369-16	33206-33207	,	
369-17	33208-33210	so	
369-18	33211-33214	you	
369-19	33215-33218	can	
369-20	33219-33223	know	
369-21	33224-33228	what	
369-22	33229-33231	it	
369-23	33232-33237	means	
369-24	33238-33241	and	
369-25	33242-33246	what	
369-26	33246-33247	’	
369-27	33247-33248	s	
369-28	33249-33252	the	
369-29	33253-33261	behavior	
369-30	33262-33264	of	
369-31	33265-33269	them	
369-32	33269-33270	.	

#Text=You also have a page to
#Text=explain the data and partner strings used for formatting and parsing functions [inaudible].
370-1	33271-33274	You	
370-2	33275-33279	also	
370-3	33280-33284	have	
370-4	33285-33286	a	
370-5	33287-33291	page	
370-6	33292-33294	to	
370-7	33295-33302	explain	
370-8	33303-33306	the	
370-9	33307-33311	data	
370-10	33312-33315	and	
370-11	33316-33323	partner	
370-12	33324-33331	strings	
370-13	33332-33336	used	
370-14	33337-33340	for	
370-15	33341-33351	formatting	
370-16	33352-33355	and	
370-17	33356-33363	parsing	
370-18	33364-33373	functions	
370-19	33374-33375	[	
370-20	33375-33384	inaudible	
370-21	33384-33385	]	
370-22	33385-33386	.	

#Text=There’s also a page to give the document for each function in Spark.
371-1	33387-33392	There	
371-2	33392-33393	’	
371-3	33393-33394	s	
371-4	33395-33399	also	
371-5	33400-33401	a	
371-6	33402-33406	page	
371-7	33407-33409	to	
371-8	33410-33414	give	
371-9	33415-33418	the	
371-10	33419-33427	document	
371-11	33428-33431	for	
371-12	33432-33436	each	
371-13	33437-33445	function	
371-14	33446-33448	in	
371-15	33449-33454	Spark	
371-16	33454-33455	.	

#Text=We also have a page
#Text=to explain the syntax, how to define the table or function [inaudible].
372-1	33456-33458	We	
372-2	33459-33463	also	
372-3	33464-33468	have	
372-4	33469-33470	a	
372-5	33471-33475	page	
372-6	33476-33478	to	
372-7	33479-33486	explain	
372-8	33487-33490	the	
372-9	33491-33497	syntax	
372-10	33497-33498	,	
372-11	33499-33502	how	
372-12	33503-33505	to	
372-13	33506-33512	define	
372-14	33513-33516	the	
372-15	33517-33522	table	
372-16	33523-33525	or	
372-17	33526-33534	function	
372-18	33535-33536	[	
372-19	33536-33545	inaudible	
372-20	33545-33546	]	
372-21	33546-33547	.	

#Text=Also, there’s a page
#Text=to explain the syntax and the semantics of each [inaudible] in Spark SQL.
373-1	33548-33552	Also	
373-2	33552-33553	,	
373-3	33554-33559	there	
373-4	33559-33560	’	
373-5	33560-33561	s	
373-6	33562-33563	a	
373-7	33564-33568	page	
373-8	33569-33571	to	
373-9	33572-33579	explain	
373-10	33580-33583	the	
373-11	33584-33590	syntax	
373-12	33591-33594	and	
373-13	33595-33598	the	
373-14	33599-33608	semantics	
373-15	33609-33611	of	
373-16	33612-33616	each	
373-17	33617-33618	[	
373-18	33618-33627	inaudible	
373-19	33627-33628	]	
373-20	33629-33631	in	
373-21	33632-33637	Spark	
373-22	33638-33641	SQL	
373-23	33641-33642	.	

#Text=Also, there’s
#Text=a page to explain the null semantic.
374-1	33643-33647	Also	
374-2	33647-33648	,	
374-3	33649-33654	there	
374-4	33654-33655	’	
374-5	33655-33656	s	
374-6	33657-33658	a	
374-7	33659-33663	page	
374-8	33664-33666	to	
374-9	33667-33674	explain	
374-10	33675-33678	the	
374-11	33679-33683	null	
374-12	33684-33692	semantic	
374-13	33692-33693	.	

#Text=The null is a very special value in Spark SQL and other
#Text=ecosystems.
375-1	33694-33697	The	
375-2	33698-33702	null	
375-3	33703-33705	is	
375-4	33706-33707	a	
375-5	33708-33712	very	
375-6	33713-33720	special	
375-7	33721-33726	value	
375-8	33727-33729	in	
375-9	33730-33735	Spark	
375-10	33736-33739	SQL	
375-11	33740-33743	and	
375-12	33744-33749	other	
375-13	33750-33760	ecosystems	
375-14	33760-33761	.	

#Text=So there must be a page to either explain what’s the meaning of null in the
#Text=null queries.
376-1	33762-33764	So	
376-2	33765-33770	there	
376-3	33771-33775	must	
376-4	33776-33778	be	
376-5	33779-33780	a	
376-6	33781-33785	page	
376-7	33786-33788	to	
376-8	33789-33795	either	
376-9	33796-33803	explain	
376-10	33804-33808	what	
376-11	33808-33809	’	
376-12	33809-33810	s	
376-13	33811-33814	the	
376-14	33815-33822	meaning	
376-15	33823-33825	of	
376-16	33826-33830	null	
376-17	33831-33833	in	
376-18	33834-33837	the	
376-19	33838-33842	null	
376-20	33843-33850	queries	
376-21	33850-33851	.	

#Text=Also, we have a page to explain the syntax for all the commands, like DDL
#Text=and DML commands, and also insert is also included in the document.
377-1	33852-33856	Also	
377-2	33856-33857	,	
377-3	33858-33860	we	
377-4	33861-33865	have	
377-5	33866-33867	a	
377-6	33868-33872	page	
377-7	33873-33875	to	
377-8	33876-33883	explain	
377-9	33884-33887	the	
377-10	33888-33894	syntax	
377-11	33895-33898	for	
377-12	33899-33902	all	
377-13	33903-33906	the	
377-14	33907-33915	commands	
377-15	33915-33916	,	
377-16	33917-33921	like	
377-17	33922-33925	DDL	
377-18	33926-33929	and	
377-19	33930-33933	DML	
377-20	33934-33942	commands	
377-21	33942-33943	,	
377-22	33944-33947	and	
377-23	33948-33952	also	
377-24	33953-33959	insert	
377-25	33960-33962	is	
377-26	33963-33967	also	
377-27	33968-33976	included	
377-28	33977-33979	in	
377-29	33980-33983	the	
377-30	33984-33992	document	
377-31	33992-33993	.	

#Text=In fact, SELECT has so many features, so we want to have a page to explain all of them.
378-1	33994-33996	In	
378-2	33997-34001	fact	
378-3	34001-34002	,	
378-4	34003-34009	SELECT	
378-5	34010-34013	has	
378-6	34014-34016	so	
378-7	34017-34021	many	
378-8	34022-34030	features	
378-9	34030-34031	,	
378-10	34032-34034	so	
378-11	34035-34037	we	
378-12	34038-34042	want	
378-13	34043-34045	to	
378-14	34046-34050	have	
378-15	34051-34052	a	
378-16	34053-34057	page	
378-17	34058-34060	to	
378-18	34061-34068	explain	
378-19	34069-34072	all	
378-20	34073-34075	of	
378-21	34076-34080	them	
378-22	34080-34081	.	

#Text=Yeah, there are
#Text=also a page for other special commands like SHOW TABLES.
379-1	34082-34086	Yeah	
379-2	34086-34087	,	
379-3	34088-34093	there	
379-4	34094-34097	are	
379-5	34098-34102	also	
379-6	34103-34104	a	
379-7	34105-34109	page	
379-8	34110-34113	for	
379-9	34114-34119	other	
379-10	34120-34127	special	
379-11	34128-34136	commands	
379-12	34137-34141	like	
379-13	34142-34146	SHOW	
379-14	34147-34153	TABLES	
379-15	34153-34154	.	

#Text=Finally, [inaudible].
380-1	34155-34162	Finally	
380-2	34162-34163	,	
380-3	34164-34165	[	
380-4	34165-34174	inaudible	
380-5	34174-34175	]	
380-6	34175-34176	.	

#Text=This is another critical enhancements in Spark
#Text=3.0 document.
381-1	34177-34181	This	
381-2	34182-34184	is	
381-3	34185-34192	another	
381-4	34193-34201	critical	
381-5	34202-34214	enhancements	
381-6	34215-34217	in	
381-7	34218-34223	Spark	
381-8	34224-34227	3.0	
381-9	34228-34236	document	
381-10	34236-34237	.	

#Text=In this release, all the components have [inaudible] guides.
382-1	34238-34240	In	
382-2	34241-34245	this	
382-3	34246-34253	release	
382-4	34253-34254	,	
382-5	34255-34258	all	
382-6	34259-34262	the	
382-7	34263-34273	components	
382-8	34274-34278	have	
382-9	34279-34280	[	
382-10	34280-34289	inaudible	
382-11	34289-34290	]	
382-12	34291-34297	guides	
382-13	34297-34298	.	

#Text=When you upgrade
#Text=your Spark version, you can read them carefully, and, in fact, [inaudible].
383-1	34299-34303	When	
383-2	34304-34307	you	
383-3	34308-34315	upgrade	
383-4	34316-34320	your	
383-5	34321-34326	Spark	
383-6	34327-34334	version	
383-7	34334-34335	,	
383-8	34336-34339	you	
383-9	34340-34343	can	
383-10	34344-34348	read	
383-11	34349-34353	them	
383-12	34354-34363	carefully	
383-13	34363-34364	,	
383-14	34365-34368	and	
383-15	34368-34369	,	
383-16	34370-34372	in	
383-17	34373-34377	fact	
383-18	34377-34378	,	
383-19	34379-34380	[	
383-20	34380-34389	inaudible	
383-21	34389-34390	]	
383-22	34390-34391	.	

#Text=You might be wondering
#Text=why it is much longer than the previous version.
384-1	34392-34395	You	
384-2	34396-34401	might	
384-3	34402-34404	be	
384-4	34405-34414	wondering	
384-5	34415-34418	why	
384-6	34419-34421	it	
384-7	34422-34424	is	
384-8	34425-34429	much	
384-9	34430-34436	longer	
384-10	34437-34441	than	
384-11	34442-34445	the	
384-12	34446-34454	previous	
384-13	34455-34462	version	
384-14	34462-34463	.	

#Text=It’s because we try to document all the important
#Text=looking changes you want to hear.
385-1	34464-34466	It	
385-2	34466-34467	’	
385-3	34467-34468	s	
385-4	34469-34476	because	
385-5	34477-34479	we	
385-6	34480-34483	try	
385-7	34484-34486	to	
385-8	34487-34495	document	
385-9	34496-34499	all	
385-10	34500-34503	the	
385-11	34504-34513	important	
385-12	34514-34521	looking	
385-13	34522-34529	changes	
385-14	34530-34533	you	
385-15	34534-34538	want	
385-16	34539-34541	to	
385-17	34542-34546	hear	
385-18	34546-34547	.	

#Text=If you upgrade into some errors, that’s another wordy document
#Text=or slightly confusing error message, please open a ticket, and we will try and fix it
#Text=in subsequent releases.
386-1	34548-34550	If	
386-2	34551-34554	you	
386-3	34555-34562	upgrade	
386-4	34563-34567	into	
386-5	34568-34572	some	
386-6	34573-34579	errors	
386-7	34579-34580	,	
386-8	34581-34585	that	
386-9	34585-34586	’	
386-10	34586-34587	s	
386-11	34588-34595	another	
386-12	34596-34601	wordy	
386-13	34602-34610	document	
386-14	34611-34613	or	
386-15	34614-34622	slightly	
386-16	34623-34632	confusing	
386-17	34633-34638	error	
386-18	34639-34646	message	
386-19	34646-34647	,	
386-20	34648-34654	please	
386-21	34655-34659	open	
386-22	34660-34661	a	
386-23	34662-34668	ticket	
386-24	34668-34669	,	
386-25	34670-34673	and	
386-26	34674-34676	we	
386-27	34677-34681	will	
386-28	34682-34685	try	
386-29	34686-34689	and	
386-30	34690-34693	fix	
386-31	34694-34696	it	
386-32	34697-34699	in	
386-33	34700-34710	subsequent	
386-34	34711-34719	releases	
386-35	34719-34720	.	

#Text=Now, that Spark is almost 10 years old now.
387-1	34721-34724	Now	
387-2	34724-34725	,	
387-3	34726-34730	that	
387-4	34731-34736	Spark	
387-5	34737-34739	is	
387-6	34740-34746	almost	
387-7	34747-34749	10	
387-8	34750-34755	years	
387-9	34756-34759	old	
387-10	34760-34763	now	
387-11	34763-34764	.	

#Text=The Spark community
#Text=is very serious about making change.
388-1	34765-34768	The	
388-2	34769-34774	Spark	
388-3	34775-34784	community	
388-4	34785-34787	is	
388-5	34788-34792	very	
388-6	34793-34800	serious	
388-7	34801-34806	about	
388-8	34807-34813	making	
388-9	34814-34820	change	
388-10	34820-34821	.	

#Text=And we try our best to avoid [inaudible] changing.
389-1	34822-34825	And	
389-2	34826-34828	we	
389-3	34829-34832	try	
389-4	34833-34836	our	
389-5	34837-34841	best	
389-6	34842-34844	to	
389-7	34845-34850	avoid	
389-8	34851-34852	[	
389-9	34852-34861	inaudible	
389-10	34861-34862	]	
389-11	34863-34871	changing	
389-12	34871-34872	.	

#Text=If you upgrade to Spark 3.0 at this time, you may see explicit error messages about
#Text=changing.
390-1	34873-34875	If	
390-2	34876-34879	you	
390-3	34880-34887	upgrade	
390-4	34888-34890	to	
390-5	34891-34896	Spark	
390-6	34897-34900	3.0	
390-7	34901-34903	at	
390-8	34904-34908	this	
390-9	34909-34913	time	
390-10	34913-34914	,	
390-11	34915-34918	you	
390-12	34919-34922	may	
390-13	34923-34926	see	
390-14	34927-34935	explicit	
390-15	34936-34941	error	
390-16	34942-34950	messages	
390-17	34951-34956	about	
390-18	34957-34965	changing	
390-19	34965-34966	.	

#Text=So the error message also provides config names for you to either go back to existing behavior or go with the new behavior.
#Text=this talk, we talked about many exciting features and improvements in
#Text=Spark 3.0.
391-1	34967-34969	So	
391-2	34970-34973	the	
391-3	34974-34979	error	
391-4	34980-34987	message	
391-5	34988-34992	also	
391-6	34993-35001	provides	
391-7	35002-35008	config	
391-8	35009-35014	names	
391-9	35015-35018	for	
391-10	35019-35022	you	
391-11	35023-35025	to	
391-12	35026-35032	either	
391-13	35033-35035	go	
391-14	35036-35040	back	
391-15	35041-35043	to	
391-16	35044-35052	existing	
391-17	35053-35061	behavior	
391-18	35062-35064	or	
391-19	35065-35067	go	
391-20	35068-35072	with	
391-21	35073-35076	the	
391-22	35077-35080	new	
391-23	35081-35089	behavior	
391-24	35089-35090	.	
391-25	35091-35095	this	
391-26	35096-35100	talk	
391-27	35100-35101	,	
391-28	35102-35104	we	
391-29	35105-35111	talked	
391-30	35112-35117	about	
391-31	35118-35122	many	
391-32	35123-35131	exciting	
391-33	35132-35140	features	
391-34	35141-35144	and	
391-35	35145-35157	improvements	
391-36	35158-35160	in	
391-37	35161-35166	Spark	
391-38	35167-35170	3.0	
391-39	35170-35171	.	

#Text=Due to the lack of time, there are still many other nice features not being
#Text=covered by this talk.
392-1	35172-35175	Due	
392-2	35176-35178	to	
392-3	35179-35182	the	
392-4	35183-35187	lack	
392-5	35188-35190	of	
392-6	35191-35195	time	
392-7	35195-35196	,	
392-8	35197-35202	there	
392-9	35203-35206	are	
392-10	35207-35212	still	
392-11	35213-35217	many	
392-12	35218-35223	other	
392-13	35224-35228	nice	
392-14	35229-35237	features	
392-15	35238-35241	not	
392-16	35242-35247	being	
392-17	35248-35255	covered	
392-18	35256-35258	by	
392-19	35259-35263	this	
392-20	35264-35268	talk	
392-21	35268-35269	.	

#Text=Please download Spark 3.0 and try yourself.
393-1	35270-35276	Please	
393-2	35277-35285	download	
393-3	35286-35291	Spark	
393-4	35292-35295	3.0	
393-5	35296-35299	and	
393-6	35300-35303	try	
393-7	35304-35312	yourself	
393-8	35312-35313	.	

#Text=You can also try the
#Text=[inaudible] Databricks [inaudible] 10.0 beta.
394-1	35314-35317	You	
394-2	35318-35321	can	
394-3	35322-35326	also	
394-4	35327-35330	try	
394-5	35331-35334	the	
394-6	35335-35336	[	
394-7	35336-35345	inaudible	
394-8	35345-35346	]	
394-9	35347-35357	Databricks	
394-10	35358-35359	[	
394-11	35359-35368	inaudible	
394-12	35368-35369	]	
394-13	35370-35374	10.0	
394-14	35375-35379	beta	
394-15	35379-35380	.	

#Text=All the new features are already available.
395-1	35381-35384	All	
395-2	35385-35388	the	
395-3	35389-35392	new	
395-4	35393-35401	features	
395-5	35402-35405	are	
395-6	35406-35413	already	
395-7	35414-35423	available	
395-8	35423-35424	.	

#Text=The Community Edition is for free.
396-1	35425-35428	The	
396-2	35429-35438	Community	
396-3	35439-35446	Edition	
396-4	35447-35449	is	
396-5	35450-35453	for	
396-6	35454-35458	free	
396-7	35458-35459	.	

#Text=Without the contributions by the whole community,
#Text=it is impossible to deliver such a successful release.
397-1	35460-35467	Without	
397-2	35468-35471	the	
397-3	35472-35485	contributions	
397-4	35486-35488	by	
397-5	35489-35492	the	
397-6	35493-35498	whole	
397-7	35499-35508	community	
397-8	35508-35509	,	
397-9	35510-35512	it	
397-10	35513-35515	is	
397-11	35516-35526	impossible	
397-12	35527-35529	to	
397-13	35530-35537	deliver	
397-14	35538-35542	such	
397-15	35543-35544	a	
397-16	35545-35555	successful	
397-17	35556-35563	release	
397-18	35563-35564	.	

#Text=It’s thanks to all the Spark committers
#Text=all over the world.
398-1	35565-35567	It	
398-2	35567-35568	’	
398-3	35568-35569	s	
398-4	35570-35576	thanks	
398-5	35577-35579	to	
398-6	35580-35583	all	
398-7	35584-35587	the	
398-8	35588-35593	Spark	
398-9	35594-35604	committers	
398-10	35605-35608	all	
398-11	35609-35613	over	
398-12	35614-35617	the	
398-13	35618-35623	world	
398-14	35623-35624	.	

#Text=Thank you.
399-1	35625-35630	Thank	
399-2	35631-35634	you	
399-3	35634-35635	.	

#Text=Thank you, everyone.
400-1	35636-35641	Thank	
400-2	35642-35645	you	
400-3	35645-35646	,	
400-4	35647-35655	everyone	
400-5	35655-35656	.	

#Text=Watch more Spark + AI sessions here
#Text=Try Databricks for free
#Text=« back
#Text=About Xiao Li
#Text=Databricks
#Text=Xiao Li is an engineering manager, Apache Spark Committer and PMC member at Databricks.
401-1	35657-35662	Watch	
401-2	35663-35667	more	
401-3	35668-35673	Spark	
401-4	35674-35675	+	
401-5	35676-35678	AI	
401-6	35679-35687	sessions	
401-7	35688-35692	here	
401-8	35693-35696	Try	
401-9	35697-35707	Databricks	
401-10	35708-35711	for	
401-11	35712-35716	free	
401-12	35717-35718	«	
401-13	35719-35723	back	
401-14	35724-35729	About	
401-15	35730-35734	Xiao	
401-16	35735-35737	Li	
401-17	35738-35748	Databricks	
401-18	35749-35753	Xiao	
401-19	35754-35756	Li	
401-20	35757-35759	is	
401-21	35760-35762	an	
401-22	35763-35774	engineering	
401-23	35775-35782	manager	
401-24	35782-35783	,	
401-25	35784-35790	Apache	
401-26	35791-35796	Spark	
401-27	35797-35806	Committer	
401-28	35807-35810	and	
401-29	35811-35814	PMC	
401-30	35815-35821	member	
401-31	35822-35824	at	
401-32	35825-35835	Databricks	
401-33	35835-35836	.	

#Text=His main interests are on Spark SQL, data replication and data integration.
402-1	35837-35840	His	
402-2	35841-35845	main	
402-3	35846-35855	interests	
402-4	35856-35859	are	
402-5	35860-35862	on	
402-6	35863-35868	Spark	
402-7	35869-35872	SQL	
402-8	35872-35873	,	
402-9	35874-35878	data	
402-10	35879-35890	replication	
402-11	35891-35894	and	
402-12	35895-35899	data	
402-13	35900-35911	integration	
402-14	35911-35912	.	

#Text=Previously, he was an IBM master inventor and an expert on asynchronous database replication and consistency verification.
403-1	35913-35923	Previously	
403-2	35923-35924	,	
403-3	35925-35927	he	
403-4	35928-35931	was	
403-5	35932-35934	an	
403-6	35935-35938	IBM	
403-7	35939-35945	master	
403-8	35946-35954	inventor	
403-9	35955-35958	and	
403-10	35959-35961	an	
403-11	35962-35968	expert	
403-12	35969-35971	on	
403-13	35972-35984	asynchronous	
403-14	35985-35993	database	
403-15	35994-36005	replication	
403-16	36006-36009	and	
403-17	36010-36021	consistency	
403-18	36022-36034	verification	
403-19	36034-36035	.	

#Text=He received his Ph.D. from University of Florida in 2011.
404-1	36036-36038	He	
404-2	36039-36047	received	
404-3	36048-36051	his	
404-4	36052-36056	Ph.D	
404-5	36056-36057	.	
404-6	36058-36062	from	
404-7	36063-36073	University	
404-8	36074-36076	of	
404-9	36077-36084	Florida	
404-10	36085-36087	in	
404-11	36088-36092	2011	
404-12	36092-36093	.	

#Text=About Wenchen Fan
#Text=Databricks
#Text=Wenchen Fan is a software engineer at Databricks, working on Spark Core and Spark SQL.
405-1	36094-36099	About	
405-2	36100-36107	Wenchen	
405-3	36108-36111	Fan	
405-4	36112-36122	Databricks	
405-5	36123-36130	Wenchen	
405-6	36131-36134	Fan	
405-7	36135-36137	is	
405-8	36138-36139	a	
405-9	36140-36148	software	
405-10	36149-36157	engineer	
405-11	36158-36160	at	
405-12	36161-36171	Databricks	
405-13	36171-36172	,	
405-14	36173-36180	working	
405-15	36181-36183	on	
405-16	36184-36189	Spark	
405-17	36190-36194	Core	
405-18	36195-36198	and	
405-19	36199-36204	Spark	
405-20	36205-36208	SQL	
405-21	36208-36209	.	

#Text=He mainly focuses on the Apache Spark open source community, leading the discussion and reviews of many features/fixes in Spark.
406-1	36210-36212	He	
406-2	36213-36219	mainly	
406-3	36220-36227	focuses	
406-4	36228-36230	on	
406-5	36231-36234	the	
406-6	36235-36241	Apache	
406-7	36242-36247	Spark	
406-8	36248-36252	open	
406-9	36253-36259	source	
406-10	36260-36269	community	
406-11	36269-36270	,	
406-12	36271-36278	leading	
406-13	36279-36282	the	
406-14	36283-36293	discussion	
406-15	36294-36297	and	
406-16	36298-36305	reviews	
406-17	36306-36308	of	
406-18	36309-36313	many	
406-19	36314-36322	features	
406-20	36322-36323	/	
406-21	36323-36328	fixes	
406-22	36329-36331	in	
406-23	36332-36337	Spark	
406-24	36337-36338	.	

#Text=He is a Spark committer and a Spark PMC member.
407-1	36339-36341	He	
407-2	36342-36344	is	
407-3	36345-36346	a	
407-4	36347-36352	Spark	
407-5	36353-36362	committer	
407-6	36363-36366	and	
407-7	36367-36368	a	
407-8	36369-36374	Spark	
407-9	36375-36378	PMC	
407-10	36379-36385	member	
407-11	36385-36386	.	

#Text=Video Archive
#Text=Terms of Use
#Text=Privacy Policy
#Text=Event Policy
#Text=Looking for a talk from a past event?
408-1	36387-36392	Video	
408-2	36393-36400	Archive	
408-3	36401-36406	Terms	
408-4	36407-36409	of	
408-5	36410-36413	Use	
408-6	36414-36421	Privacy	
408-7	36422-36428	Policy	
408-8	36429-36434	Event	
408-9	36435-36441	Policy	
408-10	36442-36449	Looking	
408-11	36450-36453	for	
408-12	36454-36455	a	
408-13	36456-36460	talk	
408-14	36461-36465	from	
408-15	36466-36467	a	
408-16	36468-36472	past	
408-17	36473-36478	event	
408-18	36478-36479	?	

#Text=Check the Video Archive
#Text=Organized by Databricks
#Text=If you have questions, or would like information on sponsoring a Spark + AI Summit, please contact organizers@spark-summit.org.
409-1	36480-36485	Check	
409-2	36486-36489	the	
409-3	36490-36495	Video	
409-4	36496-36503	Archive	
409-5	36504-36513	Organized	
409-6	36514-36516	by	
409-7	36517-36527	Databricks	
409-8	36528-36530	If	
409-9	36531-36534	you	
409-10	36535-36539	have	
409-11	36540-36549	questions	
409-12	36549-36550	,	
409-13	36551-36553	or	
409-14	36554-36559	would	
409-15	36560-36564	like	
409-16	36565-36576	information	
409-17	36577-36579	on	
409-18	36580-36590	sponsoring	
409-19	36591-36592	a	
409-20	36593-36598	Spark	
409-21	36599-36600	+	
409-22	36601-36603	AI	
409-23	36604-36610	Summit	
409-24	36610-36611	,	
409-25	36612-36618	please	
409-26	36619-36626	contact	
409-27	36627-36637	organizers	
409-28	36637-36638	@	
409-29	36638-36654	spark-summit.org	
409-30	36654-36655	.	

#Text=Apache, Apache Spark, Spark, and the Spark logo are trademarks of the Apache Software Foundation.
410-1	36656-36662	Apache	
410-2	36662-36663	,	
410-3	36664-36670	Apache	
410-4	36671-36676	Spark	
410-5	36676-36677	,	
410-6	36678-36683	Spark	
410-7	36683-36684	,	
410-8	36685-36688	and	
410-9	36689-36692	the	
410-10	36693-36698	Spark	
410-11	36699-36703	logo	
410-12	36704-36707	are	
410-13	36708-36718	trademarks	
410-14	36719-36721	of	
410-15	36722-36725	the	
410-16	36726-36732	Apache	
410-17	36733-36741	Software	
410-18	36742-36752	Foundation	
410-19	36752-36753	.	

#Text=The Apache Software Foundation has no affiliation with and does not endorse the materials provided at this event.
411-1	36754-36757	The	
411-2	36758-36764	Apache	
411-3	36765-36773	Software	
411-4	36774-36784	Foundation	
411-5	36785-36788	has	
411-6	36789-36791	no	
411-7	36792-36803	affiliation	
411-8	36804-36808	with	
411-9	36809-36812	and	
411-10	36813-36817	does	
411-11	36818-36821	not	
411-12	36822-36829	endorse	
411-13	36830-36833	the	
411-14	36834-36843	materials	
411-15	36844-36852	provided	
411-16	36853-36855	at	
411-17	36856-36860	this	
411-18	36861-36866	event	
411-19	36866-36867	.	
