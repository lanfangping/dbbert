#FORMAT=WebAnno TSV 3.3


#Text=Mapping data flow performance and tuning guide - Azure Data Factory | Microsoft Docs Skip to main content Contents Exit focus mode Bookmark Feedback Edit Share Twitter LinkedIn Facebook
1-1	0-7	Mapping	
1-2	8-12	data	
1-3	13-17	flow	
1-4	18-29	performance	
1-5	30-33	and	
1-6	34-40	tuning	
1-7	41-46	guide	
1-8	47-48	-	
1-9	49-54	Azure	
1-10	55-59	Data	
1-11	60-67	Factory	
1-12	68-69	|	
1-13	70-79	Microsoft	
1-14	80-84	Docs	
1-15	85-89	Skip	
1-16	90-92	to	
1-17	93-97	main	
1-18	98-105	content	
1-19	106-114	Contents	
1-20	115-119	Exit	
1-21	120-125	focus	
1-22	126-130	mode	
1-23	131-139	Bookmark	
1-24	140-148	Feedback	
1-25	149-153	Edit	
1-26	154-159	Share	
1-27	160-167	Twitter	
1-28	168-176	LinkedIn	
1-29	177-185	Facebook	

#Text=Email Table of contents Mapping data flows performance and tuning guide 03/15/2021 21 minutes to read In this article APPLIES TO: Azure Data Factory Azure Synapse Analytics
2-1	186-191	Email	
2-2	192-197	Table	
2-3	198-200	of	
2-4	201-209	contents	
2-5	210-217	Mapping	
2-6	218-222	data	
2-7	223-228	flows	
2-8	229-240	performance	
2-9	241-244	and	
2-10	245-251	tuning	
2-11	252-257	guide	
2-12	258-260	03	
2-13	260-261	/	
2-14	261-263	15	
2-15	263-264	/	
2-16	264-268	2021	
2-17	269-271	21	
2-18	272-279	minutes	
2-19	280-282	to	
2-20	283-287	read	
2-21	288-290	In	
2-22	291-295	this	
2-23	296-303	article	
2-24	304-311	APPLIES	
2-25	312-314	TO	
2-26	314-315	:	
2-27	316-321	Azure	
2-28	322-326	Data	
2-29	327-334	Factory	
2-30	335-340	Azure	
2-31	341-348	Synapse	
2-32	349-358	Analytics	

#Text=Mapping data flows in Azure Data Factory provide a code-free interface to design and run data transformations at scale. If you're not familiar with mapping data flows, see the Mapping Data Flow Overview. This article highlights various ways to tune and optimize your data flows so that they meet your performance benchmarks. Watch the below video to see shows some sample timings transforming data with data flows. Testing data flow logic When designing and testing data flows from the ADF UX, debug mode allows you to interactively test against a live Spark cluster. This allows you to preview data and execute your data flows without waiting for a cluster to warm up. For more information, see Debug Mode.
3-1	359-366	Mapping	
3-2	367-371	data	
3-3	372-377	flows	
3-4	378-380	in	
3-5	381-386	Azure	
3-6	387-391	Data	
3-7	392-399	Factory	
3-8	400-407	provide	
3-9	408-409	a	
3-10	410-419	code-free	
3-11	420-429	interface	
3-12	430-432	to	
3-13	433-439	design	
3-14	440-443	and	
3-15	444-447	run	
3-16	448-452	data	
3-17	453-468	transformations	
3-18	469-471	at	
3-19	472-477	scale	
3-20	477-478	.	
3-21	479-481	If	
3-22	482-488	you're	
3-23	489-492	not	
3-24	493-501	familiar	
3-25	502-506	with	
3-26	507-514	mapping	
3-27	515-519	data	
3-28	520-525	flows	
3-29	525-526	,	
3-30	527-530	see	
3-31	531-534	the	
3-32	535-542	Mapping	
3-33	543-547	Data	
3-34	548-552	Flow	
3-35	553-561	Overview	
3-36	561-562	.	
3-37	563-567	This	
3-38	568-575	article	
3-39	576-586	highlights	
3-40	587-594	various	
3-41	595-599	ways	
3-42	600-602	to	
3-43	603-607	tune	
3-44	608-611	and	
3-45	612-620	optimize	
3-46	621-625	your	
3-47	626-630	data	
3-48	631-636	flows	
3-49	637-639	so	
3-50	640-644	that	
3-51	645-649	they	
3-52	650-654	meet	
3-53	655-659	your	
3-54	660-671	performance	
3-55	672-682	benchmarks	
3-56	682-683	.	
3-57	684-689	Watch	
3-58	690-693	the	
3-59	694-699	below	
3-60	700-705	video	
3-61	706-708	to	
3-62	709-712	see	
3-63	713-718	shows	
3-64	719-723	some	
3-65	724-730	sample	
3-66	731-738	timings	
3-67	739-751	transforming	
3-68	752-756	data	
3-69	757-761	with	
3-70	762-766	data	
3-71	767-772	flows	
3-72	772-773	.	
3-73	774-781	Testing	
3-74	782-786	data	
3-75	787-791	flow	
3-76	792-797	logic	
3-77	798-802	When	
3-78	803-812	designing	
3-79	813-816	and	
3-80	817-824	testing	
3-81	825-829	data	
3-82	830-835	flows	
3-83	836-840	from	
3-84	841-844	the	
3-85	845-848	ADF	
3-86	849-851	UX	
3-87	851-852	,	
3-88	853-858	debug	
3-89	859-863	mode	
3-90	864-870	allows	
3-91	871-874	you	
3-92	875-877	to	
3-93	878-891	interactively	
3-94	892-896	test	
3-95	897-904	against	
3-96	905-906	a	
3-97	907-911	live	
3-98	912-917	Spark	
3-99	918-925	cluster	
3-100	925-926	.	
3-101	927-931	This	
3-102	932-938	allows	
3-103	939-942	you	
3-104	943-945	to	
3-105	946-953	preview	
3-106	954-958	data	
3-107	959-962	and	
3-108	963-970	execute	
3-109	971-975	your	
3-110	976-980	data	
3-111	981-986	flows	
3-112	987-994	without	
3-113	995-1002	waiting	
3-114	1003-1006	for	
3-115	1007-1008	a	
3-116	1009-1016	cluster	
3-117	1017-1019	to	
3-118	1020-1024	warm	
3-119	1025-1027	up	
3-120	1027-1028	.	
3-121	1029-1032	For	
3-122	1033-1037	more	
3-123	1038-1049	information	
3-124	1049-1050	,	
3-125	1051-1054	see	
3-126	1055-1060	Debug	
3-127	1061-1065	Mode	
3-128	1065-1066	.	

#Text=Monitoring data flow performance Once you verify your transformation logic using debug mode, run your data flow end-to-end as an activity in a pipeline. Data flows are operationalized in a pipeline using the execute data flow activity. The data flow activity has a unique monitoring experience compared to other Azure Data Factory activities that displays a detailed execution plan and performance profile of the transformation logic. To view detailed monitoring information of a data flow, click on the eyeglasses icon in the activity run output of a pipeline. For more information, see Monitoring mapping data flows.
4-1	1067-1077	Monitoring	
4-2	1078-1082	data	
4-3	1083-1087	flow	
4-4	1088-1099	performance	
4-5	1100-1104	Once	
4-6	1105-1108	you	
4-7	1109-1115	verify	
4-8	1116-1120	your	
4-9	1121-1135	transformation	
4-10	1136-1141	logic	
4-11	1142-1147	using	
4-12	1148-1153	debug	
4-13	1154-1158	mode	
4-14	1158-1159	,	
4-15	1160-1163	run	
4-16	1164-1168	your	
4-17	1169-1173	data	
4-18	1174-1178	flow	
4-19	1179-1189	end-to-end	
4-20	1190-1192	as	
4-21	1193-1195	an	
4-22	1196-1204	activity	
4-23	1205-1207	in	
4-24	1208-1209	a	
4-25	1210-1218	pipeline	
4-26	1218-1219	.	
4-27	1220-1224	Data	
4-28	1225-1230	flows	
4-29	1231-1234	are	
4-30	1235-1250	operationalized	
4-31	1251-1253	in	
4-32	1254-1255	a	
4-33	1256-1264	pipeline	
4-34	1265-1270	using	
4-35	1271-1274	the	
4-36	1275-1282	execute	
4-37	1283-1287	data	
4-38	1288-1292	flow	
4-39	1293-1301	activity	
4-40	1301-1302	.	
4-41	1303-1306	The	
4-42	1307-1311	data	
4-43	1312-1316	flow	
4-44	1317-1325	activity	
4-45	1326-1329	has	
4-46	1330-1331	a	
4-47	1332-1338	unique	
4-48	1339-1349	monitoring	
4-49	1350-1360	experience	
4-50	1361-1369	compared	
4-51	1370-1372	to	
4-52	1373-1378	other	
4-53	1379-1384	Azure	
4-54	1385-1389	Data	
4-55	1390-1397	Factory	
4-56	1398-1408	activities	
4-57	1409-1413	that	
4-58	1414-1422	displays	
4-59	1423-1424	a	
4-60	1425-1433	detailed	
4-61	1434-1443	execution	
4-62	1444-1448	plan	
4-63	1449-1452	and	
4-64	1453-1464	performance	
4-65	1465-1472	profile	
4-66	1473-1475	of	
4-67	1476-1479	the	
4-68	1480-1494	transformation	
4-69	1495-1500	logic	
4-70	1500-1501	.	
4-71	1502-1504	To	
4-72	1505-1509	view	
4-73	1510-1518	detailed	
4-74	1519-1529	monitoring	
4-75	1530-1541	information	
4-76	1542-1544	of	
4-77	1545-1546	a	
4-78	1547-1551	data	
4-79	1552-1556	flow	
4-80	1556-1557	,	
4-81	1558-1563	click	
4-82	1564-1566	on	
4-83	1567-1570	the	
4-84	1571-1581	eyeglasses	
4-85	1582-1586	icon	
4-86	1587-1589	in	
4-87	1590-1593	the	
4-88	1594-1602	activity	
4-89	1603-1606	run	
4-90	1607-1613	output	
4-91	1614-1616	of	
4-92	1617-1618	a	
4-93	1619-1627	pipeline	
4-94	1627-1628	.	
4-95	1629-1632	For	
4-96	1633-1637	more	
4-97	1638-1649	information	
4-98	1649-1650	,	
4-99	1651-1654	see	
4-100	1655-1665	Monitoring	
4-101	1666-1673	mapping	
4-102	1674-1678	data	
4-103	1679-1684	flows	
4-104	1684-1685	.	

#Text=When monitoring data flow performance, there are four possible bottlenecks to look out for: Cluster start-up time Reading from a source Transformation time Writing to a sink
5-1	1686-1690	When	
5-2	1691-1701	monitoring	
5-3	1702-1706	data	
5-4	1707-1711	flow	
5-5	1712-1723	performance	
5-6	1723-1724	,	
5-7	1725-1730	there	
5-8	1731-1734	are	
5-9	1735-1739	four	
5-10	1740-1748	possible	
5-11	1749-1760	bottlenecks	
5-12	1761-1763	to	
5-13	1764-1768	look	
5-14	1769-1772	out	
5-15	1773-1776	for	
5-16	1776-1777	:	
5-17	1778-1785	Cluster	
5-18	1786-1794	start-up	
5-19	1795-1799	time	
5-20	1800-1807	Reading	
5-21	1808-1812	from	
5-22	1813-1814	a	
5-23	1815-1821	source	
5-24	1822-1836	Transformation	
5-25	1837-1841	time	
5-26	1842-1849	Writing	
5-27	1850-1852	to	
5-28	1853-1854	a	
5-29	1855-1859	sink	

#Text=Cluster start-up time is the time it takes to spin up an Apache Spark cluster. This value is located in the top-right corner of the monitoring screen. Data flows run on a just-in-time model where each job uses an isolated cluster. This start-up time generally takes 3-5 minutes. For sequential jobs, this can be reduced by enabling a time to live value. For more information, see optimizing the Azure Integration Runtime.
6-1	1860-1867	Cluster	
6-2	1868-1876	start-up	
6-3	1877-1881	time	
6-4	1882-1884	is	
6-5	1885-1888	the	
6-6	1889-1893	time	
6-7	1894-1896	it	
6-8	1897-1902	takes	
6-9	1903-1905	to	
6-10	1906-1910	spin	
6-11	1911-1913	up	
6-12	1914-1916	an	
6-13	1917-1923	Apache	
6-14	1924-1929	Spark	
6-15	1930-1937	cluster	
6-16	1937-1938	.	
6-17	1939-1943	This	
6-18	1944-1949	value	
6-19	1950-1952	is	
6-20	1953-1960	located	
6-21	1961-1963	in	
6-22	1964-1967	the	
6-23	1968-1977	top-right	
6-24	1978-1984	corner	
6-25	1985-1987	of	
6-26	1988-1991	the	
6-27	1992-2002	monitoring	
6-28	2003-2009	screen	
6-29	2009-2010	.	
6-30	2011-2015	Data	
6-31	2016-2021	flows	
6-32	2022-2025	run	
6-33	2026-2028	on	
6-34	2029-2030	a	
6-35	2031-2043	just-in-time	
6-36	2044-2049	model	
6-37	2050-2055	where	
6-38	2056-2060	each	
6-39	2061-2064	job	
6-40	2065-2069	uses	
6-41	2070-2072	an	
6-42	2073-2081	isolated	
6-43	2082-2089	cluster	
6-44	2089-2090	.	
6-45	2091-2095	This	
6-46	2096-2104	start-up	
6-47	2105-2109	time	
6-48	2110-2119	generally	
6-49	2120-2125	takes	
6-50	2126-2127	3	
6-51	2127-2128	-	
6-52	2128-2129	5	
6-53	2130-2137	minutes	
6-54	2137-2138	.	
6-55	2139-2142	For	
6-56	2143-2153	sequential	
6-57	2154-2158	jobs	
6-58	2158-2159	,	
6-59	2160-2164	this	
6-60	2165-2168	can	
6-61	2169-2171	be	
6-62	2172-2179	reduced	
6-63	2180-2182	by	
6-64	2183-2191	enabling	
6-65	2192-2193	a	
6-66	2194-2198	time	
6-67	2199-2201	to	
6-68	2202-2206	live	
6-69	2207-2212	value	
6-70	2212-2213	.	
6-71	2214-2217	For	
6-72	2218-2222	more	
6-73	2223-2234	information	
6-74	2234-2235	,	
6-75	2236-2239	see	
6-76	2240-2250	optimizing	
6-77	2251-2254	the	
6-78	2255-2260	Azure	
6-79	2261-2272	Integration	
6-80	2273-2280	Runtime	
6-81	2280-2281	.	

#Text=Data flows utilize a Spark optimizer that reorders and runs your business logic in 'stages' to perform as quickly as possible. For each sink that your data flow writes to, the monitoring output lists the duration of each transformation stage, along with the time it takes to write data into the sink. The time that is the largest is likely the bottleneck of your data flow. If the transformation stage that takes the largest contains a source, then you may want to look at further optimizing your read time. If a transformation is taking a long time, then you may need to repartition or increase the size of your integration runtime. If the sink processing time is large, you may need to scale up your database or verify you are not outputting to a single file. Once you have identified the bottleneck of your data flow, use the below optimizations strategies to improve performance. Optimize tab
7-1	2282-2286	Data	
7-2	2287-2292	flows	
7-3	2293-2300	utilize	
7-4	2301-2302	a	
7-5	2303-2308	Spark	
7-6	2309-2318	optimizer	
7-7	2319-2323	that	
7-8	2324-2332	reorders	
7-9	2333-2336	and	
7-10	2337-2341	runs	
7-11	2342-2346	your	
7-12	2347-2355	business	
7-13	2356-2361	logic	
7-14	2362-2364	in	
7-15	2365-2366	'	
7-16	2366-2372	stages	
7-17	2372-2373	'	
7-18	2374-2376	to	
7-19	2377-2384	perform	
7-20	2385-2387	as	
7-21	2388-2395	quickly	
7-22	2396-2398	as	
7-23	2399-2407	possible	
7-24	2407-2408	.	
7-25	2409-2412	For	
7-26	2413-2417	each	
7-27	2418-2422	sink	
7-28	2423-2427	that	
7-29	2428-2432	your	
7-30	2433-2437	data	
7-31	2438-2442	flow	
7-32	2443-2449	writes	
7-33	2450-2452	to	
7-34	2452-2453	,	
7-35	2454-2457	the	
7-36	2458-2468	monitoring	
7-37	2469-2475	output	
7-38	2476-2481	lists	
7-39	2482-2485	the	
7-40	2486-2494	duration	
7-41	2495-2497	of	
7-42	2498-2502	each	
7-43	2503-2517	transformation	
7-44	2518-2523	stage	
7-45	2523-2524	,	
7-46	2525-2530	along	
7-47	2531-2535	with	
7-48	2536-2539	the	
7-49	2540-2544	time	
7-50	2545-2547	it	
7-51	2548-2553	takes	
7-52	2554-2556	to	
7-53	2557-2562	write	
7-54	2563-2567	data	
7-55	2568-2572	into	
7-56	2573-2576	the	
7-57	2577-2581	sink	
7-58	2581-2582	.	
7-59	2583-2586	The	
7-60	2587-2591	time	
7-61	2592-2596	that	
7-62	2597-2599	is	
7-63	2600-2603	the	
7-64	2604-2611	largest	
7-65	2612-2614	is	
7-66	2615-2621	likely	
7-67	2622-2625	the	
7-68	2626-2636	bottleneck	
7-69	2637-2639	of	
7-70	2640-2644	your	
7-71	2645-2649	data	
7-72	2650-2654	flow	
7-73	2654-2655	.	
7-74	2656-2658	If	
7-75	2659-2662	the	
7-76	2663-2677	transformation	
7-77	2678-2683	stage	
7-78	2684-2688	that	
7-79	2689-2694	takes	
7-80	2695-2698	the	
7-81	2699-2706	largest	
7-82	2707-2715	contains	
7-83	2716-2717	a	
7-84	2718-2724	source	
7-85	2724-2725	,	
7-86	2726-2730	then	
7-87	2731-2734	you	
7-88	2735-2738	may	
7-89	2739-2743	want	
7-90	2744-2746	to	
7-91	2747-2751	look	
7-92	2752-2754	at	
7-93	2755-2762	further	
7-94	2763-2773	optimizing	
7-95	2774-2778	your	
7-96	2779-2783	read	
7-97	2784-2788	time	
7-98	2788-2789	.	
7-99	2790-2792	If	
7-100	2793-2794	a	
7-101	2795-2809	transformation	
7-102	2810-2812	is	
7-103	2813-2819	taking	
7-104	2820-2821	a	
7-105	2822-2826	long	
7-106	2827-2831	time	
7-107	2831-2832	,	
7-108	2833-2837	then	
7-109	2838-2841	you	
7-110	2842-2845	may	
7-111	2846-2850	need	
7-112	2851-2853	to	
7-113	2854-2865	repartition	
7-114	2866-2868	or	
7-115	2869-2877	increase	
7-116	2878-2881	the	
7-117	2882-2886	size	
7-118	2887-2889	of	
7-119	2890-2894	your	
7-120	2895-2906	integration	
7-121	2907-2914	runtime	
7-122	2914-2915	.	
7-123	2916-2918	If	
7-124	2919-2922	the	
7-125	2923-2927	sink	
7-126	2928-2938	processing	
7-127	2939-2943	time	
7-128	2944-2946	is	
7-129	2947-2952	large	
7-130	2952-2953	,	
7-131	2954-2957	you	
7-132	2958-2961	may	
7-133	2962-2966	need	
7-134	2967-2969	to	
7-135	2970-2975	scale	
7-136	2976-2978	up	
7-137	2979-2983	your	
7-138	2984-2992	database	
7-139	2993-2995	or	
7-140	2996-3002	verify	
7-141	3003-3006	you	
7-142	3007-3010	are	
7-143	3011-3014	not	
7-144	3015-3025	outputting	
7-145	3026-3028	to	
7-146	3029-3030	a	
7-147	3031-3037	single	
7-148	3038-3042	file	
7-149	3042-3043	.	
7-150	3044-3048	Once	
7-151	3049-3052	you	
7-152	3053-3057	have	
7-153	3058-3068	identified	
7-154	3069-3072	the	
7-155	3073-3083	bottleneck	
7-156	3084-3086	of	
7-157	3087-3091	your	
7-158	3092-3096	data	
7-159	3097-3101	flow	
7-160	3101-3102	,	
7-161	3103-3106	use	
7-162	3107-3110	the	
7-163	3111-3116	below	
7-164	3117-3130	optimizations	
7-165	3131-3141	strategies	
7-166	3142-3144	to	
7-167	3145-3152	improve	
7-168	3153-3164	performance	
7-169	3164-3165	.	
7-170	3166-3174	Optimize	
7-171	3175-3178	tab	

#Text=The Optimize tab contains settings to configure the partitioning scheme of the Spark cluster. This tab exists in every transformation of data flow and specifies whether you want to repartition the data after the transformation has completed. Adjusting the partitioning provides control over the distribution of your data across compute nodes and data locality optimizations that can have both positive and negative effects on your overall data flow performance. By default, Use current partitioning is selected which instructs Azure Data Factory keep the current output partitioning of the transformation. As repartitioning data takes time, Use current partitioning is recommended in most scenarios. Scenarios where you may want to repartition your data include after aggregates and joins that significantly skew your data or when using Source partitioning on a SQL DB.
8-1	3179-3182	The	
8-2	3183-3191	Optimize	
8-3	3192-3195	tab	
8-4	3196-3204	contains	
8-5	3205-3213	settings	
8-6	3214-3216	to	
8-7	3217-3226	configure	
8-8	3227-3230	the	
8-9	3231-3243	partitioning	
8-10	3244-3250	scheme	
8-11	3251-3253	of	
8-12	3254-3257	the	
8-13	3258-3263	Spark	
8-14	3264-3271	cluster	
8-15	3271-3272	.	
8-16	3273-3277	This	
8-17	3278-3281	tab	
8-18	3282-3288	exists	
8-19	3289-3291	in	
8-20	3292-3297	every	
8-21	3298-3312	transformation	
8-22	3313-3315	of	
8-23	3316-3320	data	
8-24	3321-3325	flow	
8-25	3326-3329	and	
8-26	3330-3339	specifies	
8-27	3340-3347	whether	
8-28	3348-3351	you	
8-29	3352-3356	want	
8-30	3357-3359	to	
8-31	3360-3371	repartition	
8-32	3372-3375	the	
8-33	3376-3380	data	
8-34	3381-3386	after	
8-35	3387-3390	the	
8-36	3391-3405	transformation	
8-37	3406-3409	has	
8-38	3410-3419	completed	
8-39	3419-3420	.	
8-40	3421-3430	Adjusting	
8-41	3431-3434	the	
8-42	3435-3447	partitioning	
8-43	3448-3456	provides	
8-44	3457-3464	control	
8-45	3465-3469	over	
8-46	3470-3473	the	
8-47	3474-3486	distribution	
8-48	3487-3489	of	
8-49	3490-3494	your	
8-50	3495-3499	data	
8-51	3500-3506	across	
8-52	3507-3514	compute	
8-53	3515-3520	nodes	
8-54	3521-3524	and	
8-55	3525-3529	data	
8-56	3530-3538	locality	
8-57	3539-3552	optimizations	
8-58	3553-3557	that	
8-59	3558-3561	can	
8-60	3562-3566	have	
8-61	3567-3571	both	
8-62	3572-3580	positive	
8-63	3581-3584	and	
8-64	3585-3593	negative	
8-65	3594-3601	effects	
8-66	3602-3604	on	
8-67	3605-3609	your	
8-68	3610-3617	overall	
8-69	3618-3622	data	
8-70	3623-3627	flow	
8-71	3628-3639	performance	
8-72	3639-3640	.	
8-73	3641-3643	By	
8-74	3644-3651	default	
8-75	3651-3652	,	
8-76	3653-3656	Use	
8-77	3657-3664	current	
8-78	3665-3677	partitioning	
8-79	3678-3680	is	
8-80	3681-3689	selected	
8-81	3690-3695	which	
8-82	3696-3705	instructs	
8-83	3706-3711	Azure	
8-84	3712-3716	Data	
8-85	3717-3724	Factory	
8-86	3725-3729	keep	
8-87	3730-3733	the	
8-88	3734-3741	current	
8-89	3742-3748	output	
8-90	3749-3761	partitioning	
8-91	3762-3764	of	
8-92	3765-3768	the	
8-93	3769-3783	transformation	
8-94	3783-3784	.	
8-95	3785-3787	As	
8-96	3788-3802	repartitioning	
8-97	3803-3807	data	
8-98	3808-3813	takes	
8-99	3814-3818	time	
8-100	3818-3819	,	
8-101	3820-3823	Use	
8-102	3824-3831	current	
8-103	3832-3844	partitioning	
8-104	3845-3847	is	
8-105	3848-3859	recommended	
8-106	3860-3862	in	
8-107	3863-3867	most	
8-108	3868-3877	scenarios	
8-109	3877-3878	.	
8-110	3879-3888	Scenarios	
8-111	3889-3894	where	
8-112	3895-3898	you	
8-113	3899-3902	may	
8-114	3903-3907	want	
8-115	3908-3910	to	
8-116	3911-3922	repartition	
8-117	3923-3927	your	
8-118	3928-3932	data	
8-119	3933-3940	include	
8-120	3941-3946	after	
8-121	3947-3957	aggregates	
8-122	3958-3961	and	
8-123	3962-3967	joins	
8-124	3968-3972	that	
8-125	3973-3986	significantly	
8-126	3987-3991	skew	
8-127	3992-3996	your	
8-128	3997-4001	data	
8-129	4002-4004	or	
8-130	4005-4009	when	
8-131	4010-4015	using	
8-132	4016-4022	Source	
8-133	4023-4035	partitioning	
8-134	4036-4038	on	
8-135	4039-4040	a	
8-136	4041-4044	SQL	
8-137	4045-4047	DB	
8-138	4047-4048	.	

#Text=To change the partitioning on any transformation, select the Optimize tab and select the Set Partitioning radio button. You are presented with a series of options for partitioning. The best method of partitioning differs based on your data volumes, candidate keys, null values, and cardinality. Important Single partition combines all the distributed data into a single partition. This is a very slow operation that also significantly affects all downstream transformation and writes. The Azure Data Factory highly recommends against using this option unless there is an explicit business reason to do so. The following partitioning options are available in every transformation:
9-1	4049-4051	To	
9-2	4052-4058	change	
9-3	4059-4062	the	
9-4	4063-4075	partitioning	
9-5	4076-4078	on	
9-6	4079-4082	any	
9-7	4083-4097	transformation	
9-8	4097-4098	,	
9-9	4099-4105	select	
9-10	4106-4109	the	
9-11	4110-4118	Optimize	
9-12	4119-4122	tab	
9-13	4123-4126	and	
9-14	4127-4133	select	
9-15	4134-4137	the	
9-16	4138-4141	Set	
9-17	4142-4154	Partitioning	
9-18	4155-4160	radio	
9-19	4161-4167	button	
9-20	4167-4168	.	
9-21	4169-4172	You	
9-22	4173-4176	are	
9-23	4177-4186	presented	
9-24	4187-4191	with	
9-25	4192-4193	a	
9-26	4194-4200	series	
9-27	4201-4203	of	
9-28	4204-4211	options	
9-29	4212-4215	for	
9-30	4216-4228	partitioning	
9-31	4228-4229	.	
9-32	4230-4233	The	
9-33	4234-4238	best	
9-34	4239-4245	method	
9-35	4246-4248	of	
9-36	4249-4261	partitioning	
9-37	4262-4269	differs	
9-38	4270-4275	based	
9-39	4276-4278	on	
9-40	4279-4283	your	
9-41	4284-4288	data	
9-42	4289-4296	volumes	
9-43	4296-4297	,	
9-44	4298-4307	candidate	
9-45	4308-4312	keys	
9-46	4312-4313	,	
9-47	4314-4318	null	
9-48	4319-4325	values	
9-49	4325-4326	,	
9-50	4327-4330	and	
9-51	4331-4342	cardinality	
9-52	4342-4343	.	
9-53	4344-4353	Important	
9-54	4354-4360	Single	
9-55	4361-4370	partition	
9-56	4371-4379	combines	
9-57	4380-4383	all	
9-58	4384-4387	the	
9-59	4388-4399	distributed	
9-60	4400-4404	data	
9-61	4405-4409	into	
9-62	4410-4411	a	
9-63	4412-4418	single	
9-64	4419-4428	partition	
9-65	4428-4429	.	
9-66	4430-4434	This	
9-67	4435-4437	is	
9-68	4438-4439	a	
9-69	4440-4444	very	
9-70	4445-4449	slow	
9-71	4450-4459	operation	
9-72	4460-4464	that	
9-73	4465-4469	also	
9-74	4470-4483	significantly	
9-75	4484-4491	affects	
9-76	4492-4495	all	
9-77	4496-4506	downstream	
9-78	4507-4521	transformation	
9-79	4522-4525	and	
9-80	4526-4532	writes	
9-81	4532-4533	.	
9-82	4534-4537	The	
9-83	4538-4543	Azure	
9-84	4544-4548	Data	
9-85	4549-4556	Factory	
9-86	4557-4563	highly	
9-87	4564-4574	recommends	
9-88	4575-4582	against	
9-89	4583-4588	using	
9-90	4589-4593	this	
9-91	4594-4600	option	
9-92	4601-4607	unless	
9-93	4608-4613	there	
9-94	4614-4616	is	
9-95	4617-4619	an	
9-96	4620-4628	explicit	
9-97	4629-4637	business	
9-98	4638-4644	reason	
9-99	4645-4647	to	
9-100	4648-4650	do	
9-101	4651-4653	so	
9-102	4653-4654	.	
9-103	4655-4658	The	
9-104	4659-4668	following	
9-105	4669-4681	partitioning	
9-106	4682-4689	options	
9-107	4690-4693	are	
9-108	4694-4703	available	
9-109	4704-4706	in	
9-110	4707-4712	every	
9-111	4713-4727	transformation	
9-112	4727-4728	:	

#Text=Round robin Round robin distributes data equally across partitions. Use round-robin when you don't have good key candidates to implement a solid, smart partitioning strategy. You can set the number of physical partitions. Hash
10-1	4729-4734	Round	
10-2	4735-4740	robin	
10-3	4741-4746	Round	
10-4	4747-4752	robin	
10-5	4753-4764	distributes	
10-6	4765-4769	data	
10-7	4770-4777	equally	
10-8	4778-4784	across	
10-9	4785-4795	partitions	
10-10	4795-4796	.	
10-11	4797-4800	Use	
10-12	4801-4812	round-robin	
10-13	4813-4817	when	
10-14	4818-4821	you	
10-15	4822-4827	don't	
10-16	4828-4832	have	
10-17	4833-4837	good	
10-18	4838-4841	key	
10-19	4842-4852	candidates	
10-20	4853-4855	to	
10-21	4856-4865	implement	
10-22	4866-4867	a	
10-23	4868-4873	solid	
10-24	4873-4874	,	
10-25	4875-4880	smart	
10-26	4881-4893	partitioning	
10-27	4894-4902	strategy	
10-28	4902-4903	.	
10-29	4904-4907	You	
10-30	4908-4911	can	
10-31	4912-4915	set	
10-32	4916-4919	the	
10-33	4920-4926	number	
10-34	4927-4929	of	
10-35	4930-4938	physical	
10-36	4939-4949	partitions	
10-37	4949-4950	.	
10-38	4951-4955	Hash	

#Text=Azure Data Factory produces a hash of columns to produce uniform partitions such that rows with similar values fall in the same partition. When you use the Hash option, test for possible partition skew. You can set the number of physical partitions. Dynamic range The dynamic range uses Spark dynamic ranges based on the columns or expressions that you provide. You can set the number of physical partitions. Fixed range
11-1	4956-4961	Azure	
11-2	4962-4966	Data	
11-3	4967-4974	Factory	
11-4	4975-4983	produces	
11-5	4984-4985	a	
11-6	4986-4990	hash	
11-7	4991-4993	of	
11-8	4994-5001	columns	
11-9	5002-5004	to	
11-10	5005-5012	produce	
11-11	5013-5020	uniform	
11-12	5021-5031	partitions	
11-13	5032-5036	such	
11-14	5037-5041	that	
11-15	5042-5046	rows	
11-16	5047-5051	with	
11-17	5052-5059	similar	
11-18	5060-5066	values	
11-19	5067-5071	fall	
11-20	5072-5074	in	
11-21	5075-5078	the	
11-22	5079-5083	same	
11-23	5084-5093	partition	
11-24	5093-5094	.	
11-25	5095-5099	When	
11-26	5100-5103	you	
11-27	5104-5107	use	
11-28	5108-5111	the	
11-29	5112-5116	Hash	
11-30	5117-5123	option	
11-31	5123-5124	,	
11-32	5125-5129	test	
11-33	5130-5133	for	
11-34	5134-5142	possible	
11-35	5143-5152	partition	
11-36	5153-5157	skew	
11-37	5157-5158	.	
11-38	5159-5162	You	
11-39	5163-5166	can	
11-40	5167-5170	set	
11-41	5171-5174	the	
11-42	5175-5181	number	
11-43	5182-5184	of	
11-44	5185-5193	physical	
11-45	5194-5204	partitions	
11-46	5204-5205	.	
11-47	5206-5213	Dynamic	
11-48	5214-5219	range	
11-49	5220-5223	The	
11-50	5224-5231	dynamic	
11-51	5232-5237	range	
11-52	5238-5242	uses	
11-53	5243-5248	Spark	
11-54	5249-5256	dynamic	
11-55	5257-5263	ranges	
11-56	5264-5269	based	
11-57	5270-5272	on	
11-58	5273-5276	the	
11-59	5277-5284	columns	
11-60	5285-5287	or	
11-61	5288-5299	expressions	
11-62	5300-5304	that	
11-63	5305-5308	you	
11-64	5309-5316	provide	
11-65	5316-5317	.	
11-66	5318-5321	You	
11-67	5322-5325	can	
11-68	5326-5329	set	
11-69	5330-5333	the	
11-70	5334-5340	number	
11-71	5341-5343	of	
11-72	5344-5352	physical	
11-73	5353-5363	partitions	
11-74	5363-5364	.	
11-75	5365-5370	Fixed	
11-76	5371-5376	range	

#Text=Build an expression that provides a fixed range for values within your partitioned data columns. To avoid partition skew, you should have a good understanding of your data before you use this option. The values you enter for the expression are used as part of a partition function. You can set the number of physical partitions. Key If you have a good understanding of the cardinality of your data, key partitioning might be a good strategy. Key partitioning creates partitions for each unique value in your column. You can't set the number of partitions because the number is based on unique values in the data.
12-1	5377-5382	Build	
12-2	5383-5385	an	
12-3	5386-5396	expression	
12-4	5397-5401	that	
12-5	5402-5410	provides	
12-6	5411-5412	a	
12-7	5413-5418	fixed	
12-8	5419-5424	range	
12-9	5425-5428	for	
12-10	5429-5435	values	
12-11	5436-5442	within	
12-12	5443-5447	your	
12-13	5448-5459	partitioned	
12-14	5460-5464	data	
12-15	5465-5472	columns	
12-16	5472-5473	.	
12-17	5474-5476	To	
12-18	5477-5482	avoid	
12-19	5483-5492	partition	
12-20	5493-5497	skew	
12-21	5497-5498	,	
12-22	5499-5502	you	
12-23	5503-5509	should	
12-24	5510-5514	have	
12-25	5515-5516	a	
12-26	5517-5521	good	
12-27	5522-5535	understanding	
12-28	5536-5538	of	
12-29	5539-5543	your	
12-30	5544-5548	data	
12-31	5549-5555	before	
12-32	5556-5559	you	
12-33	5560-5563	use	
12-34	5564-5568	this	
12-35	5569-5575	option	
12-36	5575-5576	.	
12-37	5577-5580	The	
12-38	5581-5587	values	
12-39	5588-5591	you	
12-40	5592-5597	enter	
12-41	5598-5601	for	
12-42	5602-5605	the	
12-43	5606-5616	expression	
12-44	5617-5620	are	
12-45	5621-5625	used	
12-46	5626-5628	as	
12-47	5629-5633	part	
12-48	5634-5636	of	
12-49	5637-5638	a	
12-50	5639-5648	partition	
12-51	5649-5657	function	
12-52	5657-5658	.	
12-53	5659-5662	You	
12-54	5663-5666	can	
12-55	5667-5670	set	
12-56	5671-5674	the	
12-57	5675-5681	number	
12-58	5682-5684	of	
12-59	5685-5693	physical	
12-60	5694-5704	partitions	
12-61	5704-5705	.	
12-62	5706-5709	Key	
12-63	5710-5712	If	
12-64	5713-5716	you	
12-65	5717-5721	have	
12-66	5722-5723	a	
12-67	5724-5728	good	
12-68	5729-5742	understanding	
12-69	5743-5745	of	
12-70	5746-5749	the	
12-71	5750-5761	cardinality	
12-72	5762-5764	of	
12-73	5765-5769	your	
12-74	5770-5774	data	
12-75	5774-5775	,	
12-76	5776-5779	key	
12-77	5780-5792	partitioning	
12-78	5793-5798	might	
12-79	5799-5801	be	
12-80	5802-5803	a	
12-81	5804-5808	good	
12-82	5809-5817	strategy	
12-83	5817-5818	.	
12-84	5819-5822	Key	
12-85	5823-5835	partitioning	
12-86	5836-5843	creates	
12-87	5844-5854	partitions	
12-88	5855-5858	for	
12-89	5859-5863	each	
12-90	5864-5870	unique	
12-91	5871-5876	value	
12-92	5877-5879	in	
12-93	5880-5884	your	
12-94	5885-5891	column	
12-95	5891-5892	.	
12-96	5893-5896	You	
12-97	5897-5902	can't	
12-98	5903-5906	set	
12-99	5907-5910	the	
12-100	5911-5917	number	
12-101	5918-5920	of	
12-102	5921-5931	partitions	
12-103	5932-5939	because	
12-104	5940-5943	the	
12-105	5944-5950	number	
12-106	5951-5953	is	
12-107	5954-5959	based	
12-108	5960-5962	on	
12-109	5963-5969	unique	
12-110	5970-5976	values	
12-111	5977-5979	in	
12-112	5980-5983	the	
12-113	5984-5988	data	
12-114	5988-5989	.	

#Text=Tip Manually setting the partitioning scheme reshuffles the data and can offset the benefits of the Spark optimizer. A best practice is to not manually set the partitioning unless you need to. Logging level
13-1	5990-5993	Tip	
13-2	5994-6002	Manually	
13-3	6003-6010	setting	
13-4	6011-6014	the	
13-5	6015-6027	partitioning	
13-6	6028-6034	scheme	
13-7	6035-6045	reshuffles	
13-8	6046-6049	the	
13-9	6050-6054	data	
13-10	6055-6058	and	
13-11	6059-6062	can	
13-12	6063-6069	offset	
13-13	6070-6073	the	
13-14	6074-6082	benefits	
13-15	6083-6085	of	
13-16	6086-6089	the	
13-17	6090-6095	Spark	
13-18	6096-6105	optimizer	
13-19	6105-6106	.	
13-20	6107-6108	A	
13-21	6109-6113	best	
13-22	6114-6122	practice	
13-23	6123-6125	is	
13-24	6126-6128	to	
13-25	6129-6132	not	
13-26	6133-6141	manually	
13-27	6142-6145	set	
13-28	6146-6149	the	
13-29	6150-6162	partitioning	
13-30	6163-6169	unless	
13-31	6170-6173	you	
13-32	6174-6178	need	
13-33	6179-6181	to	
13-34	6181-6182	.	
13-35	6183-6190	Logging	
13-36	6191-6196	level	

#Text=If you do not require every pipeline execution of your data flow activities to fully log all verbose telemetry logs, you can optionally set your logging level to "Basic" or "None". When executing your data flows in "Verbose" mode (default), you are requesting ADF to fully log activity at each individual partition level during your data transformation. This can be an expensive operation, so only enabling verbose when troubleshooting can improve your overall data flow and pipeline performance. "Basic" mode will only log transformation durations while "None" will only provide a summary of durations. Optimizing the Azure Integration Runtime Data flows run on Spark clusters that are spun up at run-time. The configuration for the cluster used is defined in the integration runtime (IR) of the activity. There are three performance considerations to make when defining your integration runtime: cluster type, cluster size, and time to live.
14-1	6197-6199	If	
14-2	6200-6203	you	
14-3	6204-6206	do	
14-4	6207-6210	not	
14-5	6211-6218	require	
14-6	6219-6224	every	
14-7	6225-6233	pipeline	
14-8	6234-6243	execution	
14-9	6244-6246	of	
14-10	6247-6251	your	
14-11	6252-6256	data	
14-12	6257-6261	flow	
14-13	6262-6272	activities	
14-14	6273-6275	to	
14-15	6276-6281	fully	
14-16	6282-6285	log	
14-17	6286-6289	all	
14-18	6290-6297	verbose	
14-19	6298-6307	telemetry	
14-20	6308-6312	logs	
14-21	6312-6313	,	
14-22	6314-6317	you	
14-23	6318-6321	can	
14-24	6322-6332	optionally	
14-25	6333-6336	set	
14-26	6337-6341	your	
14-27	6342-6349	logging	
14-28	6350-6355	level	
14-29	6356-6358	to	
14-30	6359-6360	"	
14-31	6360-6365	Basic	
14-32	6365-6366	"	
14-33	6367-6369	or	
14-34	6370-6371	"	
14-35	6371-6375	None	
14-36	6375-6376	"	
14-37	6376-6377	.	
14-38	6378-6382	When	
14-39	6383-6392	executing	
14-40	6393-6397	your	
14-41	6398-6402	data	
14-42	6403-6408	flows	
14-43	6409-6411	in	
14-44	6412-6413	"	
14-45	6413-6420	Verbose	
14-46	6420-6421	"	
14-47	6422-6426	mode	
14-48	6427-6428	(	
14-49	6428-6435	default	
14-50	6435-6436	)	
14-51	6436-6437	,	
14-52	6438-6441	you	
14-53	6442-6445	are	
14-54	6446-6456	requesting	
14-55	6457-6460	ADF	
14-56	6461-6463	to	
14-57	6464-6469	fully	
14-58	6470-6473	log	
14-59	6474-6482	activity	
14-60	6483-6485	at	
14-61	6486-6490	each	
14-62	6491-6501	individual	
14-63	6502-6511	partition	
14-64	6512-6517	level	
14-65	6518-6524	during	
14-66	6525-6529	your	
14-67	6530-6534	data	
14-68	6535-6549	transformation	
14-69	6549-6550	.	
14-70	6551-6555	This	
14-71	6556-6559	can	
14-72	6560-6562	be	
14-73	6563-6565	an	
14-74	6566-6575	expensive	
14-75	6576-6585	operation	
14-76	6585-6586	,	
14-77	6587-6589	so	
14-78	6590-6594	only	
14-79	6595-6603	enabling	
14-80	6604-6611	verbose	
14-81	6612-6616	when	
14-82	6617-6632	troubleshooting	
14-83	6633-6636	can	
14-84	6637-6644	improve	
14-85	6645-6649	your	
14-86	6650-6657	overall	
14-87	6658-6662	data	
14-88	6663-6667	flow	
14-89	6668-6671	and	
14-90	6672-6680	pipeline	
14-91	6681-6692	performance	
14-92	6692-6693	.	
14-93	6694-6695	"	
14-94	6695-6700	Basic	
14-95	6700-6701	"	
14-96	6702-6706	mode	
14-97	6707-6711	will	
14-98	6712-6716	only	
14-99	6717-6720	log	
14-100	6721-6735	transformation	
14-101	6736-6745	durations	
14-102	6746-6751	while	
14-103	6752-6753	"	
14-104	6753-6757	None	
14-105	6757-6758	"	
14-106	6759-6763	will	
14-107	6764-6768	only	
14-108	6769-6776	provide	
14-109	6777-6778	a	
14-110	6779-6786	summary	
14-111	6787-6789	of	
14-112	6790-6799	durations	
14-113	6799-6800	.	
14-114	6801-6811	Optimizing	
14-115	6812-6815	the	
14-116	6816-6821	Azure	
14-117	6822-6833	Integration	
14-118	6834-6841	Runtime	
14-119	6842-6846	Data	
14-120	6847-6852	flows	
14-121	6853-6856	run	
14-122	6857-6859	on	
14-123	6860-6865	Spark	
14-124	6866-6874	clusters	
14-125	6875-6879	that	
14-126	6880-6883	are	
14-127	6884-6888	spun	
14-128	6889-6891	up	
14-129	6892-6894	at	
14-130	6895-6903	run-time	
14-131	6903-6904	.	
14-132	6905-6908	The	
14-133	6909-6922	configuration	
14-134	6923-6926	for	
14-135	6927-6930	the	
14-136	6931-6938	cluster	
14-137	6939-6943	used	
14-138	6944-6946	is	
14-139	6947-6954	defined	
14-140	6955-6957	in	
14-141	6958-6961	the	
14-142	6962-6973	integration	
14-143	6974-6981	runtime	
14-144	6982-6983	(	
14-145	6983-6985	IR	
14-146	6985-6986	)	
14-147	6987-6989	of	
14-148	6990-6993	the	
14-149	6994-7002	activity	
14-150	7002-7003	.	
14-151	7004-7009	There	
14-152	7010-7013	are	
14-153	7014-7019	three	
14-154	7020-7031	performance	
14-155	7032-7046	considerations	
14-156	7047-7049	to	
14-157	7050-7054	make	
14-158	7055-7059	when	
14-159	7060-7068	defining	
14-160	7069-7073	your	
14-161	7074-7085	integration	
14-162	7086-7093	runtime	
14-163	7093-7094	:	
14-164	7095-7102	cluster	
14-165	7103-7107	type	
14-166	7107-7108	,	
14-167	7109-7116	cluster	
14-168	7117-7121	size	
14-169	7121-7122	,	
14-170	7123-7126	and	
14-171	7127-7131	time	
14-172	7132-7134	to	
14-173	7135-7139	live	
14-174	7139-7140	.	

#Text=For more information how to create an Integration Runtime, see Integration Runtime in Azure Data Factory. Cluster type There are three available options for the type of Spark cluster spun up: general purpose, memory optimized, and compute optimized. General purpose clusters are the default selection and will be ideal for most data flow workloads. These tend to be the best balance of performance and cost.
15-1	7141-7144	For	
15-2	7145-7149	more	
15-3	7150-7161	information	
15-4	7162-7165	how	
15-5	7166-7168	to	
15-6	7169-7175	create	
15-7	7176-7178	an	
15-8	7179-7190	Integration	
15-9	7191-7198	Runtime	
15-10	7198-7199	,	
15-11	7200-7203	see	
15-12	7204-7215	Integration	
15-13	7216-7223	Runtime	
15-14	7224-7226	in	
15-15	7227-7232	Azure	
15-16	7233-7237	Data	
15-17	7238-7245	Factory	
15-18	7245-7246	.	
15-19	7247-7254	Cluster	
15-20	7255-7259	type	
15-21	7260-7265	There	
15-22	7266-7269	are	
15-23	7270-7275	three	
15-24	7276-7285	available	
15-25	7286-7293	options	
15-26	7294-7297	for	
15-27	7298-7301	the	
15-28	7302-7306	type	
15-29	7307-7309	of	
15-30	7310-7315	Spark	
15-31	7316-7323	cluster	
15-32	7324-7328	spun	
15-33	7329-7331	up	
15-34	7331-7332	:	
15-35	7333-7340	general	
15-36	7341-7348	purpose	
15-37	7348-7349	,	
15-38	7350-7356	memory	
15-39	7357-7366	optimized	
15-40	7366-7367	,	
15-41	7368-7371	and	
15-42	7372-7379	compute	
15-43	7380-7389	optimized	
15-44	7389-7390	.	
15-45	7391-7398	General	
15-46	7399-7406	purpose	
15-47	7407-7415	clusters	
15-48	7416-7419	are	
15-49	7420-7423	the	
15-50	7424-7431	default	
15-51	7432-7441	selection	
15-52	7442-7445	and	
15-53	7446-7450	will	
15-54	7451-7453	be	
15-55	7454-7459	ideal	
15-56	7460-7463	for	
15-57	7464-7468	most	
15-58	7469-7473	data	
15-59	7474-7478	flow	
15-60	7479-7488	workloads	
15-61	7488-7489	.	
15-62	7490-7495	These	
15-63	7496-7500	tend	
15-64	7501-7503	to	
15-65	7504-7506	be	
15-66	7507-7510	the	
15-67	7511-7515	best	
15-68	7516-7523	balance	
15-69	7524-7526	of	
15-70	7527-7538	performance	
15-71	7539-7542	and	
15-72	7543-7547	cost	
15-73	7547-7548	.	

#Text=If your data flow has many joins and lookups, you may want to use a memory optimized cluster. Memory optimized clusters can store more data in memory and will minimize any out-of-memory errors you may get. Memory optimized have the highest price-point per core, but also tend to result in more successful pipelines. If you experience any out of memory errors when executing data flows, switch to a memory optimized Azure IR configuration. Compute optimized aren't ideal for ETL workflows and aren't recommended by the Azure Data Factory team for most production workloads. For simpler, non-memory intensive data transformations such as filtering data or adding derived columns, compute-optimized clusters can be used at a cheaper price per core.
16-1	7549-7551	If	
16-2	7552-7556	your	
16-3	7557-7561	data	
16-4	7562-7566	flow	
16-5	7567-7570	has	
16-6	7571-7575	many	
16-7	7576-7581	joins	
16-8	7582-7585	and	
16-9	7586-7593	lookups	
16-10	7593-7594	,	
16-11	7595-7598	you	
16-12	7599-7602	may	
16-13	7603-7607	want	
16-14	7608-7610	to	
16-15	7611-7614	use	
16-16	7615-7616	a	
16-17	7617-7623	memory	
16-18	7624-7633	optimized	
16-19	7634-7641	cluster	
16-20	7641-7642	.	
16-21	7643-7649	Memory	
16-22	7650-7659	optimized	
16-23	7660-7668	clusters	
16-24	7669-7672	can	
16-25	7673-7678	store	
16-26	7679-7683	more	
16-27	7684-7688	data	
16-28	7689-7691	in	
16-29	7692-7698	memory	
16-30	7699-7702	and	
16-31	7703-7707	will	
16-32	7708-7716	minimize	
16-33	7717-7720	any	
16-34	7721-7734	out-of-memory	
16-35	7735-7741	errors	
16-36	7742-7745	you	
16-37	7746-7749	may	
16-38	7750-7753	get	
16-39	7753-7754	.	
16-40	7755-7761	Memory	
16-41	7762-7771	optimized	
16-42	7772-7776	have	
16-43	7777-7780	the	
16-44	7781-7788	highest	
16-45	7789-7800	price-point	
16-46	7801-7804	per	
16-47	7805-7809	core	
16-48	7809-7810	,	
16-49	7811-7814	but	
16-50	7815-7819	also	
16-51	7820-7824	tend	
16-52	7825-7827	to	
16-53	7828-7834	result	
16-54	7835-7837	in	
16-55	7838-7842	more	
16-56	7843-7853	successful	
16-57	7854-7863	pipelines	
16-58	7863-7864	.	
16-59	7865-7867	If	
16-60	7868-7871	you	
16-61	7872-7882	experience	
16-62	7883-7886	any	
16-63	7887-7890	out	
16-64	7891-7893	of	
16-65	7894-7900	memory	
16-66	7901-7907	errors	
16-67	7908-7912	when	
16-68	7913-7922	executing	
16-69	7923-7927	data	
16-70	7928-7933	flows	
16-71	7933-7934	,	
16-72	7935-7941	switch	
16-73	7942-7944	to	
16-74	7945-7946	a	
16-75	7947-7953	memory	
16-76	7954-7963	optimized	
16-77	7964-7969	Azure	
16-78	7970-7972	IR	
16-79	7973-7986	configuration	
16-80	7986-7987	.	
16-81	7988-7995	Compute	
16-82	7996-8005	optimized	
16-83	8006-8012	aren't	
16-84	8013-8018	ideal	
16-85	8019-8022	for	
16-86	8023-8026	ETL	
16-87	8027-8036	workflows	
16-88	8037-8040	and	
16-89	8041-8047	aren't	
16-90	8048-8059	recommended	
16-91	8060-8062	by	
16-92	8063-8066	the	
16-93	8067-8072	Azure	
16-94	8073-8077	Data	
16-95	8078-8085	Factory	
16-96	8086-8090	team	
16-97	8091-8094	for	
16-98	8095-8099	most	
16-99	8100-8110	production	
16-100	8111-8120	workloads	
16-101	8120-8121	.	
16-102	8122-8125	For	
16-103	8126-8133	simpler	
16-104	8133-8134	,	
16-105	8135-8145	non-memory	
16-106	8146-8155	intensive	
16-107	8156-8160	data	
16-108	8161-8176	transformations	
16-109	8177-8181	such	
16-110	8182-8184	as	
16-111	8185-8194	filtering	
16-112	8195-8199	data	
16-113	8200-8202	or	
16-114	8203-8209	adding	
16-115	8210-8217	derived	
16-116	8218-8225	columns	
16-117	8225-8226	,	
16-118	8227-8244	compute-optimized	
16-119	8245-8253	clusters	
16-120	8254-8257	can	
16-121	8258-8260	be	
16-122	8261-8265	used	
16-123	8266-8268	at	
16-124	8269-8270	a	
16-125	8271-8278	cheaper	
16-126	8279-8284	price	
16-127	8285-8288	per	
16-128	8289-8293	core	
16-129	8293-8294	.	

#Text=Cluster size Data flows distribute the data processing over different nodes in a Spark cluster to perform operations in parallel. A Spark cluster with more cores increases the number of nodes in the compute environment. More nodes increase the processing power of the data flow. Increasing the size of the cluster is often an easy way to reduce the processing time.
17-1	8295-8302	Cluster	
17-2	8303-8307	size	
17-3	8308-8312	Data	
17-4	8313-8318	flows	
17-5	8319-8329	distribute	
17-6	8330-8333	the	
17-7	8334-8338	data	
17-8	8339-8349	processing	
17-9	8350-8354	over	
17-10	8355-8364	different	
17-11	8365-8370	nodes	
17-12	8371-8373	in	
17-13	8374-8375	a	
17-14	8376-8381	Spark	
17-15	8382-8389	cluster	
17-16	8390-8392	to	
17-17	8393-8400	perform	
17-18	8401-8411	operations	
17-19	8412-8414	in	
17-20	8415-8423	parallel	
17-21	8423-8424	.	
17-22	8425-8426	A	
17-23	8427-8432	Spark	
17-24	8433-8440	cluster	
17-25	8441-8445	with	
17-26	8446-8450	more	
17-27	8451-8456	cores	
17-28	8457-8466	increases	
17-29	8467-8470	the	
17-30	8471-8477	number	
17-31	8478-8480	of	
17-32	8481-8486	nodes	
17-33	8487-8489	in	
17-34	8490-8493	the	
17-35	8494-8501	compute	
17-36	8502-8513	environment	
17-37	8513-8514	.	
17-38	8515-8519	More	
17-39	8520-8525	nodes	
17-40	8526-8534	increase	
17-41	8535-8538	the	
17-42	8539-8549	processing	
17-43	8550-8555	power	
17-44	8556-8558	of	
17-45	8559-8562	the	
17-46	8563-8567	data	
17-47	8568-8572	flow	
17-48	8572-8573	.	
17-49	8574-8584	Increasing	
17-50	8585-8588	the	
17-51	8589-8593	size	
17-52	8594-8596	of	
17-53	8597-8600	the	
17-54	8601-8608	cluster	
17-55	8609-8611	is	
17-56	8612-8617	often	
17-57	8618-8620	an	
17-58	8621-8625	easy	
17-59	8626-8629	way	
17-60	8630-8632	to	
17-61	8633-8639	reduce	
17-62	8640-8643	the	
17-63	8644-8654	processing	
17-64	8655-8659	time	
17-65	8659-8660	.	

#Text=The default cluster size is four driver nodes and four worker nodes. As you process more data, larger clusters are recommended. Below are the possible sizing options: Worker cores Driver cores Total cores Notes Not available for compute optimized 128 144 256 272
18-1	8661-8664	The	
18-2	8665-8672	default	
18-3	8673-8680	cluster	
18-4	8681-8685	size	
18-5	8686-8688	is	
18-6	8689-8693	four	
18-7	8694-8700	driver	
18-8	8701-8706	nodes	
18-9	8707-8710	and	
18-10	8711-8715	four	
18-11	8716-8722	worker	
18-12	8723-8728	nodes	
18-13	8728-8729	.	
18-14	8730-8732	As	
18-15	8733-8736	you	
18-16	8737-8744	process	
18-17	8745-8749	more	
18-18	8750-8754	data	
18-19	8754-8755	,	
18-20	8756-8762	larger	
18-21	8763-8771	clusters	
18-22	8772-8775	are	
18-23	8776-8787	recommended	
18-24	8787-8788	.	
18-25	8789-8794	Below	
18-26	8795-8798	are	
18-27	8799-8802	the	
18-28	8803-8811	possible	
18-29	8812-8818	sizing	
18-30	8819-8826	options	
18-31	8826-8827	:	
18-32	8828-8834	Worker	
18-33	8835-8840	cores	
18-34	8841-8847	Driver	
18-35	8848-8853	cores	
18-36	8854-8859	Total	
18-37	8860-8865	cores	
18-38	8866-8871	Notes	
18-39	8872-8875	Not	
18-40	8876-8885	available	
18-41	8886-8889	for	
18-42	8890-8897	compute	
18-43	8898-8907	optimized	
18-44	8908-8911	128	
18-45	8912-8915	144	
18-46	8916-8919	256	
18-47	8920-8923	272	

#Text=Data flows are priced at vcore-hrs meaning that both cluster size and execution-time factor into this. As you scale up, your cluster cost per minute will increase, but your overall time will decrease. Tip There is a ceiling on how much the size of a cluster affects the performance of a data flow. Depending on the size of your data, there is a point where increasing the size of a cluster will stop improving performance. For example, If you have more nodes than partitions of data, adding additional nodes won't help.
19-1	8924-8928	Data	
19-2	8929-8934	flows	
19-3	8935-8938	are	
19-4	8939-8945	priced	
19-5	8946-8948	at	
19-6	8949-8958	vcore-hrs	
19-7	8959-8966	meaning	
19-8	8967-8971	that	
19-9	8972-8976	both	
19-10	8977-8984	cluster	
19-11	8985-8989	size	
19-12	8990-8993	and	
19-13	8994-9008	execution-time	
19-14	9009-9015	factor	
19-15	9016-9020	into	
19-16	9021-9025	this	
19-17	9025-9026	.	
19-18	9027-9029	As	
19-19	9030-9033	you	
19-20	9034-9039	scale	
19-21	9040-9042	up	
19-22	9042-9043	,	
19-23	9044-9048	your	
19-24	9049-9056	cluster	
19-25	9057-9061	cost	
19-26	9062-9065	per	
19-27	9066-9072	minute	
19-28	9073-9077	will	
19-29	9078-9086	increase	
19-30	9086-9087	,	
19-31	9088-9091	but	
19-32	9092-9096	your	
19-33	9097-9104	overall	
19-34	9105-9109	time	
19-35	9110-9114	will	
19-36	9115-9123	decrease	
19-37	9123-9124	.	
19-38	9125-9128	Tip	
19-39	9129-9134	There	
19-40	9135-9137	is	
19-41	9138-9139	a	
19-42	9140-9147	ceiling	
19-43	9148-9150	on	
19-44	9151-9154	how	
19-45	9155-9159	much	
19-46	9160-9163	the	
19-47	9164-9168	size	
19-48	9169-9171	of	
19-49	9172-9173	a	
19-50	9174-9181	cluster	
19-51	9182-9189	affects	
19-52	9190-9193	the	
19-53	9194-9205	performance	
19-54	9206-9208	of	
19-55	9209-9210	a	
19-56	9211-9215	data	
19-57	9216-9220	flow	
19-58	9220-9221	.	
19-59	9222-9231	Depending	
19-60	9232-9234	on	
19-61	9235-9238	the	
19-62	9239-9243	size	
19-63	9244-9246	of	
19-64	9247-9251	your	
19-65	9252-9256	data	
19-66	9256-9257	,	
19-67	9258-9263	there	
19-68	9264-9266	is	
19-69	9267-9268	a	
19-70	9269-9274	point	
19-71	9275-9280	where	
19-72	9281-9291	increasing	
19-73	9292-9295	the	
19-74	9296-9300	size	
19-75	9301-9303	of	
19-76	9304-9305	a	
19-77	9306-9313	cluster	
19-78	9314-9318	will	
19-79	9319-9323	stop	
19-80	9324-9333	improving	
19-81	9334-9345	performance	
19-82	9345-9346	.	
19-83	9347-9350	For	
19-84	9351-9358	example	
19-85	9358-9359	,	
19-86	9360-9362	If	
19-87	9363-9366	you	
19-88	9367-9371	have	
19-89	9372-9376	more	
19-90	9377-9382	nodes	
19-91	9383-9387	than	
19-92	9388-9398	partitions	
19-93	9399-9401	of	
19-94	9402-9406	data	
19-95	9406-9407	,	
19-96	9408-9414	adding	
19-97	9415-9425	additional	
19-98	9426-9431	nodes	
19-99	9432-9437	won't	
19-100	9438-9442	help	
19-101	9442-9443	.	

#Text=A best practice is to start small and scale up to meet your performance needs. Time to live
20-1	9444-9445	A	
20-2	9446-9450	best	
20-3	9451-9459	practice	
20-4	9460-9462	is	
20-5	9463-9465	to	
20-6	9466-9471	start	
20-7	9472-9477	small	
20-8	9478-9481	and	
20-9	9482-9487	scale	
20-10	9488-9490	up	
20-11	9491-9493	to	
20-12	9494-9498	meet	
20-13	9499-9503	your	
20-14	9504-9515	performance	
20-15	9516-9521	needs	
20-16	9521-9522	.	
20-17	9523-9527	Time	
20-18	9528-9530	to	
20-19	9531-9535	live	

#Text=By default, every data flow activity spins up a new cluster based upon the IR configuration. Cluster start-up time takes a few minutes and data processing can't start until it is complete. If your pipelines contain multiple sequential data flows, you can enable a time to live (TTL) value. Specifying a time to live value keeps a cluster alive for a certain period of time after its execution completes. If a new job starts using the IR during the TTL time, it will reuse the existing cluster and start up time will greatly reduced. After the second job completes, the cluster will again stay alive for the TTL time. Only one job can run on a single cluster at a time. If there is an available cluster, but two data flows start, only one will use the live cluster. The second job will spin up its own isolated cluster. If most of your data flows execute in parallel, it is not recommended that you enable TTL.
21-1	9536-9538	By	
21-2	9539-9546	default	
21-3	9546-9547	,	
21-4	9548-9553	every	
21-5	9554-9558	data	
21-6	9559-9563	flow	
21-7	9564-9572	activity	
21-8	9573-9578	spins	
21-9	9579-9581	up	
21-10	9582-9583	a	
21-11	9584-9587	new	
21-12	9588-9595	cluster	
21-13	9596-9601	based	
21-14	9602-9606	upon	
21-15	9607-9610	the	
21-16	9611-9613	IR	
21-17	9614-9627	configuration	
21-18	9627-9628	.	
21-19	9629-9636	Cluster	
21-20	9637-9645	start-up	
21-21	9646-9650	time	
21-22	9651-9656	takes	
21-23	9657-9658	a	
21-24	9659-9662	few	
21-25	9663-9670	minutes	
21-26	9671-9674	and	
21-27	9675-9679	data	
21-28	9680-9690	processing	
21-29	9691-9696	can't	
21-30	9697-9702	start	
21-31	9703-9708	until	
21-32	9709-9711	it	
21-33	9712-9714	is	
21-34	9715-9723	complete	
21-35	9723-9724	.	
21-36	9725-9727	If	
21-37	9728-9732	your	
21-38	9733-9742	pipelines	
21-39	9743-9750	contain	
21-40	9751-9759	multiple	
21-41	9760-9770	sequential	
21-42	9771-9775	data	
21-43	9776-9781	flows	
21-44	9781-9782	,	
21-45	9783-9786	you	
21-46	9787-9790	can	
21-47	9791-9797	enable	
21-48	9798-9799	a	
21-49	9800-9804	time	
21-50	9805-9807	to	
21-51	9808-9812	live	
21-52	9813-9814	(	
21-53	9814-9817	TTL	
21-54	9817-9818	)	
21-55	9819-9824	value	
21-56	9824-9825	.	
21-57	9826-9836	Specifying	
21-58	9837-9838	a	
21-59	9839-9843	time	
21-60	9844-9846	to	
21-61	9847-9851	live	
21-62	9852-9857	value	
21-63	9858-9863	keeps	
21-64	9864-9865	a	
21-65	9866-9873	cluster	
21-66	9874-9879	alive	
21-67	9880-9883	for	
21-68	9884-9885	a	
21-69	9886-9893	certain	
21-70	9894-9900	period	
21-71	9901-9903	of	
21-72	9904-9908	time	
21-73	9909-9914	after	
21-74	9915-9918	its	
21-75	9919-9928	execution	
21-76	9929-9938	completes	
21-77	9938-9939	.	
21-78	9940-9942	If	
21-79	9943-9944	a	
21-80	9945-9948	new	
21-81	9949-9952	job	
21-82	9953-9959	starts	
21-83	9960-9965	using	
21-84	9966-9969	the	
21-85	9970-9972	IR	
21-86	9973-9979	during	
21-87	9980-9983	the	
21-88	9984-9987	TTL	
21-89	9988-9992	time	
21-90	9992-9993	,	
21-91	9994-9996	it	
21-92	9997-10001	will	
21-93	10002-10007	reuse	
21-94	10008-10011	the	
21-95	10012-10020	existing	
21-96	10021-10028	cluster	
21-97	10029-10032	and	
21-98	10033-10038	start	
21-99	10039-10041	up	
21-100	10042-10046	time	
21-101	10047-10051	will	
21-102	10052-10059	greatly	
21-103	10060-10067	reduced	
21-104	10067-10068	.	
21-105	10069-10074	After	
21-106	10075-10078	the	
21-107	10079-10085	second	
21-108	10086-10089	job	
21-109	10090-10099	completes	
21-110	10099-10100	,	
21-111	10101-10104	the	
21-112	10105-10112	cluster	
21-113	10113-10117	will	
21-114	10118-10123	again	
21-115	10124-10128	stay	
21-116	10129-10134	alive	
21-117	10135-10138	for	
21-118	10139-10142	the	
21-119	10143-10146	TTL	
21-120	10147-10151	time	
21-121	10151-10152	.	
21-122	10153-10157	Only	
21-123	10158-10161	one	
21-124	10162-10165	job	
21-125	10166-10169	can	
21-126	10170-10173	run	
21-127	10174-10176	on	
21-128	10177-10178	a	
21-129	10179-10185	single	
21-130	10186-10193	cluster	
21-131	10194-10196	at	
21-132	10197-10198	a	
21-133	10199-10203	time	
21-134	10203-10204	.	
21-135	10205-10207	If	
21-136	10208-10213	there	
21-137	10214-10216	is	
21-138	10217-10219	an	
21-139	10220-10229	available	
21-140	10230-10237	cluster	
21-141	10237-10238	,	
21-142	10239-10242	but	
21-143	10243-10246	two	
21-144	10247-10251	data	
21-145	10252-10257	flows	
21-146	10258-10263	start	
21-147	10263-10264	,	
21-148	10265-10269	only	
21-149	10270-10273	one	
21-150	10274-10278	will	
21-151	10279-10282	use	
21-152	10283-10286	the	
21-153	10287-10291	live	
21-154	10292-10299	cluster	
21-155	10299-10300	.	
21-156	10301-10304	The	
21-157	10305-10311	second	
21-158	10312-10315	job	
21-159	10316-10320	will	
21-160	10321-10325	spin	
21-161	10326-10328	up	
21-162	10329-10332	its	
21-163	10333-10336	own	
21-164	10337-10345	isolated	
21-165	10346-10353	cluster	
21-166	10353-10354	.	
21-167	10355-10357	If	
21-168	10358-10362	most	
21-169	10363-10365	of	
21-170	10366-10370	your	
21-171	10371-10375	data	
21-172	10376-10381	flows	
21-173	10382-10389	execute	
21-174	10390-10392	in	
21-175	10393-10401	parallel	
21-176	10401-10402	,	
21-177	10403-10405	it	
21-178	10406-10408	is	
21-179	10409-10412	not	
21-180	10413-10424	recommended	
21-181	10425-10429	that	
21-182	10430-10433	you	
21-183	10434-10440	enable	
21-184	10441-10444	TTL	
21-185	10444-10445	.	

#Text=Note Time to live is not available when using the auto-resolve integration runtime Optimizing sources For every source except Azure SQL Database, it is recommended that you keep Use current partitioning as the selected value. When reading from all other source systems, data flows automatically partitions data evenly based upon the size of the data. A new partition is created for about every 128 MB of data. As your data size increases, the number of partitions increase.
22-1	10446-10450	Note	
22-2	10451-10455	Time	
22-3	10456-10458	to	
22-4	10459-10463	live	
22-5	10464-10466	is	
22-6	10467-10470	not	
22-7	10471-10480	available	
22-8	10481-10485	when	
22-9	10486-10491	using	
22-10	10492-10495	the	
22-11	10496-10508	auto-resolve	
22-12	10509-10520	integration	
22-13	10521-10528	runtime	
22-14	10529-10539	Optimizing	
22-15	10540-10547	sources	
22-16	10548-10551	For	
22-17	10552-10557	every	
22-18	10558-10564	source	
22-19	10565-10571	except	
22-20	10572-10577	Azure	
22-21	10578-10581	SQL	
22-22	10582-10590	Database	
22-23	10590-10591	,	
22-24	10592-10594	it	
22-25	10595-10597	is	
22-26	10598-10609	recommended	
22-27	10610-10614	that	
22-28	10615-10618	you	
22-29	10619-10623	keep	
22-30	10624-10627	Use	
22-31	10628-10635	current	
22-32	10636-10648	partitioning	
22-33	10649-10651	as	
22-34	10652-10655	the	
22-35	10656-10664	selected	
22-36	10665-10670	value	
22-37	10670-10671	.	
22-38	10672-10676	When	
22-39	10677-10684	reading	
22-40	10685-10689	from	
22-41	10690-10693	all	
22-42	10694-10699	other	
22-43	10700-10706	source	
22-44	10707-10714	systems	
22-45	10714-10715	,	
22-46	10716-10720	data	
22-47	10721-10726	flows	
22-48	10727-10740	automatically	
22-49	10741-10751	partitions	
22-50	10752-10756	data	
22-51	10757-10763	evenly	
22-52	10764-10769	based	
22-53	10770-10774	upon	
22-54	10775-10778	the	
22-55	10779-10783	size	
22-56	10784-10786	of	
22-57	10787-10790	the	
22-58	10791-10795	data	
22-59	10795-10796	.	
22-60	10797-10798	A	
22-61	10799-10802	new	
22-62	10803-10812	partition	
22-63	10813-10815	is	
22-64	10816-10823	created	
22-65	10824-10827	for	
22-66	10828-10833	about	
22-67	10834-10839	every	
22-68	10840-10843	128	
22-69	10844-10846	MB	
22-70	10847-10849	of	
22-71	10850-10854	data	
22-72	10854-10855	.	
22-73	10856-10858	As	
22-74	10859-10863	your	
22-75	10864-10868	data	
22-76	10869-10873	size	
22-77	10874-10883	increases	
22-78	10883-10884	,	
22-79	10885-10888	the	
22-80	10889-10895	number	
22-81	10896-10898	of	
22-82	10899-10909	partitions	
22-83	10910-10918	increase	
22-84	10918-10919	.	

#Text=Any custom partitioning happens after Spark reads in the data and will negatively impact your data flow performance. As the data is evenly partitioned on read, this is not recommended. Note Read speeds can be limited by the throughput of your source system. Azure SQL Database sources
23-1	10920-10923	Any	
23-2	10924-10930	custom	
23-3	10931-10943	partitioning	
23-4	10944-10951	happens	
23-5	10952-10957	after	
23-6	10958-10963	Spark	
23-7	10964-10969	reads	
23-8	10970-10972	in	
23-9	10973-10976	the	
23-10	10977-10981	data	
23-11	10982-10985	and	
23-12	10986-10990	will	
23-13	10991-11001	negatively	
23-14	11002-11008	impact	
23-15	11009-11013	your	
23-16	11014-11018	data	
23-17	11019-11023	flow	
23-18	11024-11035	performance	
23-19	11035-11036	.	
23-20	11037-11039	As	
23-21	11040-11043	the	
23-22	11044-11048	data	
23-23	11049-11051	is	
23-24	11052-11058	evenly	
23-25	11059-11070	partitioned	
23-26	11071-11073	on	
23-27	11074-11078	read	
23-28	11078-11079	,	
23-29	11080-11084	this	
23-30	11085-11087	is	
23-31	11088-11091	not	
23-32	11092-11103	recommended	
23-33	11103-11104	.	
23-34	11105-11109	Note	
23-35	11110-11114	Read	
23-36	11115-11121	speeds	
23-37	11122-11125	can	
23-38	11126-11128	be	
23-39	11129-11136	limited	
23-40	11137-11139	by	
23-41	11140-11143	the	
23-42	11144-11154	throughput	
23-43	11155-11157	of	
23-44	11158-11162	your	
23-45	11163-11169	source	
23-46	11170-11176	system	
23-47	11176-11177	.	
23-48	11178-11183	Azure	
23-49	11184-11187	SQL	
23-50	11188-11196	Database	
23-51	11197-11204	sources	

#Text=Azure SQL Database has a unique partitioning option called 'Source' partitioning. Enabling source partitioning can improve your read times from Azure SQL DB by enabling parallel connections on the source system. Specify the number of partitions and how to partition your data. Use a partition column with high cardinality. You can also enter a query that matches the partitioning scheme of your source table. Tip For source partitioning, the I/O of the SQL Server is the bottleneck. Adding too many partitions may saturate your source database. Generally four or five partitions is ideal when using this option. Isolation level
24-1	11205-11210	Azure	
24-2	11211-11214	SQL	
24-3	11215-11223	Database	
24-4	11224-11227	has	
24-5	11228-11229	a	
24-6	11230-11236	unique	
24-7	11237-11249	partitioning	
24-8	11250-11256	option	
24-9	11257-11263	called	
24-10	11264-11265	'	
24-11	11265-11271	Source	
24-12	11271-11272	'	
24-13	11273-11285	partitioning	
24-14	11285-11286	.	
24-15	11287-11295	Enabling	
24-16	11296-11302	source	
24-17	11303-11315	partitioning	
24-18	11316-11319	can	
24-19	11320-11327	improve	
24-20	11328-11332	your	
24-21	11333-11337	read	
24-22	11338-11343	times	
24-23	11344-11348	from	
24-24	11349-11354	Azure	
24-25	11355-11358	SQL	
24-26	11359-11361	DB	
24-27	11362-11364	by	
24-28	11365-11373	enabling	
24-29	11374-11382	parallel	
24-30	11383-11394	connections	
24-31	11395-11397	on	
24-32	11398-11401	the	
24-33	11402-11408	source	
24-34	11409-11415	system	
24-35	11415-11416	.	
24-36	11417-11424	Specify	
24-37	11425-11428	the	
24-38	11429-11435	number	
24-39	11436-11438	of	
24-40	11439-11449	partitions	
24-41	11450-11453	and	
24-42	11454-11457	how	
24-43	11458-11460	to	
24-44	11461-11470	partition	
24-45	11471-11475	your	
24-46	11476-11480	data	
24-47	11480-11481	.	
24-48	11482-11485	Use	
24-49	11486-11487	a	
24-50	11488-11497	partition	
24-51	11498-11504	column	
24-52	11505-11509	with	
24-53	11510-11514	high	
24-54	11515-11526	cardinality	
24-55	11526-11527	.	
24-56	11528-11531	You	
24-57	11532-11535	can	
24-58	11536-11540	also	
24-59	11541-11546	enter	
24-60	11547-11548	a	
24-61	11549-11554	query	
24-62	11555-11559	that	
24-63	11560-11567	matches	
24-64	11568-11571	the	
24-65	11572-11584	partitioning	
24-66	11585-11591	scheme	
24-67	11592-11594	of	
24-68	11595-11599	your	
24-69	11600-11606	source	
24-70	11607-11612	table	
24-71	11612-11613	.	
24-72	11614-11617	Tip	
24-73	11618-11621	For	
24-74	11622-11628	source	
24-75	11629-11641	partitioning	
24-76	11641-11642	,	
24-77	11643-11646	the	
24-78	11647-11648	I	
24-79	11648-11649	/	
24-80	11649-11650	O	
24-81	11651-11653	of	
24-82	11654-11657	the	
24-83	11658-11661	SQL	
24-84	11662-11668	Server	
24-85	11669-11671	is	
24-86	11672-11675	the	
24-87	11676-11686	bottleneck	
24-88	11686-11687	.	
24-89	11688-11694	Adding	
24-90	11695-11698	too	
24-91	11699-11703	many	
24-92	11704-11714	partitions	
24-93	11715-11718	may	
24-94	11719-11727	saturate	
24-95	11728-11732	your	
24-96	11733-11739	source	
24-97	11740-11748	database	
24-98	11748-11749	.	
24-99	11750-11759	Generally	
24-100	11760-11764	four	
24-101	11765-11767	or	
24-102	11768-11772	five	
24-103	11773-11783	partitions	
24-104	11784-11786	is	
24-105	11787-11792	ideal	
24-106	11793-11797	when	
24-107	11798-11803	using	
24-108	11804-11808	this	
24-109	11809-11815	option	
24-110	11815-11816	.	
24-111	11817-11826	Isolation	
24-112	11827-11832	level	

#Text=The isolation level of the read on an Azure SQL source system has an impact on performance. Choosing 'Read uncommitted' will provide the fastest performance and prevent any database locks. To learn more about SQL Isolation levels, please see Understanding isolation levels. Read using query You can read from Azure SQL Database using a table or a SQL query. If you are executing a SQL query, the query must complete before transformation can start. SQL Queries can be useful to push down operations that may execute faster and reduce the amount of data read from a SQL Server such as SELECT, WHERE, and JOIN statements. When pushing down operations, you lose the ability to track lineage and performance of the transformations before the data comes into the data flow.
25-1	11833-11836	The	
25-2	11837-11846	isolation	
25-3	11847-11852	level	
25-4	11853-11855	of	
25-5	11856-11859	the	
25-6	11860-11864	read	
25-7	11865-11867	on	
25-8	11868-11870	an	
25-9	11871-11876	Azure	
25-10	11877-11880	SQL	
25-11	11881-11887	source	
25-12	11888-11894	system	
25-13	11895-11898	has	
25-14	11899-11901	an	
25-15	11902-11908	impact	
25-16	11909-11911	on	
25-17	11912-11923	performance	
25-18	11923-11924	.	
25-19	11925-11933	Choosing	
25-20	11934-11935	'	
25-21	11935-11939	Read	
25-22	11940-11951	uncommitted	
25-23	11951-11952	'	
25-24	11953-11957	will	
25-25	11958-11965	provide	
25-26	11966-11969	the	
25-27	11970-11977	fastest	
25-28	11978-11989	performance	
25-29	11990-11993	and	
25-30	11994-12001	prevent	
25-31	12002-12005	any	
25-32	12006-12014	database	
25-33	12015-12020	locks	
25-34	12020-12021	.	
25-35	12022-12024	To	
25-36	12025-12030	learn	
25-37	12031-12035	more	
25-38	12036-12041	about	
25-39	12042-12045	SQL	
25-40	12046-12055	Isolation	
25-41	12056-12062	levels	
25-42	12062-12063	,	
25-43	12064-12070	please	
25-44	12071-12074	see	
25-45	12075-12088	Understanding	
25-46	12089-12098	isolation	
25-47	12099-12105	levels	
25-48	12105-12106	.	
25-49	12107-12111	Read	
25-50	12112-12117	using	
25-51	12118-12123	query	
25-52	12124-12127	You	
25-53	12128-12131	can	
25-54	12132-12136	read	
25-55	12137-12141	from	
25-56	12142-12147	Azure	
25-57	12148-12151	SQL	
25-58	12152-12160	Database	
25-59	12161-12166	using	
25-60	12167-12168	a	
25-61	12169-12174	table	
25-62	12175-12177	or	
25-63	12178-12179	a	
25-64	12180-12183	SQL	
25-65	12184-12189	query	
25-66	12189-12190	.	
25-67	12191-12193	If	
25-68	12194-12197	you	
25-69	12198-12201	are	
25-70	12202-12211	executing	
25-71	12212-12213	a	
25-72	12214-12217	SQL	
25-73	12218-12223	query	
25-74	12223-12224	,	
25-75	12225-12228	the	
25-76	12229-12234	query	
25-77	12235-12239	must	
25-78	12240-12248	complete	
25-79	12249-12255	before	
25-80	12256-12270	transformation	
25-81	12271-12274	can	
25-82	12275-12280	start	
25-83	12280-12281	.	
25-84	12282-12285	SQL	
25-85	12286-12293	Queries	
25-86	12294-12297	can	
25-87	12298-12300	be	
25-88	12301-12307	useful	
25-89	12308-12310	to	
25-90	12311-12315	push	
25-91	12316-12320	down	
25-92	12321-12331	operations	
25-93	12332-12336	that	
25-94	12337-12340	may	
25-95	12341-12348	execute	
25-96	12349-12355	faster	
25-97	12356-12359	and	
25-98	12360-12366	reduce	
25-99	12367-12370	the	
25-100	12371-12377	amount	
25-101	12378-12380	of	
25-102	12381-12385	data	
25-103	12386-12390	read	
25-104	12391-12395	from	
25-105	12396-12397	a	
25-106	12398-12401	SQL	
25-107	12402-12408	Server	
25-108	12409-12413	such	
25-109	12414-12416	as	
25-110	12417-12423	SELECT	
25-111	12423-12424	,	
25-112	12425-12430	WHERE	
25-113	12430-12431	,	
25-114	12432-12435	and	
25-115	12436-12440	JOIN	
25-116	12441-12451	statements	
25-117	12451-12452	.	
25-118	12453-12457	When	
25-119	12458-12465	pushing	
25-120	12466-12470	down	
25-121	12471-12481	operations	
25-122	12481-12482	,	
25-123	12483-12486	you	
25-124	12487-12491	lose	
25-125	12492-12495	the	
25-126	12496-12503	ability	
25-127	12504-12506	to	
25-128	12507-12512	track	
25-129	12513-12520	lineage	
25-130	12521-12524	and	
25-131	12525-12536	performance	
25-132	12537-12539	of	
25-133	12540-12543	the	
25-134	12544-12559	transformations	
25-135	12560-12566	before	
25-136	12567-12570	the	
25-137	12571-12575	data	
25-138	12576-12581	comes	
25-139	12582-12586	into	
25-140	12587-12590	the	
25-141	12591-12595	data	
25-142	12596-12600	flow	
25-143	12600-12601	.	

#Text=Azure Synapse Analytics sources When using Azure Synapse Analytics, a setting called Enable staging exists in the source options. This allows ADF to read from Synapse using Staging, which greatly improves read performance. Enabling Staging requires you to specify an Azure Blob Storage or Azure Data Lake Storage gen2 staging location in the data flow activity settings.
26-1	12602-12607	Azure	
26-2	12608-12615	Synapse	
26-3	12616-12625	Analytics	
26-4	12626-12633	sources	
26-5	12634-12638	When	
26-6	12639-12644	using	
26-7	12645-12650	Azure	
26-8	12651-12658	Synapse	
26-9	12659-12668	Analytics	
26-10	12668-12669	,	
26-11	12670-12671	a	
26-12	12672-12679	setting	
26-13	12680-12686	called	
26-14	12687-12693	Enable	
26-15	12694-12701	staging	
26-16	12702-12708	exists	
26-17	12709-12711	in	
26-18	12712-12715	the	
26-19	12716-12722	source	
26-20	12723-12730	options	
26-21	12730-12731	.	
26-22	12732-12736	This	
26-23	12737-12743	allows	
26-24	12744-12747	ADF	
26-25	12748-12750	to	
26-26	12751-12755	read	
26-27	12756-12760	from	
26-28	12761-12768	Synapse	
26-29	12769-12774	using	
26-30	12775-12782	Staging	
26-31	12782-12783	,	
26-32	12784-12789	which	
26-33	12790-12797	greatly	
26-34	12798-12806	improves	
26-35	12807-12811	read	
26-36	12812-12823	performance	
26-37	12823-12824	.	
26-38	12825-12833	Enabling	
26-39	12834-12841	Staging	
26-40	12842-12850	requires	
26-41	12851-12854	you	
26-42	12855-12857	to	
26-43	12858-12865	specify	
26-44	12866-12868	an	
26-45	12869-12874	Azure	
26-46	12875-12879	Blob	
26-47	12880-12887	Storage	
26-48	12888-12890	or	
26-49	12891-12896	Azure	
26-50	12897-12901	Data	
26-51	12902-12906	Lake	
26-52	12907-12914	Storage	
26-53	12915-12919	gen2	
26-54	12920-12927	staging	
26-55	12928-12936	location	
26-56	12937-12939	in	
26-57	12940-12943	the	
26-58	12944-12948	data	
26-59	12949-12953	flow	
26-60	12954-12962	activity	
26-61	12963-12971	settings	
26-62	12971-12972	.	

#Text=File-based sources While data flows support a variety of file types, the Azure Data Factory recommends using the Spark-native Parquet format for optimal read and write times.
27-1	12973-12983	File-based	
27-2	12984-12991	sources	
27-3	12992-12997	While	
27-4	12998-13002	data	
27-5	13003-13008	flows	
27-6	13009-13016	support	
27-7	13017-13018	a	
27-8	13019-13026	variety	
27-9	13027-13029	of	
27-10	13030-13034	file	
27-11	13035-13040	types	
27-12	13040-13041	,	
27-13	13042-13045	the	
27-14	13046-13051	Azure	
27-15	13052-13056	Data	
27-16	13057-13064	Factory	
27-17	13065-13075	recommends	
27-18	13076-13081	using	
27-19	13082-13085	the	
27-20	13086-13098	Spark-native	
27-21	13099-13106	Parquet	
27-22	13107-13113	format	
27-23	13114-13117	for	
27-24	13118-13125	optimal	
27-25	13126-13130	read	
27-26	13131-13134	and	
27-27	13135-13140	write	
27-28	13141-13146	times	
27-29	13146-13147	.	

#Text=If you're running the same data flow on a set of files, we recommend reading from a folder, using wildcard paths or reading from a list of files. A single data flow activity run can process all of your files in batch. More information on how to set these settings can be found in the connector documentation such as Azure Blob Storage. If possible, avoid using the For-Each activity to run data flows over a set of files. This will cause each iteration of the for-each to spin up its own Spark cluster, which is often not necessary and can be expensive. Optimizing sinks
28-1	13148-13150	If	
28-2	13151-13157	you're	
28-3	13158-13165	running	
28-4	13166-13169	the	
28-5	13170-13174	same	
28-6	13175-13179	data	
28-7	13180-13184	flow	
28-8	13185-13187	on	
28-9	13188-13189	a	
28-10	13190-13193	set	
28-11	13194-13196	of	
28-12	13197-13202	files	
28-13	13202-13203	,	
28-14	13204-13206	we	
28-15	13207-13216	recommend	
28-16	13217-13224	reading	
28-17	13225-13229	from	
28-18	13230-13231	a	
28-19	13232-13238	folder	
28-20	13238-13239	,	
28-21	13240-13245	using	
28-22	13246-13254	wildcard	
28-23	13255-13260	paths	
28-24	13261-13263	or	
28-25	13264-13271	reading	
28-26	13272-13276	from	
28-27	13277-13278	a	
28-28	13279-13283	list	
28-29	13284-13286	of	
28-30	13287-13292	files	
28-31	13292-13293	.	
28-32	13294-13295	A	
28-33	13296-13302	single	
28-34	13303-13307	data	
28-35	13308-13312	flow	
28-36	13313-13321	activity	
28-37	13322-13325	run	
28-38	13326-13329	can	
28-39	13330-13337	process	
28-40	13338-13341	all	
28-41	13342-13344	of	
28-42	13345-13349	your	
28-43	13350-13355	files	
28-44	13356-13358	in	
28-45	13359-13364	batch	
28-46	13364-13365	.	
28-47	13366-13370	More	
28-48	13371-13382	information	
28-49	13383-13385	on	
28-50	13386-13389	how	
28-51	13390-13392	to	
28-52	13393-13396	set	
28-53	13397-13402	these	
28-54	13403-13411	settings	
28-55	13412-13415	can	
28-56	13416-13418	be	
28-57	13419-13424	found	
28-58	13425-13427	in	
28-59	13428-13431	the	
28-60	13432-13441	connector	
28-61	13442-13455	documentation	
28-62	13456-13460	such	
28-63	13461-13463	as	
28-64	13464-13469	Azure	
28-65	13470-13474	Blob	
28-66	13475-13482	Storage	
28-67	13482-13483	.	
28-68	13484-13486	If	
28-69	13487-13495	possible	
28-70	13495-13496	,	
28-71	13497-13502	avoid	
28-72	13503-13508	using	
28-73	13509-13512	the	
28-74	13513-13521	For-Each	
28-75	13522-13530	activity	
28-76	13531-13533	to	
28-77	13534-13537	run	
28-78	13538-13542	data	
28-79	13543-13548	flows	
28-80	13549-13553	over	
28-81	13554-13555	a	
28-82	13556-13559	set	
28-83	13560-13562	of	
28-84	13563-13568	files	
28-85	13568-13569	.	
28-86	13570-13574	This	
28-87	13575-13579	will	
28-88	13580-13585	cause	
28-89	13586-13590	each	
28-90	13591-13600	iteration	
28-91	13601-13603	of	
28-92	13604-13607	the	
28-93	13608-13616	for-each	
28-94	13617-13619	to	
28-95	13620-13624	spin	
28-96	13625-13627	up	
28-97	13628-13631	its	
28-98	13632-13635	own	
28-99	13636-13641	Spark	
28-100	13642-13649	cluster	
28-101	13649-13650	,	
28-102	13651-13656	which	
28-103	13657-13659	is	
28-104	13660-13665	often	
28-105	13666-13669	not	
28-106	13670-13679	necessary	
28-107	13680-13683	and	
28-108	13684-13687	can	
28-109	13688-13690	be	
28-110	13691-13700	expensive	
28-111	13700-13701	.	
28-112	13702-13712	Optimizing	
28-113	13713-13718	sinks	

#Text=When data flows write to sinks, any custom partitioning will happen immediately before the write. Like the source, in most cases it is recommended that you keep Use current partitioning as the selected partition option. Partitioned data will write significantly quicker than unpartitioned data, even your destination is not partitioned. Below are the individual considerations for various sink types. Azure SQL Database sinks With Azure SQL Database, the default partitioning should work in most cases. There is a chance that your sink may have too many partitions for your SQL database to handle. If you are running into this, reduce the number of partitions outputted by your SQL Database sink.
29-1	13719-13723	When	
29-2	13724-13728	data	
29-3	13729-13734	flows	
29-4	13735-13740	write	
29-5	13741-13743	to	
29-6	13744-13749	sinks	
29-7	13749-13750	,	
29-8	13751-13754	any	
29-9	13755-13761	custom	
29-10	13762-13774	partitioning	
29-11	13775-13779	will	
29-12	13780-13786	happen	
29-13	13787-13798	immediately	
29-14	13799-13805	before	
29-15	13806-13809	the	
29-16	13810-13815	write	
29-17	13815-13816	.	
29-18	13817-13821	Like	
29-19	13822-13825	the	
29-20	13826-13832	source	
29-21	13832-13833	,	
29-22	13834-13836	in	
29-23	13837-13841	most	
29-24	13842-13847	cases	
29-25	13848-13850	it	
29-26	13851-13853	is	
29-27	13854-13865	recommended	
29-28	13866-13870	that	
29-29	13871-13874	you	
29-30	13875-13879	keep	
29-31	13880-13883	Use	
29-32	13884-13891	current	
29-33	13892-13904	partitioning	
29-34	13905-13907	as	
29-35	13908-13911	the	
29-36	13912-13920	selected	
29-37	13921-13930	partition	
29-38	13931-13937	option	
29-39	13937-13938	.	
29-40	13939-13950	Partitioned	
29-41	13951-13955	data	
29-42	13956-13960	will	
29-43	13961-13966	write	
29-44	13967-13980	significantly	
29-45	13981-13988	quicker	
29-46	13989-13993	than	
29-47	13994-14007	unpartitioned	
29-48	14008-14012	data	
29-49	14012-14013	,	
29-50	14014-14018	even	
29-51	14019-14023	your	
29-52	14024-14035	destination	
29-53	14036-14038	is	
29-54	14039-14042	not	
29-55	14043-14054	partitioned	
29-56	14054-14055	.	
29-57	14056-14061	Below	
29-58	14062-14065	are	
29-59	14066-14069	the	
29-60	14070-14080	individual	
29-61	14081-14095	considerations	
29-62	14096-14099	for	
29-63	14100-14107	various	
29-64	14108-14112	sink	
29-65	14113-14118	types	
29-66	14118-14119	.	
29-67	14120-14125	Azure	
29-68	14126-14129	SQL	
29-69	14130-14138	Database	
29-70	14139-14144	sinks	
29-71	14145-14149	With	
29-72	14150-14155	Azure	
29-73	14156-14159	SQL	
29-74	14160-14168	Database	
29-75	14168-14169	,	
29-76	14170-14173	the	
29-77	14174-14181	default	
29-78	14182-14194	partitioning	
29-79	14195-14201	should	
29-80	14202-14206	work	
29-81	14207-14209	in	
29-82	14210-14214	most	
29-83	14215-14220	cases	
29-84	14220-14221	.	
29-85	14222-14227	There	
29-86	14228-14230	is	
29-87	14231-14232	a	
29-88	14233-14239	chance	
29-89	14240-14244	that	
29-90	14245-14249	your	
29-91	14250-14254	sink	
29-92	14255-14258	may	
29-93	14259-14263	have	
29-94	14264-14267	too	
29-95	14268-14272	many	
29-96	14273-14283	partitions	
29-97	14284-14287	for	
29-98	14288-14292	your	
29-99	14293-14296	SQL	
29-100	14297-14305	database	
29-101	14306-14308	to	
29-102	14309-14315	handle	
29-103	14315-14316	.	
29-104	14317-14319	If	
29-105	14320-14323	you	
29-106	14324-14327	are	
29-107	14328-14335	running	
29-108	14336-14340	into	
29-109	14341-14345	this	
29-110	14345-14346	,	
29-111	14347-14353	reduce	
29-112	14354-14357	the	
29-113	14358-14364	number	
29-114	14365-14367	of	
29-115	14368-14378	partitions	
29-116	14379-14388	outputted	
29-117	14389-14391	by	
29-118	14392-14396	your	
29-119	14397-14400	SQL	
29-120	14401-14409	Database	
29-121	14410-14414	sink	
29-122	14414-14415	.	

#Text=Impact of error row handling to performance When you enable error row handling ("continue on error") in the sink transformation, ADF will take an additional step before writing the compatible rows to your destination table. This additional step will have a small performance penalty that can be in the range of 5% added for this step with an additional small performance hit also added if you set the option to also with the incompatible rows to a log file.
30-1	14416-14422	Impact	
30-2	14423-14425	of	
30-3	14426-14431	error	
30-4	14432-14435	row	
30-5	14436-14444	handling	
30-6	14445-14447	to	
30-7	14448-14459	performance	
30-8	14460-14464	When	
30-9	14465-14468	you	
30-10	14469-14475	enable	
30-11	14476-14481	error	
30-12	14482-14485	row	
30-13	14486-14494	handling	
30-14	14495-14496	(	
30-15	14496-14497	"	
30-16	14497-14505	continue	
30-17	14506-14508	on	
30-18	14509-14514	error	
30-19	14514-14515	"	
30-20	14515-14516	)	
30-21	14517-14519	in	
30-22	14520-14523	the	
30-23	14524-14528	sink	
30-24	14529-14543	transformation	
30-25	14543-14544	,	
30-26	14545-14548	ADF	
30-27	14549-14553	will	
30-28	14554-14558	take	
30-29	14559-14561	an	
30-30	14562-14572	additional	
30-31	14573-14577	step	
30-32	14578-14584	before	
30-33	14585-14592	writing	
30-34	14593-14596	the	
30-35	14597-14607	compatible	
30-36	14608-14612	rows	
30-37	14613-14615	to	
30-38	14616-14620	your	
30-39	14621-14632	destination	
30-40	14633-14638	table	
30-41	14638-14639	.	
30-42	14640-14644	This	
30-43	14645-14655	additional	
30-44	14656-14660	step	
30-45	14661-14665	will	
30-46	14666-14670	have	
30-47	14671-14672	a	
30-48	14673-14678	small	
30-49	14679-14690	performance	
30-50	14691-14698	penalty	
30-51	14699-14703	that	
30-52	14704-14707	can	
30-53	14708-14710	be	
30-54	14711-14713	in	
30-55	14714-14717	the	
30-56	14718-14723	range	
30-57	14724-14726	of	
30-58	14727-14729	5%	
30-59	14730-14735	added	
30-60	14736-14739	for	
30-61	14740-14744	this	
30-62	14745-14749	step	
30-63	14750-14754	with	
30-64	14755-14757	an	
30-65	14758-14768	additional	
30-66	14769-14774	small	
30-67	14775-14786	performance	
30-68	14787-14790	hit	
30-69	14791-14795	also	
30-70	14796-14801	added	
30-71	14802-14804	if	
30-72	14805-14808	you	
30-73	14809-14812	set	
30-74	14813-14816	the	
30-75	14817-14823	option	
30-76	14824-14826	to	
30-77	14827-14831	also	
30-78	14832-14836	with	
30-79	14837-14840	the	
30-80	14841-14853	incompatible	
30-81	14854-14858	rows	
30-82	14859-14861	to	
30-83	14862-14863	a	
30-84	14864-14867	log	
30-85	14868-14872	file	
30-86	14872-14873	.	

#Text=Disabling indexes using a SQL Script Disabling indexes before a load in a SQL database can greatly improve performance of writing to the table. Run the below command before writing to your SQL sink. ALTER INDEX ALL ON dbo.[Table Name] DISABLE
31-1	14874-14883	Disabling	
31-2	14884-14891	indexes	
31-3	14892-14897	using	
31-4	14898-14899	a	
31-5	14900-14903	SQL	
31-6	14904-14910	Script	
31-7	14911-14920	Disabling	
31-8	14921-14928	indexes	
31-9	14929-14935	before	
31-10	14936-14937	a	
31-11	14938-14942	load	
31-12	14943-14945	in	
31-13	14946-14947	a	
31-14	14948-14951	SQL	
31-15	14952-14960	database	
31-16	14961-14964	can	
31-17	14965-14972	greatly	
31-18	14973-14980	improve	
31-19	14981-14992	performance	
31-20	14993-14995	of	
31-21	14996-15003	writing	
31-22	15004-15006	to	
31-23	15007-15010	the	
31-24	15011-15016	table	
31-25	15016-15017	.	
31-26	15018-15021	Run	
31-27	15022-15025	the	
31-28	15026-15031	below	
31-29	15032-15039	command	
31-30	15040-15046	before	
31-31	15047-15054	writing	
31-32	15055-15057	to	
31-33	15058-15062	your	
31-34	15063-15066	SQL	
31-35	15067-15071	sink	
31-36	15071-15072	.	
31-37	15073-15078	ALTER	
31-38	15079-15084	INDEX	
31-39	15085-15088	ALL	
31-40	15089-15091	ON	
31-41	15092-15095	dbo	
31-42	15095-15096	.	
31-43	15096-15097	[	
31-44	15097-15102	Table	
31-45	15103-15107	Name	
31-46	15107-15108	]	
31-47	15109-15116	DISABLE	

#Text=After the write has completed, rebuild the indexes using the following command: ALTER INDEX ALL ON dbo.[Table Name] REBUILD These can both be done natively using Pre and Post-SQL scripts within an Azure SQL DB or Synapse sink in mapping data flows. Warning
32-1	15117-15122	After	
32-2	15123-15126	the	
32-3	15127-15132	write	
32-4	15133-15136	has	
32-5	15137-15146	completed	
32-6	15146-15147	,	
32-7	15148-15155	rebuild	
32-8	15156-15159	the	
32-9	15160-15167	indexes	
32-10	15168-15173	using	
32-11	15174-15177	the	
32-12	15178-15187	following	
32-13	15188-15195	command	
32-14	15195-15196	:	
32-15	15197-15202	ALTER	
32-16	15203-15208	INDEX	
32-17	15209-15212	ALL	
32-18	15213-15215	ON	
32-19	15216-15219	dbo	
32-20	15219-15220	.	
32-21	15220-15221	[	
32-22	15221-15226	Table	
32-23	15227-15231	Name	
32-24	15231-15232	]	
32-25	15233-15240	REBUILD	
32-26	15241-15246	These	
32-27	15247-15250	can	
32-28	15251-15255	both	
32-29	15256-15258	be	
32-30	15259-15263	done	
32-31	15264-15272	natively	
32-32	15273-15278	using	
32-33	15279-15282	Pre	
32-34	15283-15286	and	
32-35	15287-15295	Post-SQL	
32-36	15296-15303	scripts	
32-37	15304-15310	within	
32-38	15311-15313	an	
32-39	15314-15319	Azure	
32-40	15320-15323	SQL	
32-41	15324-15326	DB	
32-42	15327-15329	or	
32-43	15330-15337	Synapse	
32-44	15338-15342	sink	
32-45	15343-15345	in	
32-46	15346-15353	mapping	
32-47	15354-15358	data	
32-48	15359-15364	flows	
32-49	15364-15365	.	
32-50	15366-15373	Warning	

#Text=When disabling indexes, the data flow is effectively taking control of a database and queries are unlikely to succeed at this time. As a result, many ETL jobs are triggered in the middle of the night to avoid this conflict. For more information, learn about the constraints of disabling indexes Scaling up your database Schedule a resizing of your source and sink Azure SQL DB and DW before your pipeline run to increase the throughput and minimize Azure throttling once you reach DTU limits. After your pipeline execution is complete, resize your databases back to their normal run rate.
33-1	15374-15378	When	
33-2	15379-15388	disabling	
33-3	15389-15396	indexes	
33-4	15396-15397	,	
33-5	15398-15401	the	
33-6	15402-15406	data	
33-7	15407-15411	flow	
33-8	15412-15414	is	
33-9	15415-15426	effectively	
33-10	15427-15433	taking	
33-11	15434-15441	control	
33-12	15442-15444	of	
33-13	15445-15446	a	
33-14	15447-15455	database	
33-15	15456-15459	and	
33-16	15460-15467	queries	
33-17	15468-15471	are	
33-18	15472-15480	unlikely	
33-19	15481-15483	to	
33-20	15484-15491	succeed	
33-21	15492-15494	at	
33-22	15495-15499	this	
33-23	15500-15504	time	
33-24	15504-15505	.	
33-25	15506-15508	As	
33-26	15509-15510	a	
33-27	15511-15517	result	
33-28	15517-15518	,	
33-29	15519-15523	many	
33-30	15524-15527	ETL	
33-31	15528-15532	jobs	
33-32	15533-15536	are	
33-33	15537-15546	triggered	
33-34	15547-15549	in	
33-35	15550-15553	the	
33-36	15554-15560	middle	
33-37	15561-15563	of	
33-38	15564-15567	the	
33-39	15568-15573	night	
33-40	15574-15576	to	
33-41	15577-15582	avoid	
33-42	15583-15587	this	
33-43	15588-15596	conflict	
33-44	15596-15597	.	
33-45	15598-15601	For	
33-46	15602-15606	more	
33-47	15607-15618	information	
33-48	15618-15619	,	
33-49	15620-15625	learn	
33-50	15626-15631	about	
33-51	15632-15635	the	
33-52	15636-15647	constraints	
33-53	15648-15650	of	
33-54	15651-15660	disabling	
33-55	15661-15668	indexes	
33-56	15669-15676	Scaling	
33-57	15677-15679	up	
33-58	15680-15684	your	
33-59	15685-15693	database	
33-60	15694-15702	Schedule	
33-61	15703-15704	a	
33-62	15705-15713	resizing	
33-63	15714-15716	of	
33-64	15717-15721	your	
33-65	15722-15728	source	
33-66	15729-15732	and	
33-67	15733-15737	sink	
33-68	15738-15743	Azure	
33-69	15744-15747	SQL	
33-70	15748-15750	DB	
33-71	15751-15754	and	
33-72	15755-15757	DW	
33-73	15758-15764	before	
33-74	15765-15769	your	
33-75	15770-15778	pipeline	
33-76	15779-15782	run	
33-77	15783-15785	to	
33-78	15786-15794	increase	
33-79	15795-15798	the	
33-80	15799-15809	throughput	
33-81	15810-15813	and	
33-82	15814-15822	minimize	
33-83	15823-15828	Azure	
33-84	15829-15839	throttling	
33-85	15840-15844	once	
33-86	15845-15848	you	
33-87	15849-15854	reach	
33-88	15855-15858	DTU	
33-89	15859-15865	limits	
33-90	15865-15866	.	
33-91	15867-15872	After	
33-92	15873-15877	your	
33-93	15878-15886	pipeline	
33-94	15887-15896	execution	
33-95	15897-15899	is	
33-96	15900-15908	complete	
33-97	15908-15909	,	
33-98	15910-15916	resize	
33-99	15917-15921	your	
33-100	15922-15931	databases	
33-101	15932-15936	back	
33-102	15937-15939	to	
33-103	15940-15945	their	
33-104	15946-15952	normal	
33-105	15953-15956	run	
33-106	15957-15961	rate	
33-107	15961-15962	.	

#Text=Azure Synapse Analytics sinks When writing to Azure Synapse Analytics, make sure that Enable staging is set to true. This enables ADF to write using SQL Copy Command which effectively loads the data in bulk. You will need to reference an Azure Data Lake Storage gen2 or Azure Blob Storage account for staging of the data when using Staging.
34-1	15963-15968	Azure	
34-2	15969-15976	Synapse	
34-3	15977-15986	Analytics	
34-4	15987-15992	sinks	
34-5	15993-15997	When	
34-6	15998-16005	writing	
34-7	16006-16008	to	
34-8	16009-16014	Azure	
34-9	16015-16022	Synapse	
34-10	16023-16032	Analytics	
34-11	16032-16033	,	
34-12	16034-16038	make	
34-13	16039-16043	sure	
34-14	16044-16048	that	
34-15	16049-16055	Enable	
34-16	16056-16063	staging	
34-17	16064-16066	is	
34-18	16067-16070	set	
34-19	16071-16073	to	
34-20	16074-16078	true	
34-21	16078-16079	.	
34-22	16080-16084	This	
34-23	16085-16092	enables	
34-24	16093-16096	ADF	
34-25	16097-16099	to	
34-26	16100-16105	write	
34-27	16106-16111	using	
34-28	16112-16115	SQL	
34-29	16116-16120	Copy	
34-30	16121-16128	Command	
34-31	16129-16134	which	
34-32	16135-16146	effectively	
34-33	16147-16152	loads	
34-34	16153-16156	the	
34-35	16157-16161	data	
34-36	16162-16164	in	
34-37	16165-16169	bulk	
34-38	16169-16170	.	
34-39	16171-16174	You	
34-40	16175-16179	will	
34-41	16180-16184	need	
34-42	16185-16187	to	
34-43	16188-16197	reference	
34-44	16198-16200	an	
34-45	16201-16206	Azure	
34-46	16207-16211	Data	
34-47	16212-16216	Lake	
34-48	16217-16224	Storage	
34-49	16225-16229	gen2	
34-50	16230-16232	or	
34-51	16233-16238	Azure	
34-52	16239-16243	Blob	
34-53	16244-16251	Storage	
34-54	16252-16259	account	
34-55	16260-16263	for	
34-56	16264-16271	staging	
34-57	16272-16274	of	
34-58	16275-16278	the	
34-59	16279-16283	data	
34-60	16284-16288	when	
34-61	16289-16294	using	
34-62	16295-16302	Staging	
34-63	16302-16303	.	

#Text=Other than Staging, the same best practices apply to Azure Synapse Analytics as Azure SQL Database. File-based sinks While data flows support a variety of file types, the Azure Data Factory recommends using the Spark-native Parquet format for optimal read and write times. If the data is evenly distributed, Use current partitioning will be the fastest partitioning option for writing files.
35-1	16304-16309	Other	
35-2	16310-16314	than	
35-3	16315-16322	Staging	
35-4	16322-16323	,	
35-5	16324-16327	the	
35-6	16328-16332	same	
35-7	16333-16337	best	
35-8	16338-16347	practices	
35-9	16348-16353	apply	
35-10	16354-16356	to	
35-11	16357-16362	Azure	
35-12	16363-16370	Synapse	
35-13	16371-16380	Analytics	
35-14	16381-16383	as	
35-15	16384-16389	Azure	
35-16	16390-16393	SQL	
35-17	16394-16402	Database	
35-18	16402-16403	.	
35-19	16404-16414	File-based	
35-20	16415-16420	sinks	
35-21	16421-16426	While	
35-22	16427-16431	data	
35-23	16432-16437	flows	
35-24	16438-16445	support	
35-25	16446-16447	a	
35-26	16448-16455	variety	
35-27	16456-16458	of	
35-28	16459-16463	file	
35-29	16464-16469	types	
35-30	16469-16470	,	
35-31	16471-16474	the	
35-32	16475-16480	Azure	
35-33	16481-16485	Data	
35-34	16486-16493	Factory	
35-35	16494-16504	recommends	
35-36	16505-16510	using	
35-37	16511-16514	the	
35-38	16515-16527	Spark-native	
35-39	16528-16535	Parquet	
35-40	16536-16542	format	
35-41	16543-16546	for	
35-42	16547-16554	optimal	
35-43	16555-16559	read	
35-44	16560-16563	and	
35-45	16564-16569	write	
35-46	16570-16575	times	
35-47	16575-16576	.	
35-48	16577-16579	If	
35-49	16580-16583	the	
35-50	16584-16588	data	
35-51	16589-16591	is	
35-52	16592-16598	evenly	
35-53	16599-16610	distributed	
35-54	16610-16611	,	
35-55	16612-16615	Use	
35-56	16616-16623	current	
35-57	16624-16636	partitioning	
35-58	16637-16641	will	
35-59	16642-16644	be	
35-60	16645-16648	the	
35-61	16649-16656	fastest	
35-62	16657-16669	partitioning	
35-63	16670-16676	option	
35-64	16677-16680	for	
35-65	16681-16688	writing	
35-66	16689-16694	files	
35-67	16694-16695	.	

#Text=File name options When writing files, you have a choice of naming options that each have a performance impact. Selecting the Default option will write the fastest. Each partition will equate to a file with the Spark default name. This is useful if you are just reading from the folder of data.
36-1	16696-16700	File	
36-2	16701-16705	name	
36-3	16706-16713	options	
36-4	16714-16718	When	
36-5	16719-16726	writing	
36-6	16727-16732	files	
36-7	16732-16733	,	
36-8	16734-16737	you	
36-9	16738-16742	have	
36-10	16743-16744	a	
36-11	16745-16751	choice	
36-12	16752-16754	of	
36-13	16755-16761	naming	
36-14	16762-16769	options	
36-15	16770-16774	that	
36-16	16775-16779	each	
36-17	16780-16784	have	
36-18	16785-16786	a	
36-19	16787-16798	performance	
36-20	16799-16805	impact	
36-21	16805-16806	.	
36-22	16807-16816	Selecting	
36-23	16817-16820	the	
36-24	16821-16828	Default	
36-25	16829-16835	option	
36-26	16836-16840	will	
36-27	16841-16846	write	
36-28	16847-16850	the	
36-29	16851-16858	fastest	
36-30	16858-16859	.	
36-31	16860-16864	Each	
36-32	16865-16874	partition	
36-33	16875-16879	will	
36-34	16880-16886	equate	
36-35	16887-16889	to	
36-36	16890-16891	a	
36-37	16892-16896	file	
36-38	16897-16901	with	
36-39	16902-16905	the	
36-40	16906-16911	Spark	
36-41	16912-16919	default	
36-42	16920-16924	name	
36-43	16924-16925	.	
36-44	16926-16930	This	
36-45	16931-16933	is	
36-46	16934-16940	useful	
36-47	16941-16943	if	
36-48	16944-16947	you	
36-49	16948-16951	are	
36-50	16952-16956	just	
36-51	16957-16964	reading	
36-52	16965-16969	from	
36-53	16970-16973	the	
36-54	16974-16980	folder	
36-55	16981-16983	of	
36-56	16984-16988	data	
36-57	16988-16989	.	

#Text=Setting a naming Pattern will rename each partition file to a more user-friendly name. This operation happens after write and is slightly slower than choosing the default. Per partition allows you to name each individual partition manually. If a column corresponds to how you wish to output the data, you can select As data in column. This reshuffles the data and can impact performance if the columns are not evenly distributed.
37-1	16990-16997	Setting	
37-2	16998-16999	a	
37-3	17000-17006	naming	
37-4	17007-17014	Pattern	
37-5	17015-17019	will	
37-6	17020-17026	rename	
37-7	17027-17031	each	
37-8	17032-17041	partition	
37-9	17042-17046	file	
37-10	17047-17049	to	
37-11	17050-17051	a	
37-12	17052-17056	more	
37-13	17057-17070	user-friendly	
37-14	17071-17075	name	
37-15	17075-17076	.	
37-16	17077-17081	This	
37-17	17082-17091	operation	
37-18	17092-17099	happens	
37-19	17100-17105	after	
37-20	17106-17111	write	
37-21	17112-17115	and	
37-22	17116-17118	is	
37-23	17119-17127	slightly	
37-24	17128-17134	slower	
37-25	17135-17139	than	
37-26	17140-17148	choosing	
37-27	17149-17152	the	
37-28	17153-17160	default	
37-29	17160-17161	.	
37-30	17162-17165	Per	
37-31	17166-17175	partition	
37-32	17176-17182	allows	
37-33	17183-17186	you	
37-34	17187-17189	to	
37-35	17190-17194	name	
37-36	17195-17199	each	
37-37	17200-17210	individual	
37-38	17211-17220	partition	
37-39	17221-17229	manually	
37-40	17229-17230	.	
37-41	17231-17233	If	
37-42	17234-17235	a	
37-43	17236-17242	column	
37-44	17243-17254	corresponds	
37-45	17255-17257	to	
37-46	17258-17261	how	
37-47	17262-17265	you	
37-48	17266-17270	wish	
37-49	17271-17273	to	
37-50	17274-17280	output	
37-51	17281-17284	the	
37-52	17285-17289	data	
37-53	17289-17290	,	
37-54	17291-17294	you	
37-55	17295-17298	can	
37-56	17299-17305	select	
37-57	17306-17308	As	
37-58	17309-17313	data	
37-59	17314-17316	in	
37-60	17317-17323	column	
37-61	17323-17324	.	
37-62	17325-17329	This	
37-63	17330-17340	reshuffles	
37-64	17341-17344	the	
37-65	17345-17349	data	
37-66	17350-17353	and	
37-67	17354-17357	can	
37-68	17358-17364	impact	
37-69	17365-17376	performance	
37-70	17377-17379	if	
37-71	17380-17383	the	
37-72	17384-17391	columns	
37-73	17392-17395	are	
37-74	17396-17399	not	
37-75	17400-17406	evenly	
37-76	17407-17418	distributed	
37-77	17418-17419	.	

#Text=Output to single file combines all the data into a single partition. This leads to long write times, especially for large datasets. The Azure Data Factory team highly recommends not choosing this option unless there is an explicit business reason to do so. CosmosDB sinks When writing to CosmosDB, altering throughput and batch size during data flow execution can improve performance. These changes only take effect during the data flow activity run and will return to the original collection settings after conclusion.
38-1	17420-17426	Output	
38-2	17427-17429	to	
38-3	17430-17436	single	
38-4	17437-17441	file	
38-5	17442-17450	combines	
38-6	17451-17454	all	
38-7	17455-17458	the	
38-8	17459-17463	data	
38-9	17464-17468	into	
38-10	17469-17470	a	
38-11	17471-17477	single	
38-12	17478-17487	partition	
38-13	17487-17488	.	
38-14	17489-17493	This	
38-15	17494-17499	leads	
38-16	17500-17502	to	
38-17	17503-17507	long	
38-18	17508-17513	write	
38-19	17514-17519	times	
38-20	17519-17520	,	
38-21	17521-17531	especially	
38-22	17532-17535	for	
38-23	17536-17541	large	
38-24	17542-17550	datasets	
38-25	17550-17551	.	
38-26	17552-17555	The	
38-27	17556-17561	Azure	
38-28	17562-17566	Data	
38-29	17567-17574	Factory	
38-30	17575-17579	team	
38-31	17580-17586	highly	
38-32	17587-17597	recommends	
38-33	17598-17601	not	
38-34	17602-17610	choosing	
38-35	17611-17615	this	
38-36	17616-17622	option	
38-37	17623-17629	unless	
38-38	17630-17635	there	
38-39	17636-17638	is	
38-40	17639-17641	an	
38-41	17642-17650	explicit	
38-42	17651-17659	business	
38-43	17660-17666	reason	
38-44	17667-17669	to	
38-45	17670-17672	do	
38-46	17673-17675	so	
38-47	17675-17676	.	
38-48	17677-17685	CosmosDB	
38-49	17686-17691	sinks	
38-50	17692-17696	When	
38-51	17697-17704	writing	
38-52	17705-17707	to	
38-53	17708-17716	CosmosDB	
38-54	17716-17717	,	
38-55	17718-17726	altering	
38-56	17727-17737	throughput	
38-57	17738-17741	and	
38-58	17742-17747	batch	
38-59	17748-17752	size	
38-60	17753-17759	during	
38-61	17760-17764	data	
38-62	17765-17769	flow	
38-63	17770-17779	execution	
38-64	17780-17783	can	
38-65	17784-17791	improve	
38-66	17792-17803	performance	
38-67	17803-17804	.	
38-68	17805-17810	These	
38-69	17811-17818	changes	
38-70	17819-17823	only	
38-71	17824-17828	take	
38-72	17829-17835	effect	
38-73	17836-17842	during	
38-74	17843-17846	the	
38-75	17847-17851	data	
38-76	17852-17856	flow	
38-77	17857-17865	activity	
38-78	17866-17869	run	
38-79	17870-17873	and	
38-80	17874-17878	will	
38-81	17879-17885	return	
38-82	17886-17888	to	
38-83	17889-17892	the	
38-84	17893-17901	original	
38-85	17902-17912	collection	
38-86	17913-17921	settings	
38-87	17922-17927	after	
38-88	17928-17938	conclusion	
38-89	17938-17939	.	

#Text=Batch size: Usually, starting with the default batch size is sufficient. To further tune this value, calculate the rough object size of your data, and make sure that object size * batch size is less than 2MB. If it is, you can increase the batch size to get better throughput. Throughput: Set a higher throughput setting here to allow documents to write faster to CosmosDB. Keep in mind the higher RU costs based upon a high throughput setting.
39-1	17940-17945	Batch	
39-2	17946-17950	size	
39-3	17950-17951	:	
39-4	17952-17959	Usually	
39-5	17959-17960	,	
39-6	17961-17969	starting	
39-7	17970-17974	with	
39-8	17975-17978	the	
39-9	17979-17986	default	
39-10	17987-17992	batch	
39-11	17993-17997	size	
39-12	17998-18000	is	
39-13	18001-18011	sufficient	
39-14	18011-18012	.	
39-15	18013-18015	To	
39-16	18016-18023	further	
39-17	18024-18028	tune	
39-18	18029-18033	this	
39-19	18034-18039	value	
39-20	18039-18040	,	
39-21	18041-18050	calculate	
39-22	18051-18054	the	
39-23	18055-18060	rough	
39-24	18061-18067	object	
39-25	18068-18072	size	
39-26	18073-18075	of	
39-27	18076-18080	your	
39-28	18081-18085	data	
39-29	18085-18086	,	
39-30	18087-18090	and	
39-31	18091-18095	make	
39-32	18096-18100	sure	
39-33	18101-18105	that	
39-34	18106-18112	object	
39-35	18113-18117	size	
39-36	18118-18119	*	
39-37	18120-18125	batch	
39-38	18126-18130	size	
39-39	18131-18133	is	
39-40	18134-18138	less	
39-41	18139-18143	than	
39-42	18144-18147	2MB	
39-43	18147-18148	.	
39-44	18149-18151	If	
39-45	18152-18154	it	
39-46	18155-18157	is	
39-47	18157-18158	,	
39-48	18159-18162	you	
39-49	18163-18166	can	
39-50	18167-18175	increase	
39-51	18176-18179	the	
39-52	18180-18185	batch	
39-53	18186-18190	size	
39-54	18191-18193	to	
39-55	18194-18197	get	
39-56	18198-18204	better	
39-57	18205-18215	throughput	
39-58	18215-18216	.	
39-59	18217-18227	Throughput	
39-60	18227-18228	:	
39-61	18229-18232	Set	
39-62	18233-18234	a	
39-63	18235-18241	higher	
39-64	18242-18252	throughput	
39-65	18253-18260	setting	
39-66	18261-18265	here	
39-67	18266-18268	to	
39-68	18269-18274	allow	
39-69	18275-18284	documents	
39-70	18285-18287	to	
39-71	18288-18293	write	
39-72	18294-18300	faster	
39-73	18301-18303	to	
39-74	18304-18312	CosmosDB	
39-75	18312-18313	.	
39-76	18314-18318	Keep	
39-77	18319-18321	in	
39-78	18322-18326	mind	
39-79	18327-18330	the	
39-80	18331-18337	higher	
39-81	18338-18340	RU	
39-82	18341-18346	costs	
39-83	18347-18352	based	
39-84	18353-18357	upon	
39-85	18358-18359	a	
39-86	18360-18364	high	
39-87	18365-18375	throughput	
39-88	18376-18383	setting	
39-89	18383-18384	.	

#Text=Write throughput budget: Use a value which is smaller than total RUs per minute. If you have a data flow with a high number of Spark partitions, setting a budget throughput will allow more balance across those partitions. Optimizing transformations Optimizing Joins, Exists, and Lookups Broadcasting
40-1	18385-18390	Write	
40-2	18391-18401	throughput	
40-3	18402-18408	budget	
40-4	18408-18409	:	
40-5	18410-18413	Use	
40-6	18414-18415	a	
40-7	18416-18421	value	
40-8	18422-18427	which	
40-9	18428-18430	is	
40-10	18431-18438	smaller	
40-11	18439-18443	than	
40-12	18444-18449	total	
40-13	18450-18453	RUs	
40-14	18454-18457	per	
40-15	18458-18464	minute	
40-16	18464-18465	.	
40-17	18466-18468	If	
40-18	18469-18472	you	
40-19	18473-18477	have	
40-20	18478-18479	a	
40-21	18480-18484	data	
40-22	18485-18489	flow	
40-23	18490-18494	with	
40-24	18495-18496	a	
40-25	18497-18501	high	
40-26	18502-18508	number	
40-27	18509-18511	of	
40-28	18512-18517	Spark	
40-29	18518-18528	partitions	
40-30	18528-18529	,	
40-31	18530-18537	setting	
40-32	18538-18539	a	
40-33	18540-18546	budget	
40-34	18547-18557	throughput	
40-35	18558-18562	will	
40-36	18563-18568	allow	
40-37	18569-18573	more	
40-38	18574-18581	balance	
40-39	18582-18588	across	
40-40	18589-18594	those	
40-41	18595-18605	partitions	
40-42	18605-18606	.	
40-43	18607-18617	Optimizing	
40-44	18618-18633	transformations	
40-45	18634-18644	Optimizing	
40-46	18645-18650	Joins	
40-47	18650-18651	,	
40-48	18652-18658	Exists	
40-49	18658-18659	,	
40-50	18660-18663	and	
40-51	18664-18671	Lookups	
40-52	18672-18684	Broadcasting	

#Text=In joins, lookups, and exists transformations, if one or both data streams are small enough to fit into worker node memory, you can optimize performance by enabling Broadcasting. Broadcasting is when you send small data frames to all nodes in the cluster. This allows for the Spark engine to perform a join without reshuffling the data in the large stream. By default, the Spark engine will automatically decide whether or not to broadcast one side of a join. If you are familiar with your incoming data and know that one stream will be significantly smaller than the other, you can select Fixed broadcasting. Fixed broadcasting forces Spark to broadcast the selected stream. If the size of the broadcasted data is too large for the Spark node, you may get an out of memory error. To avoid out of memory errors, use memory optimized clusters. If you experience broadcast timeouts during data flow executions, you can switch off the broadcast optimization. However, this will result in slower performing data flows.
41-1	18685-18687	In	
41-2	18688-18693	joins	
41-3	18693-18694	,	
41-4	18695-18702	lookups	
41-5	18702-18703	,	
41-6	18704-18707	and	
41-7	18708-18714	exists	
41-8	18715-18730	transformations	
41-9	18730-18731	,	
41-10	18732-18734	if	
41-11	18735-18738	one	
41-12	18739-18741	or	
41-13	18742-18746	both	
41-14	18747-18751	data	
41-15	18752-18759	streams	
41-16	18760-18763	are	
41-17	18764-18769	small	
41-18	18770-18776	enough	
41-19	18777-18779	to	
41-20	18780-18783	fit	
41-21	18784-18788	into	
41-22	18789-18795	worker	
41-23	18796-18800	node	
41-24	18801-18807	memory	
41-25	18807-18808	,	
41-26	18809-18812	you	
41-27	18813-18816	can	
41-28	18817-18825	optimize	
41-29	18826-18837	performance	
41-30	18838-18840	by	
41-31	18841-18849	enabling	
41-32	18850-18862	Broadcasting	
41-33	18862-18863	.	
41-34	18864-18876	Broadcasting	
41-35	18877-18879	is	
41-36	18880-18884	when	
41-37	18885-18888	you	
41-38	18889-18893	send	
41-39	18894-18899	small	
41-40	18900-18904	data	
41-41	18905-18911	frames	
41-42	18912-18914	to	
41-43	18915-18918	all	
41-44	18919-18924	nodes	
41-45	18925-18927	in	
41-46	18928-18931	the	
41-47	18932-18939	cluster	
41-48	18939-18940	.	
41-49	18941-18945	This	
41-50	18946-18952	allows	
41-51	18953-18956	for	
41-52	18957-18960	the	
41-53	18961-18966	Spark	
41-54	18967-18973	engine	
41-55	18974-18976	to	
41-56	18977-18984	perform	
41-57	18985-18986	a	
41-58	18987-18991	join	
41-59	18992-18999	without	
41-60	19000-19011	reshuffling	
41-61	19012-19015	the	
41-62	19016-19020	data	
41-63	19021-19023	in	
41-64	19024-19027	the	
41-65	19028-19033	large	
41-66	19034-19040	stream	
41-67	19040-19041	.	
41-68	19042-19044	By	
41-69	19045-19052	default	
41-70	19052-19053	,	
41-71	19054-19057	the	
41-72	19058-19063	Spark	
41-73	19064-19070	engine	
41-74	19071-19075	will	
41-75	19076-19089	automatically	
41-76	19090-19096	decide	
41-77	19097-19104	whether	
41-78	19105-19107	or	
41-79	19108-19111	not	
41-80	19112-19114	to	
41-81	19115-19124	broadcast	
41-82	19125-19128	one	
41-83	19129-19133	side	
41-84	19134-19136	of	
41-85	19137-19138	a	
41-86	19139-19143	join	
41-87	19143-19144	.	
41-88	19145-19147	If	
41-89	19148-19151	you	
41-90	19152-19155	are	
41-91	19156-19164	familiar	
41-92	19165-19169	with	
41-93	19170-19174	your	
41-94	19175-19183	incoming	
41-95	19184-19188	data	
41-96	19189-19192	and	
41-97	19193-19197	know	
41-98	19198-19202	that	
41-99	19203-19206	one	
41-100	19207-19213	stream	
41-101	19214-19218	will	
41-102	19219-19221	be	
41-103	19222-19235	significantly	
41-104	19236-19243	smaller	
41-105	19244-19248	than	
41-106	19249-19252	the	
41-107	19253-19258	other	
41-108	19258-19259	,	
41-109	19260-19263	you	
41-110	19264-19267	can	
41-111	19268-19274	select	
41-112	19275-19280	Fixed	
41-113	19281-19293	broadcasting	
41-114	19293-19294	.	
41-115	19295-19300	Fixed	
41-116	19301-19313	broadcasting	
41-117	19314-19320	forces	
41-118	19321-19326	Spark	
41-119	19327-19329	to	
41-120	19330-19339	broadcast	
41-121	19340-19343	the	
41-122	19344-19352	selected	
41-123	19353-19359	stream	
41-124	19359-19360	.	
41-125	19361-19363	If	
41-126	19364-19367	the	
41-127	19368-19372	size	
41-128	19373-19375	of	
41-129	19376-19379	the	
41-130	19380-19391	broadcasted	
41-131	19392-19396	data	
41-132	19397-19399	is	
41-133	19400-19403	too	
41-134	19404-19409	large	
41-135	19410-19413	for	
41-136	19414-19417	the	
41-137	19418-19423	Spark	
41-138	19424-19428	node	
41-139	19428-19429	,	
41-140	19430-19433	you	
41-141	19434-19437	may	
41-142	19438-19441	get	
41-143	19442-19444	an	
41-144	19445-19448	out	
41-145	19449-19451	of	
41-146	19452-19458	memory	
41-147	19459-19464	error	
41-148	19464-19465	.	
41-149	19466-19468	To	
41-150	19469-19474	avoid	
41-151	19475-19478	out	
41-152	19479-19481	of	
41-153	19482-19488	memory	
41-154	19489-19495	errors	
41-155	19495-19496	,	
41-156	19497-19500	use	
41-157	19501-19507	memory	
41-158	19508-19517	optimized	
41-159	19518-19526	clusters	
41-160	19526-19527	.	
41-161	19528-19530	If	
41-162	19531-19534	you	
41-163	19535-19545	experience	
41-164	19546-19555	broadcast	
41-165	19556-19564	timeouts	
41-166	19565-19571	during	
41-167	19572-19576	data	
41-168	19577-19581	flow	
41-169	19582-19592	executions	
41-170	19592-19593	,	
41-171	19594-19597	you	
41-172	19598-19601	can	
41-173	19602-19608	switch	
41-174	19609-19612	off	
41-175	19613-19616	the	
41-176	19617-19626	broadcast	
41-177	19627-19639	optimization	
41-178	19639-19640	.	
41-179	19641-19648	However	
41-180	19648-19649	,	
41-181	19650-19654	this	
41-182	19655-19659	will	
41-183	19660-19666	result	
41-184	19667-19669	in	
41-185	19670-19676	slower	
41-186	19677-19687	performing	
41-187	19688-19692	data	
41-188	19693-19698	flows	
41-189	19698-19699	.	

#Text=When working with data sources that can take longer to query, like large database queries, it is recommended to turn broadcast off for joins. Source with long query times can cause Spark timeouts when the cluster attempts to broadcast to compute nodes. Another good choice for turning off broadcast is when you have a stream in your data flow that is aggregating values for use in a lookup transformation later. This pattern can confuse the Spark optimizer and cause timeouts. Cross joins If you use literal values in your join conditions or have multiple matches on both sides of a join, Spark will run the join as a cross join. A cross join is a full cartesian product that then filters out the joined values. This is significantly slower than other join types. Ensure that you have column references on both sides of your join conditions to avoid the performance impact.
42-1	19700-19704	When	
42-2	19705-19712	working	
42-3	19713-19717	with	
42-4	19718-19722	data	
42-5	19723-19730	sources	
42-6	19731-19735	that	
42-7	19736-19739	can	
42-8	19740-19744	take	
42-9	19745-19751	longer	
42-10	19752-19754	to	
42-11	19755-19760	query	
42-12	19760-19761	,	
42-13	19762-19766	like	
42-14	19767-19772	large	
42-15	19773-19781	database	
42-16	19782-19789	queries	
42-17	19789-19790	,	
42-18	19791-19793	it	
42-19	19794-19796	is	
42-20	19797-19808	recommended	
42-21	19809-19811	to	
42-22	19812-19816	turn	
42-23	19817-19826	broadcast	
42-24	19827-19830	off	
42-25	19831-19834	for	
42-26	19835-19840	joins	
42-27	19840-19841	.	
42-28	19842-19848	Source	
42-29	19849-19853	with	
42-30	19854-19858	long	
42-31	19859-19864	query	
42-32	19865-19870	times	
42-33	19871-19874	can	
42-34	19875-19880	cause	
42-35	19881-19886	Spark	
42-36	19887-19895	timeouts	
42-37	19896-19900	when	
42-38	19901-19904	the	
42-39	19905-19912	cluster	
42-40	19913-19921	attempts	
42-41	19922-19924	to	
42-42	19925-19934	broadcast	
42-43	19935-19937	to	
42-44	19938-19945	compute	
42-45	19946-19951	nodes	
42-46	19951-19952	.	
42-47	19953-19960	Another	
42-48	19961-19965	good	
42-49	19966-19972	choice	
42-50	19973-19976	for	
42-51	19977-19984	turning	
42-52	19985-19988	off	
42-53	19989-19998	broadcast	
42-54	19999-20001	is	
42-55	20002-20006	when	
42-56	20007-20010	you	
42-57	20011-20015	have	
42-58	20016-20017	a	
42-59	20018-20024	stream	
42-60	20025-20027	in	
42-61	20028-20032	your	
42-62	20033-20037	data	
42-63	20038-20042	flow	
42-64	20043-20047	that	
42-65	20048-20050	is	
42-66	20051-20062	aggregating	
42-67	20063-20069	values	
42-68	20070-20073	for	
42-69	20074-20077	use	
42-70	20078-20080	in	
42-71	20081-20082	a	
42-72	20083-20089	lookup	
42-73	20090-20104	transformation	
42-74	20105-20110	later	
42-75	20110-20111	.	
42-76	20112-20116	This	
42-77	20117-20124	pattern	
42-78	20125-20128	can	
42-79	20129-20136	confuse	
42-80	20137-20140	the	
42-81	20141-20146	Spark	
42-82	20147-20156	optimizer	
42-83	20157-20160	and	
42-84	20161-20166	cause	
42-85	20167-20175	timeouts	
42-86	20175-20176	.	
42-87	20177-20182	Cross	
42-88	20183-20188	joins	
42-89	20189-20191	If	
42-90	20192-20195	you	
42-91	20196-20199	use	
42-92	20200-20207	literal	
42-93	20208-20214	values	
42-94	20215-20217	in	
42-95	20218-20222	your	
42-96	20223-20227	join	
42-97	20228-20238	conditions	
42-98	20239-20241	or	
42-99	20242-20246	have	
42-100	20247-20255	multiple	
42-101	20256-20263	matches	
42-102	20264-20266	on	
42-103	20267-20271	both	
42-104	20272-20277	sides	
42-105	20278-20280	of	
42-106	20281-20282	a	
42-107	20283-20287	join	
42-108	20287-20288	,	
42-109	20289-20294	Spark	
42-110	20295-20299	will	
42-111	20300-20303	run	
42-112	20304-20307	the	
42-113	20308-20312	join	
42-114	20313-20315	as	
42-115	20316-20317	a	
42-116	20318-20323	cross	
42-117	20324-20328	join	
42-118	20328-20329	.	
42-119	20330-20331	A	
42-120	20332-20337	cross	
42-121	20338-20342	join	
42-122	20343-20345	is	
42-123	20346-20347	a	
42-124	20348-20352	full	
42-125	20353-20362	cartesian	
42-126	20363-20370	product	
42-127	20371-20375	that	
42-128	20376-20380	then	
42-129	20381-20388	filters	
42-130	20389-20392	out	
42-131	20393-20396	the	
42-132	20397-20403	joined	
42-133	20404-20410	values	
42-134	20410-20411	.	
42-135	20412-20416	This	
42-136	20417-20419	is	
42-137	20420-20433	significantly	
42-138	20434-20440	slower	
42-139	20441-20445	than	
42-140	20446-20451	other	
42-141	20452-20456	join	
42-142	20457-20462	types	
42-143	20462-20463	.	
42-144	20464-20470	Ensure	
42-145	20471-20475	that	
42-146	20476-20479	you	
42-147	20480-20484	have	
42-148	20485-20491	column	
42-149	20492-20502	references	
42-150	20503-20505	on	
42-151	20506-20510	both	
42-152	20511-20516	sides	
42-153	20517-20519	of	
42-154	20520-20524	your	
42-155	20525-20529	join	
42-156	20530-20540	conditions	
42-157	20541-20543	to	
42-158	20544-20549	avoid	
42-159	20550-20553	the	
42-160	20554-20565	performance	
42-161	20566-20572	impact	
42-162	20572-20573	.	

#Text=Sorting before joins Unlike merge join in tools like SSIS, the join transformation isn't a mandatory merge join operation. The join keys don't require sorting prior to the transformation. The Azure Data Factory team doesn't recommend using Sort transformations in mapping data flows. Window transformation performance
43-1	20574-20581	Sorting	
43-2	20582-20588	before	
43-3	20589-20594	joins	
43-4	20595-20601	Unlike	
43-5	20602-20607	merge	
43-6	20608-20612	join	
43-7	20613-20615	in	
43-8	20616-20621	tools	
43-9	20622-20626	like	
43-10	20627-20631	SSIS	
43-11	20631-20632	,	
43-12	20633-20636	the	
43-13	20637-20641	join	
43-14	20642-20656	transformation	
43-15	20657-20662	isn't	
43-16	20663-20664	a	
43-17	20665-20674	mandatory	
43-18	20675-20680	merge	
43-19	20681-20685	join	
43-20	20686-20695	operation	
43-21	20695-20696	.	
43-22	20697-20700	The	
43-23	20701-20705	join	
43-24	20706-20710	keys	
43-25	20711-20716	don't	
43-26	20717-20724	require	
43-27	20725-20732	sorting	
43-28	20733-20738	prior	
43-29	20739-20741	to	
43-30	20742-20745	the	
43-31	20746-20760	transformation	
43-32	20760-20761	.	
43-33	20762-20765	The	
43-34	20766-20771	Azure	
43-35	20772-20776	Data	
43-36	20777-20784	Factory	
43-37	20785-20789	team	
43-38	20790-20797	doesn't	
43-39	20798-20807	recommend	
43-40	20808-20813	using	
43-41	20814-20818	Sort	
43-42	20819-20834	transformations	
43-43	20835-20837	in	
43-44	20838-20845	mapping	
43-45	20846-20850	data	
43-46	20851-20856	flows	
43-47	20856-20857	.	
43-48	20858-20864	Window	
43-49	20865-20879	transformation	
43-50	20880-20891	performance	

#Text=The Window transformation partitions your data by value in columns that you select as part of the over() clause in the transformation settings. There are a number of very popular aggregate and analytical functions that are exposed in the Windows transformation. However, if your use case is to generate a window over your entire dataset for the purpose of ranking rank() or row number rowNumber(), it is recommended that you instead use the Rank transformation and the Surrogate Key transformation. Those transformation will perform better again full dataset operations using those functions. Repartitioning skewed data Certain transformations such as joins and aggregates reshuffle your data partitions and can occasionally lead to skewed data. Skewed data means that data is not evenly distributed across the partitions. Heavily skewed data can lead to slower downstream transformations and sink writes. You can check the skewness of your data at any point in a data flow run by clicking on the transformation in the monitoring display.
44-1	20892-20895	The	
44-2	20896-20902	Window	
44-3	20903-20917	transformation	
44-4	20918-20928	partitions	
44-5	20929-20933	your	
44-6	20934-20938	data	
44-7	20939-20941	by	
44-8	20942-20947	value	
44-9	20948-20950	in	
44-10	20951-20958	columns	
44-11	20959-20963	that	
44-12	20964-20967	you	
44-13	20968-20974	select	
44-14	20975-20977	as	
44-15	20978-20982	part	
44-16	20983-20985	of	
44-17	20986-20989	the	
44-18	20990-20994	over	
44-19	20994-20995	(	
44-20	20995-20996	)	
44-21	20997-21003	clause	
44-22	21004-21006	in	
44-23	21007-21010	the	
44-24	21011-21025	transformation	
44-25	21026-21034	settings	
44-26	21034-21035	.	
44-27	21036-21041	There	
44-28	21042-21045	are	
44-29	21046-21047	a	
44-30	21048-21054	number	
44-31	21055-21057	of	
44-32	21058-21062	very	
44-33	21063-21070	popular	
44-34	21071-21080	aggregate	
44-35	21081-21084	and	
44-36	21085-21095	analytical	
44-37	21096-21105	functions	
44-38	21106-21110	that	
44-39	21111-21114	are	
44-40	21115-21122	exposed	
44-41	21123-21125	in	
44-42	21126-21129	the	
44-43	21130-21137	Windows	
44-44	21138-21152	transformation	
44-45	21152-21153	.	
44-46	21154-21161	However	
44-47	21161-21162	,	
44-48	21163-21165	if	
44-49	21166-21170	your	
44-50	21171-21174	use	
44-51	21175-21179	case	
44-52	21180-21182	is	
44-53	21183-21185	to	
44-54	21186-21194	generate	
44-55	21195-21196	a	
44-56	21197-21203	window	
44-57	21204-21208	over	
44-58	21209-21213	your	
44-59	21214-21220	entire	
44-60	21221-21228	dataset	
44-61	21229-21232	for	
44-62	21233-21236	the	
44-63	21237-21244	purpose	
44-64	21245-21247	of	
44-65	21248-21255	ranking	
44-66	21256-21260	rank	
44-67	21260-21261	(	
44-68	21261-21262	)	
44-69	21263-21265	or	
44-70	21266-21269	row	
44-71	21270-21276	number	
44-72	21277-21286	rowNumber	
44-73	21286-21287	(	
44-74	21287-21288	)	
44-75	21288-21289	,	
44-76	21290-21292	it	
44-77	21293-21295	is	
44-78	21296-21307	recommended	
44-79	21308-21312	that	
44-80	21313-21316	you	
44-81	21317-21324	instead	
44-82	21325-21328	use	
44-83	21329-21332	the	
44-84	21333-21337	Rank	
44-85	21338-21352	transformation	
44-86	21353-21356	and	
44-87	21357-21360	the	
44-88	21361-21370	Surrogate	
44-89	21371-21374	Key	
44-90	21375-21389	transformation	
44-91	21389-21390	.	
44-92	21391-21396	Those	
44-93	21397-21411	transformation	
44-94	21412-21416	will	
44-95	21417-21424	perform	
44-96	21425-21431	better	
44-97	21432-21437	again	
44-98	21438-21442	full	
44-99	21443-21450	dataset	
44-100	21451-21461	operations	
44-101	21462-21467	using	
44-102	21468-21473	those	
44-103	21474-21483	functions	
44-104	21483-21484	.	
44-105	21485-21499	Repartitioning	
44-106	21500-21506	skewed	
44-107	21507-21511	data	
44-108	21512-21519	Certain	
44-109	21520-21535	transformations	
44-110	21536-21540	such	
44-111	21541-21543	as	
44-112	21544-21549	joins	
44-113	21550-21553	and	
44-114	21554-21564	aggregates	
44-115	21565-21574	reshuffle	
44-116	21575-21579	your	
44-117	21580-21584	data	
44-118	21585-21595	partitions	
44-119	21596-21599	and	
44-120	21600-21603	can	
44-121	21604-21616	occasionally	
44-122	21617-21621	lead	
44-123	21622-21624	to	
44-124	21625-21631	skewed	
44-125	21632-21636	data	
44-126	21636-21637	.	
44-127	21638-21644	Skewed	
44-128	21645-21649	data	
44-129	21650-21655	means	
44-130	21656-21660	that	
44-131	21661-21665	data	
44-132	21666-21668	is	
44-133	21669-21672	not	
44-134	21673-21679	evenly	
44-135	21680-21691	distributed	
44-136	21692-21698	across	
44-137	21699-21702	the	
44-138	21703-21713	partitions	
44-139	21713-21714	.	
44-140	21715-21722	Heavily	
44-141	21723-21729	skewed	
44-142	21730-21734	data	
44-143	21735-21738	can	
44-144	21739-21743	lead	
44-145	21744-21746	to	
44-146	21747-21753	slower	
44-147	21754-21764	downstream	
44-148	21765-21780	transformations	
44-149	21781-21784	and	
44-150	21785-21789	sink	
44-151	21790-21796	writes	
44-152	21796-21797	.	
44-153	21798-21801	You	
44-154	21802-21805	can	
44-155	21806-21811	check	
44-156	21812-21815	the	
44-157	21816-21824	skewness	
44-158	21825-21827	of	
44-159	21828-21832	your	
44-160	21833-21837	data	
44-161	21838-21840	at	
44-162	21841-21844	any	
44-163	21845-21850	point	
44-164	21851-21853	in	
44-165	21854-21855	a	
44-166	21856-21860	data	
44-167	21861-21865	flow	
44-168	21866-21869	run	
44-169	21870-21872	by	
44-170	21873-21881	clicking	
44-171	21882-21884	on	
44-172	21885-21888	the	
44-173	21889-21903	transformation	
44-174	21904-21906	in	
44-175	21907-21910	the	
44-176	21911-21921	monitoring	
44-177	21922-21929	display	
44-178	21929-21930	.	

#Text=The monitoring display will show how the data is distributed across each partition along with two metrics, skewness and kurtosis. Skewness is a measure of how asymmetrical the data is and can have a positive, zero, negative, or undefined value. Negative skew means the left tail is longer than the right. Kurtosis is the measure of whether the data is heavy-tailed or light-tailed. High kurtosis values are not desirable. Ideal ranges of skewness lie between -3 and 3 and ranges of kurtosis are less than 10. An easy way to interpret these numbers is looking at the partition chart and seeing if 1 bar is significantly larger than the rest. If your data is not evenly partitioned after a transformation, you can use the optimize tab to repartition. Reshuffling data takes time and may not improve your data flow performance. Tip
45-1	21931-21934	The	
45-2	21935-21945	monitoring	
45-3	21946-21953	display	
45-4	21954-21958	will	
45-5	21959-21963	show	
45-6	21964-21967	how	
45-7	21968-21971	the	
45-8	21972-21976	data	
45-9	21977-21979	is	
45-10	21980-21991	distributed	
45-11	21992-21998	across	
45-12	21999-22003	each	
45-13	22004-22013	partition	
45-14	22014-22019	along	
45-15	22020-22024	with	
45-16	22025-22028	two	
45-17	22029-22036	metrics	
45-18	22036-22037	,	
45-19	22038-22046	skewness	
45-20	22047-22050	and	
45-21	22051-22059	kurtosis	
45-22	22059-22060	.	
45-23	22061-22069	Skewness	
45-24	22070-22072	is	
45-25	22073-22074	a	
45-26	22075-22082	measure	
45-27	22083-22085	of	
45-28	22086-22089	how	
45-29	22090-22102	asymmetrical	
45-30	22103-22106	the	
45-31	22107-22111	data	
45-32	22112-22114	is	
45-33	22115-22118	and	
45-34	22119-22122	can	
45-35	22123-22127	have	
45-36	22128-22129	a	
45-37	22130-22138	positive	
45-38	22138-22139	,	
45-39	22140-22144	zero	
45-40	22144-22145	,	
45-41	22146-22154	negative	
45-42	22154-22155	,	
45-43	22156-22158	or	
45-44	22159-22168	undefined	
45-45	22169-22174	value	
45-46	22174-22175	.	
45-47	22176-22184	Negative	
45-48	22185-22189	skew	
45-49	22190-22195	means	
45-50	22196-22199	the	
45-51	22200-22204	left	
45-52	22205-22209	tail	
45-53	22210-22212	is	
45-54	22213-22219	longer	
45-55	22220-22224	than	
45-56	22225-22228	the	
45-57	22229-22234	right	
45-58	22234-22235	.	
45-59	22236-22244	Kurtosis	
45-60	22245-22247	is	
45-61	22248-22251	the	
45-62	22252-22259	measure	
45-63	22260-22262	of	
45-64	22263-22270	whether	
45-65	22271-22274	the	
45-66	22275-22279	data	
45-67	22280-22282	is	
45-68	22283-22295	heavy-tailed	
45-69	22296-22298	or	
45-70	22299-22311	light-tailed	
45-71	22311-22312	.	
45-72	22313-22317	High	
45-73	22318-22326	kurtosis	
45-74	22327-22333	values	
45-75	22334-22337	are	
45-76	22338-22341	not	
45-77	22342-22351	desirable	
45-78	22351-22352	.	
45-79	22353-22358	Ideal	
45-80	22359-22365	ranges	
45-81	22366-22368	of	
45-82	22369-22377	skewness	
45-83	22378-22381	lie	
45-84	22382-22389	between	
45-85	22390-22391	-	
45-86	22391-22392	3	
45-87	22393-22396	and	
45-88	22397-22398	3	
45-89	22399-22402	and	
45-90	22403-22409	ranges	
45-91	22410-22412	of	
45-92	22413-22421	kurtosis	
45-93	22422-22425	are	
45-94	22426-22430	less	
45-95	22431-22435	than	
45-96	22436-22438	10	
45-97	22438-22439	.	
45-98	22440-22442	An	
45-99	22443-22447	easy	
45-100	22448-22451	way	
45-101	22452-22454	to	
45-102	22455-22464	interpret	
45-103	22465-22470	these	
45-104	22471-22478	numbers	
45-105	22479-22481	is	
45-106	22482-22489	looking	
45-107	22490-22492	at	
45-108	22493-22496	the	
45-109	22497-22506	partition	
45-110	22507-22512	chart	
45-111	22513-22516	and	
45-112	22517-22523	seeing	
45-113	22524-22526	if	
45-114	22527-22528	1	
45-115	22529-22532	bar	
45-116	22533-22535	is	
45-117	22536-22549	significantly	
45-118	22550-22556	larger	
45-119	22557-22561	than	
45-120	22562-22565	the	
45-121	22566-22570	rest	
45-122	22570-22571	.	
45-123	22572-22574	If	
45-124	22575-22579	your	
45-125	22580-22584	data	
45-126	22585-22587	is	
45-127	22588-22591	not	
45-128	22592-22598	evenly	
45-129	22599-22610	partitioned	
45-130	22611-22616	after	
45-131	22617-22618	a	
45-132	22619-22633	transformation	
45-133	22633-22634	,	
45-134	22635-22638	you	
45-135	22639-22642	can	
45-136	22643-22646	use	
45-137	22647-22650	the	
45-138	22651-22659	optimize	
45-139	22660-22663	tab	
45-140	22664-22666	to	
45-141	22667-22678	repartition	
45-142	22678-22679	.	
45-143	22680-22691	Reshuffling	
45-144	22692-22696	data	
45-145	22697-22702	takes	
45-146	22703-22707	time	
45-147	22708-22711	and	
45-148	22712-22715	may	
45-149	22716-22719	not	
45-150	22720-22727	improve	
45-151	22728-22732	your	
45-152	22733-22737	data	
45-153	22738-22742	flow	
45-154	22743-22754	performance	
45-155	22754-22755	.	
45-156	22756-22759	Tip	

#Text=If you repartition your data, but have downstream transformations that reshuffle your data, use hash partitioning on a column used as a join key. Using data flows in pipelines When building complex pipelines with multiple data flows, your logical flow can have a big impact on timing and cost. This section covers the impact of different architecture strategies. Executing data flows in parallel
46-1	22760-22762	If	
46-2	22763-22766	you	
46-3	22767-22778	repartition	
46-4	22779-22783	your	
46-5	22784-22788	data	
46-6	22788-22789	,	
46-7	22790-22793	but	
46-8	22794-22798	have	
46-9	22799-22809	downstream	
46-10	22810-22825	transformations	
46-11	22826-22830	that	
46-12	22831-22840	reshuffle	
46-13	22841-22845	your	
46-14	22846-22850	data	
46-15	22850-22851	,	
46-16	22852-22855	use	
46-17	22856-22860	hash	
46-18	22861-22873	partitioning	
46-19	22874-22876	on	
46-20	22877-22878	a	
46-21	22879-22885	column	
46-22	22886-22890	used	
46-23	22891-22893	as	
46-24	22894-22895	a	
46-25	22896-22900	join	
46-26	22901-22904	key	
46-27	22904-22905	.	
46-28	22906-22911	Using	
46-29	22912-22916	data	
46-30	22917-22922	flows	
46-31	22923-22925	in	
46-32	22926-22935	pipelines	
46-33	22936-22940	When	
46-34	22941-22949	building	
46-35	22950-22957	complex	
46-36	22958-22967	pipelines	
46-37	22968-22972	with	
46-38	22973-22981	multiple	
46-39	22982-22986	data	
46-40	22987-22992	flows	
46-41	22992-22993	,	
46-42	22994-22998	your	
46-43	22999-23006	logical	
46-44	23007-23011	flow	
46-45	23012-23015	can	
46-46	23016-23020	have	
46-47	23021-23022	a	
46-48	23023-23026	big	
46-49	23027-23033	impact	
46-50	23034-23036	on	
46-51	23037-23043	timing	
46-52	23044-23047	and	
46-53	23048-23052	cost	
46-54	23052-23053	.	
46-55	23054-23058	This	
46-56	23059-23066	section	
46-57	23067-23073	covers	
46-58	23074-23077	the	
46-59	23078-23084	impact	
46-60	23085-23087	of	
46-61	23088-23097	different	
46-62	23098-23110	architecture	
46-63	23111-23121	strategies	
46-64	23121-23122	.	
46-65	23123-23132	Executing	
46-66	23133-23137	data	
46-67	23138-23143	flows	
46-68	23144-23146	in	
46-69	23147-23155	parallel	

#Text=If you execute multiple data flows in parallel, ADF spins up separate Spark clusters for each activity. This allows for each job to be isolated and run in parallel, but will lead to multiple clusters running at the same time. If your data flows execute in parallel, its recommended to not enable the Azure IR time to live property as it will lead to multiple unused warm pools. Tip Instead of running the same data flow multiple times in a for each activity, stage your data in a data lake and use wildcard paths to process the data in a single data flow.
47-1	23156-23158	If	
47-2	23159-23162	you	
47-3	23163-23170	execute	
47-4	23171-23179	multiple	
47-5	23180-23184	data	
47-6	23185-23190	flows	
47-7	23191-23193	in	
47-8	23194-23202	parallel	
47-9	23202-23203	,	
47-10	23204-23207	ADF	
47-11	23208-23213	spins	
47-12	23214-23216	up	
47-13	23217-23225	separate	
47-14	23226-23231	Spark	
47-15	23232-23240	clusters	
47-16	23241-23244	for	
47-17	23245-23249	each	
47-18	23250-23258	activity	
47-19	23258-23259	.	
47-20	23260-23264	This	
47-21	23265-23271	allows	
47-22	23272-23275	for	
47-23	23276-23280	each	
47-24	23281-23284	job	
47-25	23285-23287	to	
47-26	23288-23290	be	
47-27	23291-23299	isolated	
47-28	23300-23303	and	
47-29	23304-23307	run	
47-30	23308-23310	in	
47-31	23311-23319	parallel	
47-32	23319-23320	,	
47-33	23321-23324	but	
47-34	23325-23329	will	
47-35	23330-23334	lead	
47-36	23335-23337	to	
47-37	23338-23346	multiple	
47-38	23347-23355	clusters	
47-39	23356-23363	running	
47-40	23364-23366	at	
47-41	23367-23370	the	
47-42	23371-23375	same	
47-43	23376-23380	time	
47-44	23380-23381	.	
47-45	23382-23384	If	
47-46	23385-23389	your	
47-47	23390-23394	data	
47-48	23395-23400	flows	
47-49	23401-23408	execute	
47-50	23409-23411	in	
47-51	23412-23420	parallel	
47-52	23420-23421	,	
47-53	23422-23425	its	
47-54	23426-23437	recommended	
47-55	23438-23440	to	
47-56	23441-23444	not	
47-57	23445-23451	enable	
47-58	23452-23455	the	
47-59	23456-23461	Azure	
47-60	23462-23464	IR	
47-61	23465-23469	time	
47-62	23470-23472	to	
47-63	23473-23477	live	
47-64	23478-23486	property	
47-65	23487-23489	as	
47-66	23490-23492	it	
47-67	23493-23497	will	
47-68	23498-23502	lead	
47-69	23503-23505	to	
47-70	23506-23514	multiple	
47-71	23515-23521	unused	
47-72	23522-23526	warm	
47-73	23527-23532	pools	
47-74	23532-23533	.	
47-75	23534-23537	Tip	
47-76	23538-23545	Instead	
47-77	23546-23548	of	
47-78	23549-23556	running	
47-79	23557-23560	the	
47-80	23561-23565	same	
47-81	23566-23570	data	
47-82	23571-23575	flow	
47-83	23576-23584	multiple	
47-84	23585-23590	times	
47-85	23591-23593	in	
47-86	23594-23595	a	
47-87	23596-23599	for	
47-88	23600-23604	each	
47-89	23605-23613	activity	
47-90	23613-23614	,	
47-91	23615-23620	stage	
47-92	23621-23625	your	
47-93	23626-23630	data	
47-94	23631-23633	in	
47-95	23634-23635	a	
47-96	23636-23640	data	
47-97	23641-23645	lake	
47-98	23646-23649	and	
47-99	23650-23653	use	
47-100	23654-23662	wildcard	
47-101	23663-23668	paths	
47-102	23669-23671	to	
47-103	23672-23679	process	
47-104	23680-23683	the	
47-105	23684-23688	data	
47-106	23689-23691	in	
47-107	23692-23693	a	
47-108	23694-23700	single	
47-109	23701-23705	data	
47-110	23706-23710	flow	
47-111	23710-23711	.	

#Text=Execute data flows sequentially If you execute your data flow activities in sequence, it is recommended that you set a TTL in the Azure IR configuration. ADF will reuse the compute resources resulting in a faster cluster start up time. Each activity will still be isolated receive a new Spark context for each execution.
48-1	23712-23719	Execute	
48-2	23720-23724	data	
48-3	23725-23730	flows	
48-4	23731-23743	sequentially	
48-5	23744-23746	If	
48-6	23747-23750	you	
48-7	23751-23758	execute	
48-8	23759-23763	your	
48-9	23764-23768	data	
48-10	23769-23773	flow	
48-11	23774-23784	activities	
48-12	23785-23787	in	
48-13	23788-23796	sequence	
48-14	23796-23797	,	
48-15	23798-23800	it	
48-16	23801-23803	is	
48-17	23804-23815	recommended	
48-18	23816-23820	that	
48-19	23821-23824	you	
48-20	23825-23828	set	
48-21	23829-23830	a	
48-22	23831-23834	TTL	
48-23	23835-23837	in	
48-24	23838-23841	the	
48-25	23842-23847	Azure	
48-26	23848-23850	IR	
48-27	23851-23864	configuration	
48-28	23864-23865	.	
48-29	23866-23869	ADF	
48-30	23870-23874	will	
48-31	23875-23880	reuse	
48-32	23881-23884	the	
48-33	23885-23892	compute	
48-34	23893-23902	resources	
48-35	23903-23912	resulting	
48-36	23913-23915	in	
48-37	23916-23917	a	
48-38	23918-23924	faster	
48-39	23925-23932	cluster	
48-40	23933-23938	start	
48-41	23939-23941	up	
48-42	23942-23946	time	
48-43	23946-23947	.	
48-44	23948-23952	Each	
48-45	23953-23961	activity	
48-46	23962-23966	will	
48-47	23967-23972	still	
48-48	23973-23975	be	
48-49	23976-23984	isolated	
48-50	23985-23992	receive	
48-51	23993-23994	a	
48-52	23995-23998	new	
48-53	23999-24004	Spark	
48-54	24005-24012	context	
48-55	24013-24016	for	
48-56	24017-24021	each	
48-57	24022-24031	execution	
48-58	24031-24032	.	

#Text=Running jobs sequentially will likely take the longest time to execute end-to-end, but provides a clean separation of logical operations. Overloading a single data flow
49-1	24033-24040	Running	
49-2	24041-24045	jobs	
49-3	24046-24058	sequentially	
49-4	24059-24063	will	
49-5	24064-24070	likely	
49-6	24071-24075	take	
49-7	24076-24079	the	
49-8	24080-24087	longest	
49-9	24088-24092	time	
49-10	24093-24095	to	
49-11	24096-24103	execute	
49-12	24104-24114	end-to-end	
49-13	24114-24115	,	
49-14	24116-24119	but	
49-15	24120-24128	provides	
49-16	24129-24130	a	
49-17	24131-24136	clean	
49-18	24137-24147	separation	
49-19	24148-24150	of	
49-20	24151-24158	logical	
49-21	24159-24169	operations	
49-22	24169-24170	.	
49-23	24171-24182	Overloading	
49-24	24183-24184	a	
49-25	24185-24191	single	
49-26	24192-24196	data	
49-27	24197-24201	flow	

#Text=If you put all of your logic inside of a single data flow, ADF will execute the entire job on a single Spark instance. While this may seem like a way to reduce costs, it mixes together different logical flows and can be difficult to monitor and debug. If one component fails, all other parts of the job will fail as well. The Azure Data Factory team recommends organizing data flows by independent flows of business logic. If your data flow becomes too large, splitting it into separates components will make monitoring and debugging easier. While there is no hard limit on the number of transformations in a data flow, having too many will make the job complex. Execute sinks in parallel The default behavior of data flow sinks is to execute each sink sequentially, in a serial manner, and to fail the data flow when an error is encountered in the sink. Additionally, all sinks are defaulted to the same group unless you go into the data flow properties and set different priorities for the sinks.
50-1	24202-24204	If	
50-2	24205-24208	you	
50-3	24209-24212	put	
50-4	24213-24216	all	
50-5	24217-24219	of	
50-6	24220-24224	your	
50-7	24225-24230	logic	
50-8	24231-24237	inside	
50-9	24238-24240	of	
50-10	24241-24242	a	
50-11	24243-24249	single	
50-12	24250-24254	data	
50-13	24255-24259	flow	
50-14	24259-24260	,	
50-15	24261-24264	ADF	
50-16	24265-24269	will	
50-17	24270-24277	execute	
50-18	24278-24281	the	
50-19	24282-24288	entire	
50-20	24289-24292	job	
50-21	24293-24295	on	
50-22	24296-24297	a	
50-23	24298-24304	single	
50-24	24305-24310	Spark	
50-25	24311-24319	instance	
50-26	24319-24320	.	
50-27	24321-24326	While	
50-28	24327-24331	this	
50-29	24332-24335	may	
50-30	24336-24340	seem	
50-31	24341-24345	like	
50-32	24346-24347	a	
50-33	24348-24351	way	
50-34	24352-24354	to	
50-35	24355-24361	reduce	
50-36	24362-24367	costs	
50-37	24367-24368	,	
50-38	24369-24371	it	
50-39	24372-24377	mixes	
50-40	24378-24386	together	
50-41	24387-24396	different	
50-42	24397-24404	logical	
50-43	24405-24410	flows	
50-44	24411-24414	and	
50-45	24415-24418	can	
50-46	24419-24421	be	
50-47	24422-24431	difficult	
50-48	24432-24434	to	
50-49	24435-24442	monitor	
50-50	24443-24446	and	
50-51	24447-24452	debug	
50-52	24452-24453	.	
50-53	24454-24456	If	
50-54	24457-24460	one	
50-55	24461-24470	component	
50-56	24471-24476	fails	
50-57	24476-24477	,	
50-58	24478-24481	all	
50-59	24482-24487	other	
50-60	24488-24493	parts	
50-61	24494-24496	of	
50-62	24497-24500	the	
50-63	24501-24504	job	
50-64	24505-24509	will	
50-65	24510-24514	fail	
50-66	24515-24517	as	
50-67	24518-24522	well	
50-68	24522-24523	.	
50-69	24524-24527	The	
50-70	24528-24533	Azure	
50-71	24534-24538	Data	
50-72	24539-24546	Factory	
50-73	24547-24551	team	
50-74	24552-24562	recommends	
50-75	24563-24573	organizing	
50-76	24574-24578	data	
50-77	24579-24584	flows	
50-78	24585-24587	by	
50-79	24588-24599	independent	
50-80	24600-24605	flows	
50-81	24606-24608	of	
50-82	24609-24617	business	
50-83	24618-24623	logic	
50-84	24623-24624	.	
50-85	24625-24627	If	
50-86	24628-24632	your	
50-87	24633-24637	data	
50-88	24638-24642	flow	
50-89	24643-24650	becomes	
50-90	24651-24654	too	
50-91	24655-24660	large	
50-92	24660-24661	,	
50-93	24662-24671	splitting	
50-94	24672-24674	it	
50-95	24675-24679	into	
50-96	24680-24689	separates	
50-97	24690-24700	components	
50-98	24701-24705	will	
50-99	24706-24710	make	
50-100	24711-24721	monitoring	
50-101	24722-24725	and	
50-102	24726-24735	debugging	
50-103	24736-24742	easier	
50-104	24742-24743	.	
50-105	24744-24749	While	
50-106	24750-24755	there	
50-107	24756-24758	is	
50-108	24759-24761	no	
50-109	24762-24766	hard	
50-110	24767-24772	limit	
50-111	24773-24775	on	
50-112	24776-24779	the	
50-113	24780-24786	number	
50-114	24787-24789	of	
50-115	24790-24805	transformations	
50-116	24806-24808	in	
50-117	24809-24810	a	
50-118	24811-24815	data	
50-119	24816-24820	flow	
50-120	24820-24821	,	
50-121	24822-24828	having	
50-122	24829-24832	too	
50-123	24833-24837	many	
50-124	24838-24842	will	
50-125	24843-24847	make	
50-126	24848-24851	the	
50-127	24852-24855	job	
50-128	24856-24863	complex	
50-129	24863-24864	.	
50-130	24865-24872	Execute	
50-131	24873-24878	sinks	
50-132	24879-24881	in	
50-133	24882-24890	parallel	
50-134	24891-24894	The	
50-135	24895-24902	default	
50-136	24903-24911	behavior	
50-137	24912-24914	of	
50-138	24915-24919	data	
50-139	24920-24924	flow	
50-140	24925-24930	sinks	
50-141	24931-24933	is	
50-142	24934-24936	to	
50-143	24937-24944	execute	
50-144	24945-24949	each	
50-145	24950-24954	sink	
50-146	24955-24967	sequentially	
50-147	24967-24968	,	
50-148	24969-24971	in	
50-149	24972-24973	a	
50-150	24974-24980	serial	
50-151	24981-24987	manner	
50-152	24987-24988	,	
50-153	24989-24992	and	
50-154	24993-24995	to	
50-155	24996-25000	fail	
50-156	25001-25004	the	
50-157	25005-25009	data	
50-158	25010-25014	flow	
50-159	25015-25019	when	
50-160	25020-25022	an	
50-161	25023-25028	error	
50-162	25029-25031	is	
50-163	25032-25043	encountered	
50-164	25044-25046	in	
50-165	25047-25050	the	
50-166	25051-25055	sink	
50-167	25055-25056	.	
50-168	25057-25069	Additionally	
50-169	25069-25070	,	
50-170	25071-25074	all	
50-171	25075-25080	sinks	
50-172	25081-25084	are	
50-173	25085-25094	defaulted	
50-174	25095-25097	to	
50-175	25098-25101	the	
50-176	25102-25106	same	
50-177	25107-25112	group	
50-178	25113-25119	unless	
50-179	25120-25123	you	
50-180	25124-25126	go	
50-181	25127-25131	into	
50-182	25132-25135	the	
50-183	25136-25140	data	
50-184	25141-25145	flow	
50-185	25146-25156	properties	
50-186	25157-25160	and	
50-187	25161-25164	set	
50-188	25165-25174	different	
50-189	25175-25185	priorities	
50-190	25186-25189	for	
50-191	25190-25193	the	
50-192	25194-25199	sinks	
50-193	25199-25200	.	

#Text=Data flows allow you to group sinks together into groups from the data flow properties tab in the UI designer. You can both set the order of execution of your sinks as well as to group sinks together using the same group number. To help manage groups, you can ask ADF to run sinks in the same group, to run in parallel. On the pipeline execute data flow activity under the "Sink Properties" section is an option to turn on parallel sink loading. When you enable "run in parallel", you are instructing data flows write to connected sinks at the same time rather than in a sequential manner. In order to utilize the parallel option, the sinks must be group together and connected to the same stream via a New Branch or Conditional Split.
51-1	25201-25205	Data	
51-2	25206-25211	flows	
51-3	25212-25217	allow	
51-4	25218-25221	you	
51-5	25222-25224	to	
51-6	25225-25230	group	
51-7	25231-25236	sinks	
51-8	25237-25245	together	
51-9	25246-25250	into	
51-10	25251-25257	groups	
51-11	25258-25262	from	
51-12	25263-25266	the	
51-13	25267-25271	data	
51-14	25272-25276	flow	
51-15	25277-25287	properties	
51-16	25288-25291	tab	
51-17	25292-25294	in	
51-18	25295-25298	the	
51-19	25299-25301	UI	
51-20	25302-25310	designer	
51-21	25310-25311	.	
51-22	25312-25315	You	
51-23	25316-25319	can	
51-24	25320-25324	both	
51-25	25325-25328	set	
51-26	25329-25332	the	
51-27	25333-25338	order	
51-28	25339-25341	of	
51-29	25342-25351	execution	
51-30	25352-25354	of	
51-31	25355-25359	your	
51-32	25360-25365	sinks	
51-33	25366-25368	as	
51-34	25369-25373	well	
51-35	25374-25376	as	
51-36	25377-25379	to	
51-37	25380-25385	group	
51-38	25386-25391	sinks	
51-39	25392-25400	together	
51-40	25401-25406	using	
51-41	25407-25410	the	
51-42	25411-25415	same	
51-43	25416-25421	group	
51-44	25422-25428	number	
51-45	25428-25429	.	
51-46	25430-25432	To	
51-47	25433-25437	help	
51-48	25438-25444	manage	
51-49	25445-25451	groups	
51-50	25451-25452	,	
51-51	25453-25456	you	
51-52	25457-25460	can	
51-53	25461-25464	ask	
51-54	25465-25468	ADF	
51-55	25469-25471	to	
51-56	25472-25475	run	
51-57	25476-25481	sinks	
51-58	25482-25484	in	
51-59	25485-25488	the	
51-60	25489-25493	same	
51-61	25494-25499	group	
51-62	25499-25500	,	
51-63	25501-25503	to	
51-64	25504-25507	run	
51-65	25508-25510	in	
51-66	25511-25519	parallel	
51-67	25519-25520	.	
51-68	25521-25523	On	
51-69	25524-25527	the	
51-70	25528-25536	pipeline	
51-71	25537-25544	execute	
51-72	25545-25549	data	
51-73	25550-25554	flow	
51-74	25555-25563	activity	
51-75	25564-25569	under	
51-76	25570-25573	the	
51-77	25574-25575	"	
51-78	25575-25579	Sink	
51-79	25580-25590	Properties	
51-80	25590-25591	"	
51-81	25592-25599	section	
51-82	25600-25602	is	
51-83	25603-25605	an	
51-84	25606-25612	option	
51-85	25613-25615	to	
51-86	25616-25620	turn	
51-87	25621-25623	on	
51-88	25624-25632	parallel	
51-89	25633-25637	sink	
51-90	25638-25645	loading	
51-91	25645-25646	.	
51-92	25647-25651	When	
51-93	25652-25655	you	
51-94	25656-25662	enable	
51-95	25663-25664	"	
51-96	25664-25667	run	
51-97	25668-25670	in	
51-98	25671-25679	parallel	
51-99	25679-25680	"	
51-100	25680-25681	,	
51-101	25682-25685	you	
51-102	25686-25689	are	
51-103	25690-25701	instructing	
51-104	25702-25706	data	
51-105	25707-25712	flows	
51-106	25713-25718	write	
51-107	25719-25721	to	
51-108	25722-25731	connected	
51-109	25732-25737	sinks	
51-110	25738-25740	at	
51-111	25741-25744	the	
51-112	25745-25749	same	
51-113	25750-25754	time	
51-114	25755-25761	rather	
51-115	25762-25766	than	
51-116	25767-25769	in	
51-117	25770-25771	a	
51-118	25772-25782	sequential	
51-119	25783-25789	manner	
51-120	25789-25790	.	
51-121	25791-25793	In	
51-122	25794-25799	order	
51-123	25800-25802	to	
51-124	25803-25810	utilize	
51-125	25811-25814	the	
51-126	25815-25823	parallel	
51-127	25824-25830	option	
51-128	25830-25831	,	
51-129	25832-25835	the	
51-130	25836-25841	sinks	
51-131	25842-25846	must	
51-132	25847-25849	be	
51-133	25850-25855	group	
51-134	25856-25864	together	
51-135	25865-25868	and	
51-136	25869-25878	connected	
51-137	25879-25881	to	
51-138	25882-25885	the	
51-139	25886-25890	same	
51-140	25891-25897	stream	
51-141	25898-25901	via	
51-142	25902-25903	a	
51-143	25904-25907	New	
51-144	25908-25914	Branch	
51-145	25915-25917	or	
51-146	25918-25929	Conditional	
51-147	25930-25935	Split	
51-148	25935-25936	.	

#Text=Next steps See other Data Flow articles related to performance: Data Flow activity Monitor Data Flow performance Is this page helpful? Yes Any additional feedback? Skip Submit Thank you. Feedback Submit and view feedback for
52-1	25937-25941	Next	
52-2	25942-25947	steps	
52-3	25948-25951	See	
52-4	25952-25957	other	
52-5	25958-25962	Data	
52-6	25963-25967	Flow	
52-7	25968-25976	articles	
52-8	25977-25984	related	
52-9	25985-25987	to	
52-10	25988-25999	performance	
52-11	25999-26000	:	
52-12	26001-26005	Data	
52-13	26006-26010	Flow	
52-14	26011-26019	activity	
52-15	26020-26027	Monitor	
52-16	26028-26032	Data	
52-17	26033-26037	Flow	
52-18	26038-26049	performance	
52-19	26050-26052	Is	
52-20	26053-26057	this	
52-21	26058-26062	page	
52-22	26063-26070	helpful	
52-23	26070-26071	?	
52-24	26072-26075	Yes	
52-25	26076-26079	Any	
52-26	26080-26090	additional	
52-27	26091-26099	feedback	
52-28	26099-26100	?	
52-29	26101-26105	Skip	
52-30	26106-26112	Submit	
52-31	26113-26118	Thank	
52-32	26119-26122	you	
52-33	26122-26123	.	
52-34	26124-26132	Feedback	
52-35	26133-26139	Submit	
52-36	26140-26143	and	
52-37	26144-26148	view	
52-38	26149-26157	feedback	
52-39	26158-26161	for	

#Text=This product This page View all page feedback Theme Light Dark High contrast Previous Version Docs Blog Contribute Privacy & Cookies Terms of Use Trademarks © Microsoft 2021
53-1	26162-26166	This	
53-2	26167-26174	product	
53-3	26175-26179	This	
53-4	26180-26184	page	
53-5	26185-26189	View	
53-6	26190-26193	all	
53-7	26194-26198	page	
53-8	26199-26207	feedback	
53-9	26208-26213	Theme	
53-10	26214-26219	Light	
53-11	26220-26224	Dark	
53-12	26225-26229	High	
53-13	26230-26238	contrast	
53-14	26239-26247	Previous	
53-15	26248-26255	Version	
53-16	26256-26260	Docs	
53-17	26261-26265	Blog	
53-18	26266-26276	Contribute	
53-19	26277-26284	Privacy	
53-20	26285-26286	&	
53-21	26287-26294	Cookies	
53-22	26295-26300	Terms	
53-23	26301-26303	of	
53-24	26304-26307	Use	
53-25	26308-26318	Trademarks	
53-26	26319-26320	©	
53-27	26321-26330	Microsoft	
53-28	26331-26335	2021	

#Text=Is this page helpful? Yes Any additional feedback? Skip Submit Thank you. In this article Theme Light Dark High contrast Previous Version Docs Blog Contribute Privacy & Cookies
54-1	26336-26338	Is	
54-2	26339-26343	this	
54-3	26344-26348	page	
54-4	26349-26356	helpful	
54-5	26356-26357	?	
54-6	26358-26361	Yes	
54-7	26362-26365	Any	
54-8	26366-26376	additional	
54-9	26377-26385	feedback	
54-10	26385-26386	?	
54-11	26387-26391	Skip	
54-12	26392-26398	Submit	
54-13	26399-26404	Thank	
54-14	26405-26408	you	
54-15	26408-26409	.	
54-16	26410-26412	In	
54-17	26413-26417	this	
54-18	26418-26425	article	
54-19	26426-26431	Theme	
54-20	26432-26437	Light	
54-21	26438-26442	Dark	
54-22	26443-26447	High	
54-23	26448-26456	contrast	
54-24	26457-26465	Previous	
54-25	26466-26473	Version	
54-26	26474-26478	Docs	
54-27	26479-26483	Blog	
54-28	26484-26494	Contribute	
54-29	26495-26502	Privacy	
54-30	26503-26504	&	
54-31	26505-26512	Cookies	
