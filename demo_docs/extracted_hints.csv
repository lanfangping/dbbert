,doc_id,passage,recommendation,parameter,value,hint_type,Note,If you have lots of RAM and few developers,Default,Windows,"In the mysqld section, add or edit the max_connections property",Add or edit the max_connections property,Let's remember the current WAL location
0,1,"#records
= 100000
seq_page_cost
= 1
(default)
cpu_tuple_cost
= 0.01
(default)
cpu_filter_cost = 0.0025 (default) cpu_index_tuple_cost",0.01,cpu_index_tuple_cost,0.01,Absolute Value,,,,,,,
1,1,"#records
= 100000
seq_page_cost
= 1
(default)
cpu_tuple_cost
= 0.01
(default)
cpu_filter_cost = 0.0025 (default) cpu_index_tuple_cost",1,seq_page_cost,1,Absolute Value,,,,,,,
2,1,"#records
= 100000
seq_page_cost
= 1
(default)
cpu_tuple_cost
= 0.01
(default)
cpu_filter_cost = 0.0025 (default) cpu_index_tuple_cost",0.01,cpu_tuple_cost,0.01,Absolute Value,,,,,,,
3,5,"8. Properly Configure shared_buffers
We typically recommend 25% of available RAM. If you install TimescaleDB via a method that runs timescaledb-tune, it should automatically configure shared_buffers to something well-suited to your hardware specs. shared_buffers",25% of available RAM,shared_buffers,25%,Relative (RAM),,,,,,,
4,5,"Note: in some cases, typically with virtualization and constrained cgroups memory allocation, these automatically-configured settings may not be ideal. To check that your shared_buffers are set to within the 25% range,  run SHOW shared_buffers from your psql connection.
9. Run our Docker Images on Linux Hosts
If you are running a TimescaleDB Docker container (which runs Linux) on top of another Linux operating system, you're in great shape. The container is basically providing process isolation, and the overhead is extremely minimal. max_replication_slots",25%,shared_buffers,25%,Relative (RAM),,,,,,,
5,11,"PostgreSQL supports various types of indexes such as B-Tree (default), Hash, GiST, SP-GiST, and GIN. Here are the detailed steps to create PostgreSQL index.
5. Increase maximum connections
By default, PostgreSQL supports a maximum of 100 concurrent connections. This is stored in max_connections server variable. You can increase this number to support more concurrent connections and keep users from waiting. However, each connection consumes memory, so don’t increase it, unless required. temp_file_limit",100 concurrent connections,max_connections,100,Absolute Value,,,,,,,
6,15,"[local]:5433 user@exampledb=# select name, setting from pg_settings where name like '%wal_size%' or name like '%checkpoint%' order by name;
name
setting
------------------------------+-----------
checkpoint_completion_target | 0.9 checkpoint_completion_target",0.9,checkpoint_completion_target,0.9,Absolute Value,,,,,,,
7,15,"checkpoint_flush_after
| 32
checkpoint_timeout
| 300
checkpoint_warning
| 30
log_checkpoints
| off
max_wal_size
| 1024
min_wal_size
| 80
(7 rows) checkpoint_flush_after",300,checkpoint_warning,300,Absolute Value,,,,,,,
8,15,"checkpoint_flush_after
| 32
checkpoint_timeout
| 300
checkpoint_warning
| 30
log_checkpoints
| off
max_wal_size
| 1024
min_wal_size
| 80
(7 rows) checkpoint_flush_after",32,checkpoint_timeout,32,Absolute Value,,,,,,,
9,15,"checkpoint_flush_after
| 32
checkpoint_timeout
| 300
checkpoint_warning
| 30
log_checkpoints
| off
max_wal_size
| 1024
min_wal_size
| 80
(7 rows) checkpoint_flush_after",1024,min_wal_size,1024,Absolute Value,,,,,,,
10,15,"checkpoint_flush_after
| 32
checkpoint_timeout
| 300
checkpoint_warning
| 30
log_checkpoints
| off
max_wal_size
| 1024
min_wal_size
| 80
(7 rows) checkpoint_flush_after",1024,max_wal_size,1024,Absolute Value,,,,,,,
11,15,"max_wal_size sets the maximum amount of Write-Ahead-Logging (WAL) to grow between automatic checkpoints. This is a soft limit; WAL size can exceed max_wal_size under special circumstances, such as heavy load, a failing archive_command, or a high wal_keep_segments setting.
It should also be noted that increasing this parameter can increase the amount of time needed for crash recovery. The default value is 1GB (1024MB). max_wal_size",1GB (1024MB,max_wal_size,1GB,Absolute Value,,,,,,,
12,15,"max_wal_size sets the maximum amount of Write-Ahead-Logging (WAL) to grow between automatic checkpoints. This is a soft limit; WAL size can exceed max_wal_size under special circumstances, such as heavy load, a failing archive_command, or a high wal_keep_segments setting.
It should also be noted that increasing this parameter can increase the amount of time needed for crash recovery. The default value is 1GB (1024MB). max_wal_size",1GB (1024MB,max_wal_size,1024MB,Absolute Value,,,,,,,
13,15,"checkpoint_flush_after
| 32
checkpoint_timeout
| 300
checkpoint_warning
| 30
log_checkpoints
| off
max_wal_size
| 16384
min_wal_size
| 4096 checkpoint_timeout",300,checkpoint_warning,300,Absolute Value,,,,,,,
14,15,"checkpoint_flush_after
| 32
checkpoint_timeout
| 300
checkpoint_warning
| 30
log_checkpoints
| off
max_wal_size
| 16384
min_wal_size
| 4096 checkpoint_timeout",4096,checkpoint_timeout,4096,Absolute Value,,,,,,,
15,15,"checkpoint_flush_after
| 32
checkpoint_timeout
| 300
checkpoint_warning
| 30
log_checkpoints
| off
max_wal_size
| 16384
min_wal_size
| 4096 checkpoint_timeout",16384,min_wal_size,16384,Absolute Value,,,,,,,
16,15,"checkpoint_flush_after
| 32
checkpoint_timeout
| 300
checkpoint_warning
| 30
log_checkpoints
| off
max_wal_size
| 16384
min_wal_size
| 4096 checkpoint_timeout",16384,max_wal_size,16384,Absolute Value,,,,,,,
17,22,"resources available to PostgreSQL, as described at Connection Settings.
shared_buffers - 256MB
wal_buffers - 8MB
checkpoint_segments - 16",8MB,wal_buffers,8MB,Absolute Value,"The checkpoint_segments setting is removed in PostgreSQL 9.5 and higher, replaced by min_wal_size and max_wal_size. The PostgreSQL 9.5 shared_buffers",,,,,,
18,22,"resources available to PostgreSQL, as described at Connection Settings.
shared_buffers - 256MB
wal_buffers - 8MB
checkpoint_segments - 16",256MB,shared_buffers,256MB,Absolute Value,"The checkpoint_segments setting is removed in PostgreSQL 9.5 and higher, replaced by min_wal_size and max_wal_size. The PostgreSQL 9.5 shared_buffers",,,,,,
19,22,"release notes provides the following formula for determining the new settings:
max_wal_size = (3 * checkpoint_segments) * 16MB
checkpoint_completion_target - 0.9
Large clusters - Can contain up to 1000 hosts. Consider the following settings as starting points. log_checkpoints",0.9,checkpoint_completion_target,0.9,Absolute Value,,,,,,,
20,22,"max_connection - For large clusters, each database is typically hosted on a different host. In general, allow each database on a host 100 maximum
connections and then add 50 extra connections. You may have to increase the system resources available to PostgreSQL, as described at Connection Settings.
shared_buffers - 1024MB. This requires that the operating system can allocate sufficient shared memory. See PostgreSQL information on Managing Kernel Resources for more information on setting kernel resources. max_connections",1024MB,shared_buffers,1024MB,Absolute Value,,,,,,,
21,22,"max_connection - For large clusters, each database is typically hosted on a different host. In general, allow each database on a host 100 maximum
connections and then add 50 extra connections. You may have to increase the system resources available to PostgreSQL, as described at Connection Settings.
shared_buffers - 1024MB. This requires that the operating system can allocate sufficient shared memory. See PostgreSQL information on Managing Kernel Resources for more information on setting kernel resources. max_connections",100,max_connections,100,Absolute Value,,,,,,,
22,22,"release notes provides the following formula for determining the new settings:
max_wal_size = (3 * checkpoint_segments) * 16MB
checkpoint_completion_target - 0.9.
Configure the PostgreSQL server to start at boot.
Command
RHEL 7 compatible checkpoint_completion_target",0.9,checkpoint_completion_target,0.9,Absolute Value,,,,,,,
23,22,"release notes provides the following formula for determining the new settings:
max_wal_size = (3 * checkpoint_segments) * 16MB
checkpoint_completion_target - 0.9.
Configure the PostgreSQL server to start at boot.
Command
RHEL 7 compatible checkpoint_completion_target",(3 * checkpoint_segments) * 16MB,max_wal_size,3,Absolute Value,,,,,,,
24,22,"release notes provides the following formula for determining the new settings:
max_wal_size = (3 * checkpoint_segments) * 16MB
checkpoint_completion_target - 0.9.
Configure the PostgreSQL server to start at boot.
Command
RHEL 7 compatible checkpoint_completion_target",(3 * checkpoint_segments) * 16MB,max_wal_size,16MB,Absolute Value,,,,,,,
25,48,"When using ssds, the default value for
random_page_cost should be lowered, perhaps to 1.1.
This can be set at the
tablespace level if there is a mix of tablespaces on ssds and magnetic disks. min_parallel_table_scan_size",1.1,random_page_cost,1.1,Absolute Value,,,,,,,
26,49,"so memory-related optimizations generally have more of an impact on PostGIS than other types of PostgreSQL queries.For general details about optimizing PostgreSQL, refer to Tuning your PostgreSQL Server.For PostgreSQL 9.4+ configuration can be set at the server level without touching postgresql.conf or postgresql.auto.conf
by using the ALTER SYSTEM command.ALTER SYSTEM SET work_mem = '256MB';
-- this forces non-startup configs to take effect for new connections
SELECT pg_reload_conf(); allow_system_table_mods",256MB,work_mem,256MB,Absolute Value,,,,,,,
27,49,Adjust down for many concurrent users or low RAM.,16-64MB,effective_cache_size,16,Absolute Value,,"SET work_mem TO '256MB';
maintenance_work_mem
- the memory size used for VACUUM, CREATE INDEX, etc.",16-64MB effective_cache_size,,,,
28,49,Adjust down for many concurrent users or low RAM.,16-64MB,effective_cache_size,64MB,Absolute Value,,"SET work_mem TO '256MB';
maintenance_work_mem
- the memory size used for VACUUM, CREATE INDEX, etc.",16-64MB effective_cache_size,,,,
29,49,Adjust down for many concurrent users or low RAM.,256MB,work_mem,256MB,Absolute Value,,"SET work_mem TO '256MB';
maintenance_work_mem
- the memory size used for VACUUM, CREATE INDEX, etc.",16-64MB effective_cache_size,,,,
30,49,"Generally too low - ties up I/O, locks objects while swapping memory
Recommend 32MB to 1GB on production servers w/lots of RAM, but depends
on the # of concurrent users.",1GB,maintenance_work_mem,1GB,Absolute Value,,SET maintenance_work_mem TO '1GB'; effective_cache_size,,,,,
31,49,"max_parallel_workers_per_gather
This setting is only available for PostgreSQL 9.6+ and will only affect PostGIS 2.3+, since only PostGIS 2.3+ supports parallel queries.
If set to higher than 0, then some queries such as those involving relation functions like ST_Intersects can use multiple processes and can run max_function_args",0,max_function_args,0,Absolute Value,,,,,,,
32,49,"max_parallel_workers_per_gather
This setting is only available for PostgreSQL 9.6+ and will only affect PostGIS 2.3+, since only PostGIS 2.3+ supports parallel queries.
If set to higher than 0, then some queries such as those involving relation functions like ST_Intersects can use multiple processes and can run max_function_args",higher than 0,max_parallel_workers_per_gather,0,Absolute Value,,,,,,,
33,57,"shared_buffers = 1GB # up to 8GB
work_mem = 64MB
effective_cache_size = 2GB
checkpoint_segments = 64
checkpoint_timeout = 20min
checkpoint_completion_target = 0.9
maintenance_work_mem = 256MB shared_buffers",256MB shared_buffers,maintenance_work_mem,256MB,Absolute Value,,,,,,,
34,57,"shared_buffers = 1GB # up to 8GB
work_mem = 64MB
effective_cache_size = 2GB
checkpoint_segments = 64
checkpoint_timeout = 20min
checkpoint_completion_target = 0.9
maintenance_work_mem = 256MB shared_buffers",64MB,work_mem,64MB,Absolute Value,,,,,,,
35,57,"shared_buffers = 1GB # up to 8GB
work_mem = 64MB
effective_cache_size = 2GB
checkpoint_segments = 64
checkpoint_timeout = 20min
checkpoint_completion_target = 0.9
maintenance_work_mem = 256MB shared_buffers",20min,checkpoint_timeout,20min,Absolute Value,,,,,,,
36,57,"shared_buffers = 1GB # up to 8GB
work_mem = 64MB
effective_cache_size = 2GB
checkpoint_segments = 64
checkpoint_timeout = 20min
checkpoint_completion_target = 0.9
maintenance_work_mem = 256MB shared_buffers",2GB,effective_cache_size,2GB,Absolute Value,,,,,,,
37,57,"shared_buffers = 1GB # up to 8GB
work_mem = 64MB
effective_cache_size = 2GB
checkpoint_segments = 64
checkpoint_timeout = 20min
checkpoint_completion_target = 0.9
maintenance_work_mem = 256MB shared_buffers",1GB # up to 8GB,shared_buffers,1GB,Absolute Value,,,,,,,
38,57,"shared_buffers = 1GB # up to 8GB
work_mem = 64MB
effective_cache_size = 2GB
checkpoint_segments = 64
checkpoint_timeout = 20min
checkpoint_completion_target = 0.9
maintenance_work_mem = 256MB shared_buffers",1GB # up to 8GB,shared_buffers,8GB,Absolute Value,,,,,,,
39,57,"shared_buffers = 1GB # up to 8GB
work_mem = 64MB
effective_cache_size = 2GB
checkpoint_segments = 64
checkpoint_timeout = 20min
checkpoint_completion_target = 0.9
maintenance_work_mem = 256MB shared_buffers",0.9,checkpoint_completion_target,0.9,Absolute Value,,,,,,,
40,64,"(3 rows)The following example shows an increased value of max_parallel_workers_per_gather:SET max_parallel_workers_per_gather TO 6;
SHOW max_parallel_workers_per_gather;
max_parallel_workers_per_gather
--------------------------------- max_parallel_workers_per_gather",6,max_parallel_workers_per_gather,6,Absolute Value,,,,,,,
41,68,Linux: /etc/my.cnf,275,max_connections,275,Absolute Value,,,,c:\Users\All Users\MySQL\MySQL Server 5.x\my.ini,"max_connections = 275
Restart the database. log_connections",,
42,68,Windows: C:\Program Files\PostgreSQL\<version-of-postgresql>\data\postgresql.conf,275,max_connections,275,Absolute Value,,,,,,"max_connections = 275
Restart the database.
Create a database named alfresco.
Create a user named alfresco.
This user must have write permissions on all tables and sequences. db_user_namespace",
43,91,"=> ALTER SYSTEM SET max_wal_senders = 0;
student$ sudo pg_ctlcluster 11 main restart
Note that the change of the level requires restarting the server.",0,max_wal_senders,0,Absolute Value,,,,,,,=> SELECT pg_current_wal_insert_lsn(); wal_init_zero
44,91,"Because synchronization is connected with the actual (that is, slow) input/output, it is beneficial to do it as infrequently as possible. To this end, a backend process that completes a transaction and writes WAL makes a short pause, defined by the commit_delay parameter. But this happens only if the system has not less than commit_siblings active transactions. This behavior relies on the expectation that during the waiting time some transactions will be completed and it will be possible to synchronize them in one go. This is similar to how you hold the doors of an elevator so that someone has time to jump into the car.
By default, commit_siblings = 5 and commit_delay = 0, so actually there is no wait. It makes sense to change the value of commit_delay only for systems that execute a great number of OLTP transactions. commit_delay",commit_siblings = 5 and commit_delay = 0,commit_delay,5,Absolute Value,,,,,,,
45,91,"Because synchronization is connected with the actual (that is, slow) input/output, it is beneficial to do it as infrequently as possible. To this end, a backend process that completes a transaction and writes WAL makes a short pause, defined by the commit_delay parameter. But this happens only if the system has not less than commit_siblings active transactions. This behavior relies on the expectation that during the waiting time some transactions will be completed and it will be possible to synchronize them in one go. This is similar to how you hold the doors of an elevator so that someone has time to jump into the car.
By default, commit_siblings = 5 and commit_delay = 0, so actually there is no wait. It makes sense to change the value of commit_delay only for systems that execute a great number of OLTP transactions. commit_delay",commit_siblings = 5 and commit_delay = 0,commit_delay,0,Absolute Value,,,,,,,
46,91,"Because synchronization is connected with the actual (that is, slow) input/output, it is beneficial to do it as infrequently as possible. To this end, a backend process that completes a transaction and writes WAL makes a short pause, defined by the commit_delay parameter. But this happens only if the system has not less than commit_siblings active transactions. This behavior relies on the expectation that during the waiting time some transactions will be completed and it will be possible to synchronize them in one go. This is similar to how you hold the doors of an elevator so that someone has time to jump into the car.
By default, commit_siblings = 5 and commit_delay = 0, so actually there is no wait. It makes sense to change the value of commit_delay only for systems that execute a great number of OLTP transactions. commit_delay",5 and commit_delay = 0,commit_siblings,5,Absolute Value,,,,,,,
47,91,"Because synchronization is connected with the actual (that is, slow) input/output, it is beneficial to do it as infrequently as possible. To this end, a backend process that completes a transaction and writes WAL makes a short pause, defined by the commit_delay parameter. But this happens only if the system has not less than commit_siblings active transactions. This behavior relies on the expectation that during the waiting time some transactions will be completed and it will be possible to synchronize them in one go. This is similar to how you hold the doors of an elevator so that someone has time to jump into the car.
By default, commit_siblings = 5 and commit_delay = 0, so actually there is no wait. It makes sense to change the value of commit_delay only for systems that execute a great number of OLTP transactions. commit_delay",5 and commit_delay = 0,commit_siblings,0,Absolute Value,,,,,,,
48,91,"You can make writing asynchronous by setting synchronous_commit = off (or local).
When writing is asynchronous, WAL records are flushed by the wal writer process, which alternates work and waits (the waiting time is specified by the wal_writer_delay parameter with the default value of 200 ms). wal_writer_delay",200 ms,wal_writer_delay,200,Absolute Value,,,,,,,
